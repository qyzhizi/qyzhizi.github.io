<!doctype html><html lang=zh-cn data-theme=dark><head><meta charset=utf-8><meta name=viewport content="width=device-width"><meta name=theme-color content="#222" media="(prefers-color-scheme: dark)"><meta name=generator content="Hugo 0.112.5"><link rel="shortcut icon" type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=/imgs/icons/favicon_16x16_next.png><link rel=icon type=image/png sizes=32x32 href=/imgs/icons/favicon_32_32_next.png><link rel=apple-touch-icon sizes=180x180 href=/imgs/icons/apple_touch_icon_next.png><meta itemprop=name content="PyTorch 实现 Opencv Canny 算法"><meta itemprop=description content="PyTorch-实现-Opencv-Canny-算法"><meta itemprop=datePublished zgotmplz><meta itemprop=dateModified zgotmplz><meta itemprop=image content="/imgs/2001_big_icons.png"><meta itemprop=keywords content="opencv,pytorch,canny"><meta property="og:type" content="article"><meta property="og:title" content="PyTorch 实现 Opencv Canny 算法"><meta property="og:description" content="PyTorch-实现-Opencv-Canny-算法"><meta property="og:image" content="/imgs/2001_big_icons.png"><meta property="og:image:width" content="312"><meta property="og:image:height" content="312"><meta property="og:image:type" content="image/jpeg/png/svg/jpg"><meta property="og:url" content="/pytorch-implement-opencv-canny-algorithm.html"><meta property="og:site_name" content="log"><meta property="og:locale" content="zh-CN"><meta property="article:author" content="Hollis"><meta property="article:published_time" content="2023-07-04 17:06:31 +0800 CST"><meta property="article:modified_time" content="2023-07-04 17:06:31 +0800 CST"><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/font-awesome/6.1.2/css/all.min.css><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/animate.css/3.1.1/animate.min.css><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/viewerjs/1.11.0/viewer.min.css><link rel=stylesheet href=/css/main.min.8b63813f6d971d6efc075de818d178312c142a542313b8ac1b773085bbc915ef.css><style type=text/css>.post-footer,.flinks-list-footer hr:after{content:"~ 我可是有底线的哟 ~"}</style><script type=text/javascript>(function(){localDB={set:function(e,t,n){if(n===0)return;const s=new Date,o=n*864e5,i={value:t,expiry:s.getTime()+o};localStorage.setItem(e,JSON.stringify(i))},get:function(e){const t=localStorage.getItem(e);if(!t)return void 0;const n=JSON.parse(t),s=new Date;return s.getTime()>n.expiry?(localStorage.removeItem(e),void 0):n.value}},theme={active:function(){const e=localDB.get("theme");if(e==null)return;theme.toggle(e),window.matchMedia("(prefers-color-scheme: dark)").addListener(function(e){theme.toggle(e.matches?"dark":"light")})},toggle:function(e){document.documentElement.setAttribute("data-theme",e),localDB.set("theme",e,2);const t=document.querySelector("iframe.giscus-frame");if(t){const n={setConfig:{theme:e}};t.contentWindow.postMessage({giscus:n},"https://giscus.app")}}},theme.active()})(window)</script><script class=next-config data-name=page type=application/json>{"comments":false,"isHome":false,"isPage":true,"path":"pytorch-implement-opencv-canny-algorithm.html","permalink":"/pytorch-implement-opencv-canny-algorithm.html","title":"PyTorch 实现 Opencv Canny 算法","waline":{"js":[{"alias":"waline","alias_name":"@waline/client","file":"dist/pageview.js","name":"pageview","version":"2.13.0"},{"alias":"waline","alias_name":"@waline/client","file":"dist/comment.js","name":"comment","version":"2.13.0"}]}}</script><title>PyTorch 实现 Opencv Canny 算法 - log</title><noscript><link rel=stylesheet href=/css/noscript.css></noscript></head><body itemscope itemtype=http://schema.org/WebPage class=use-motion><div class=headband></div><main class=main><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle aria-label=切换导航栏 role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div></div><div class=site-meta><a href=/ class=brand rel=start><i class=logo-line></i><h1 class=site-title>log</h1><i class=logo-line></i></a><p class=site-subtitle itemprop=description>programming</p></div><div class=site-nav-right><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href=/ class=hvr-icon-pulse rel=section><i class="fa fa-home hvr-icon"></i>首页</a></li><li class="menu-item menu-item-about"><a href=/about.html class=hvr-icon-pulse rel=section><i class="fa fa-user hvr-icon"></i>关于</a></li><li class="menu-item menu-item-flinks"><a href=/flinks.html class=hvr-icon-pulse rel=section><i class="fa fa-thumbs-up hvr-icon"></i>站点示例</a></li><li class="menu-item menu-item-archives"><a href=/archives/ class=hvr-icon-pulse rel=section><i class="fa fa-archive hvr-icon"></i>归档
<span class=badge>16</span></a></li><li class="menu-item menu-item-commonweal"><a href=/404.html class=hvr-icon-pulse rel=section><i class="fa fa-heartbeat hvr-icon"></i>公益 404</a></li><li class="menu-item menu-item-RSS"><a href=/rss.xml class=hvr-icon-pulse rel=section><i class="fa fa-archive hvr-icon"></i>RSS</a></li><li class="menu-item menu-item-search"><a role=button class="popup-trigger hvr-icon-pulse"><i class="fa fa-search fa-fw hvr-icon"></i>搜索</a></li></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon><i class="fa fa-search"></i></span><div class=search-input-container><input autocomplete=off autocapitalize=off maxlength=80 placeholder=搜索... spellcheck=false type=search class=search-input></div><span class=popup-btn-close role=button><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class=search-result-icon><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></div><div class="toggle sidebar-toggle" role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div><aside class=sidebar><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class=sidebar-nav><li class=sidebar-nav-toc>文章目录</li><li class=sidebar-nav-overview>站点概览</li></ul><div class=sidebar-panel-container><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><nav id=TableOfContents><ul><li><a href=#程序运行>程序运行</a></li><li><a href=#canny-算法执行步骤>Canny 算法执行步骤</a></li><li><a href=#高斯滤波>高斯滤波</a></li><li><a href=#sobel-算子计算梯度>sobel 算子计算梯度</a></li><li><a href=#计算梯度的幅值与方向>计算梯度的幅值与方向</a><ul><li><a href=#计算幅值>计算幅值</a></li><li><a href=#计算梯度方向>计算梯度方向</a></li></ul></li><li><a href=#梯度的极大值抑制>梯度的极大值抑制</a></li><li><a href=#滞后阈值>滞后阈值</a></li><li><a href=#与opencv-算法对比>与opencv 算法对比</a></li><li><a href=#参考>参考</a></li></ul></nav></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author site-overview-item animated" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image alt=Hollis src=/imgs/img-lazy-loading.gif data-src=/imgs/2001_big_icons.png><p class=site-author-name itemprop=name>Hollis</p><div class=site-description itemprop=description>share something</div></div><div class="site-state-wrap site-overview-item animated"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/><span class=site-state-item-count>16</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>2</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>32</span>
<span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-social site-overview-item animated"><span class=links-of-social-item><a href=https://github.com/qyzhizi title="Github → https://github.com/qyzhizi" rel=noopener class=hvr-icon-pulse target=_blank><i class="fab fa-github fa-fw hvr-icon"></i>Github</a></span>
<span class=links-of-social-item><a href=https://twitter.com/qyzhizi title="Twitter → https://twitter.com/qyzhizi" rel=noopener class=hvr-icon-pulse target=_blank><i class="fab fa-twitter fa-fw hvr-icon"></i>Twitter</a></span></div><div class="cc-license animated" itemprop=license><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh class=cc-opacity rel=noopener target=_blank title=共享知识><img src=/imgs/img-lazy-loading.gif data-src=/imgs/cc/big/by_nc_sa.svg alt=共享知识></a></div><div class="links-of-blogroll site-overview-item animated"><div class=links-of-blogroll-title><i class="fa fa-globe fa-fw"></i>友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://lisenhui.cn title=https://lisenhui.cn target=_blank>凡梦星尘空间站</a></li></ul></div></div></div></div><div id=siteinfo-card-widget class=sidebar-card-widget><div class=item-headline><i class="fas fa-chart-line"></i>
<span>网站资讯</span></div><div class=siteinfo><div class=siteinfo-item><div class=item-name><i class="fa-solid fa-calendar-check"></i>已运行：</div><div class=item-count id=runTimes data-publishdate=2022-06-03T11:52:18+08:00></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-font"></i>总字数：</div><div class=item-count id=wordsCount data-count=30237></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-mug-hot"></i>阅读约：</div><div class=item-count id=readTimes data-times=71></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-clock-rotate-left"></i>最后更新于：</div><div class=item-count id=last-push-date data-lastpushdate=2023-07-04T17:06:31+08:00></div></div></div></div></aside><div class=sidebar-dimmer></div></header><div class=tool-buttons><div id=goto-gtranslate class=button title=多语言翻译><i class="fas fa-globe"></i></div><div id=toggle-theme class=button title=深浅模式切换><i class="fas fa-adjust"></i></div><div class=back-to-top role=button title=返回顶部><i class="fa fa-arrow-up"></i>
<span>0%</span></div></div><div class=reading-progress-bar></div><a role=button class="book-mark-link book-mark-link-fixed"></a>
<a href=https://github.com/qyzhizi rel="noopener external nofollow noreferrer" target=_blank title="Follow me on GitHub" class="exturl github-corner"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115h15l12 27L250 250V0z"/><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentcolor" style="transform-origin:130px 106px" class="octo-arm"/><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4l13.9-13.8C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8z" fill="currentcolor" class="octo-body"/></svg></a><script type=text/javascript src=//sidecar.gitter.im/dist/sidecar.v1.js async></script>
<script type=text/javascript>((window.gitter={}).chat={}).options={room:"hugo-next/community"}</script><noscript><div class=noscript-warning>Theme NexT works best with JavaScript enabled</div></noscript><div class="main-inner post posts-expand"><div class=post-block><article itemscope itemtype=http://schema.org/Article class=post-content lang><link itemprop=mainEntityOfPage href=/pytorch-implement-opencv-canny-algorithm.html><span hidden itemprop=author itemscope itemtype=http://schema.org/Person><meta itemprop=image content="/imgs/2001_big_icons.png"><meta itemprop=name content="Hollis"></span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization><meta itemprop=name content="Hollis"><meta itemprop=description content="share something"></span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork><meta itemprop=name content="PyTorch 实现 Opencv Canny 算法"><meta itemprop=description content="PyTorch-实现-Opencv-Canny-算法"></span><header class=post-header><h1 class=post-title itemprop="name headline">PyTorch 实现 Opencv Canny 算法
<a href=https://github.com/qyzhizi/hugo-blog/tree/main/content/post/PyTorch-%e5%ae%9e%e7%8e%b0-Opencv-Canny-%e7%ae%97%e6%b3%95.md rel="noopener external nofollow noreferrer" target=_blank class="exturl post-edit-link" title=编辑><i class="fa fa-pen-nib"></i></a></h1><div class=post-meta-container><div class=post-meta-items><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-calendar"></i></span>
<span class=post-meta-item-text>发表于：</span>
<time title="发表于：2023-07-04 17:06:31 +0800 CST" itemprop="dateCreated datePublished" datetime="2023-07-04 17:06:31 +0800 CST">2023-07-04</time></span>
<span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-folder-open"></i></span>
<span class=post-meta-item-text>分类于：</span>
<span itemprop=about itemscope itemtype=http://schema.org/Thing><a href=/categories/programming itemprop=url rel=index><span itemprop=name>programming</span></a></span></span></div><div class=post-meta-items><span class=post-meta-item title=字数><span class=post-meta-item-icon><i class="far fa-file-word"></i></span>
<span class=post-meta-item-text>字数：</span><span>4160</span></span>
<span class=post-meta-item title=阅读><span class=post-meta-item-icon><i class="far fa-clock"></i></span>
<span class=post-meta-item-text>阅读：&ap;</span>
<span>9分钟</span></span>
<span class=post-meta-item title=浏览><span class=post-meta-item-icon><i class="far fa-eye"></i></span>
<span class=post-meta-item-text>浏览：</span>
<span class=waline-pageview-count data-path=/pytorch-implement-opencv-canny-algorithm.html><i class="fa fa-sync fa-spin"></i></span></span></div></div></header><div class="post-body autonumber" itemprop=articleBody><div style=text-align:center><img src=https://qyzhizi.cn/img/202307041413380.png style=width:50%></div><p>使用PyTorch 实现Canny算法，相比于纯python实现，速度会更快，因为PyTorch api 使用很多c语言的底层模块，比如卷积。另外使用Pytorch可以很方便得利用cuda的加速，所以也在GPU并行运算上也有优势。</p><p>不过相比OpenCV c++的高效，PyTorch的实现显得更冗余，效率一般。但是PyTorch 使用张量、卷积来实现图像处理，保证一定效率的同时代码更简洁，另外比较重要的是，全过程使用python语言所以程序比较方进行调试，展示算法的中间处理过程。</p><h2 id=程序运行>程序运行</h2><p>完整程序：https://github.com/qyzhizi/canny-algorithm.git</p><p>运行命令：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-shell data-lang=shell><span style=display:flex><span>python pytorch-canny.py -v -i data/lena.png -gk <span style=color:#ae81ff>0</span> -L <span style=color:#ae81ff>100</span> -H <span style=color:#ae81ff>200</span>
</span></span></code></pre></div><p>命令行参数：
<code>-v</code>: 展示中间过程处理的图片
<code>-i</code>: 图片路径
<code>-gk</code>: 高斯核大小，默认是3， 传入0则表示不使用高斯模糊处理
<code>-L</code>: 低阈值
<code>-H</code>: 高阈值</p><p>结果：</p><div>    <img src=https://qyzhizi.cn/img/202306291745926.png style=display:inline-block;width:49%>
    <img src=https://qyzhizi.cn/img/202307041413380.png style=display:inline-block;width:49%></div><h2 id=canny-算法执行步骤>Canny 算法执行步骤</h2><p>算法主要分为一下步骤：</p><ul><li>高斯滤波</li><li>使用sobel 算子计算梯度(水平梯度, 垂直梯度)</li><li>计算梯度的幅值与方向</li><li>梯度的极大值抑制</li><li>滞后滤波</li></ul><p>main 程序片段</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>main</span>():
</span></span><span style=display:flex><span>    ap <span style=color:#f92672>=</span> argparse<span style=color:#f92672>.</span>ArgumentParser()
</span></span><span style=display:flex><span>    ap<span style=color:#f92672>.</span>add_argument(<span style=color:#e6db74>&#34;-i&#34;</span>, <span style=color:#e6db74>&#34;--image&#34;</span>, required<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>, default<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;lena.png&#34;</span>, help<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Path to the image&#34;</span>)
</span></span><span style=display:flex><span>    ap<span style=color:#f92672>.</span>add_argument(<span style=color:#e6db74>&#34;-v&#34;</span>, <span style=color:#e6db74>&#34;--verbose&#34;</span>, action<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;store_true&#39;</span>, default<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>, help<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Path to the image&#34;</span>)
</span></span><span style=display:flex><span>    ap<span style=color:#f92672>.</span>add_argument(<span style=color:#e6db74>&#34;-gk&#34;</span>, <span style=color:#e6db74>&#34;--gaussian_kernel_size&#34;</span>, type<span style=color:#f92672>=</span>int, default<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, help<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Path to the image&#34;</span>)
</span></span><span style=display:flex><span>    ap<span style=color:#f92672>.</span>add_argument(<span style=color:#e6db74>&#34;-L&#34;</span>, <span style=color:#e6db74>&#34;--threshold_low&#34;</span>, type<span style=color:#f92672>=</span>int, default<span style=color:#f92672>=</span><span style=color:#ae81ff>20</span>, help<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Path to the image&#34;</span>)
</span></span><span style=display:flex><span>    ap<span style=color:#f92672>.</span>add_argument(<span style=color:#e6db74>&#34;-H&#34;</span>, <span style=color:#e6db74>&#34;--threshold_high&#34;</span>, type<span style=color:#f92672>=</span>int, default<span style=color:#f92672>=</span><span style=color:#ae81ff>50</span>, help<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Path to the image&#34;</span>)
</span></span><span style=display:flex><span>    args <span style=color:#f92672>=</span> vars(ap<span style=color:#f92672>.</span>parse_args())
</span></span><span style=display:flex><span>    verbose <span style=color:#f92672>=</span> args[<span style=color:#e6db74>&#34;verbose&#34;</span>]
</span></span><span style=display:flex><span>    threshold_low <span style=color:#f92672>=</span> args[<span style=color:#e6db74>&#34;threshold_low&#34;</span>]
</span></span><span style=display:flex><span>    threshold_high <span style=color:#f92672>=</span> args[<span style=color:#e6db74>&#34;threshold_high&#34;</span>]
</span></span><span style=display:flex><span>    gaussian_kernel_size <span style=color:#f92672>=</span> args[<span style=color:#e6db74>&#34;gaussian_kernel_size&#34;</span>]
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;args: &#34;</span> , args)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 把工作目录切换到当前文件夹所在目录</span>
</span></span><span style=display:flex><span>    os<span style=color:#f92672>.</span>chdir(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>dirname(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>abspath(__file__)))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 打印当前工作目录</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> verbose:
</span></span><span style=display:flex><span>        print(os<span style=color:#f92672>.</span>getcwd()) 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 读入一张图片，并转换为灰度图</span>
</span></span><span style=display:flex><span>    im <span style=color:#f92672>=</span> Image<span style=color:#f92672>.</span>open(args[<span style=color:#e6db74>&#34;image&#34;</span>])<span style=color:#f92672>.</span>convert(<span style=color:#e6db74>&#39;L&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 将图片数据转换为矩阵</span>
</span></span><span style=display:flex><span>    im <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array(im, dtype<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;float32&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 将图片矩阵转换为pytorch tensor,并适配卷积输入的要求</span>
</span></span><span style=display:flex><span>    im <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>from_numpy(im<span style=color:#f92672>.</span>reshape((<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, im<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>], im<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>])))
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> verbose:
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#34;im.shape: &#34;</span>, im<span style=color:#f92672>.</span>shape)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 对图像进行高斯滤波，平滑图像，去除噪声</span>
</span></span><span style=display:flex><span>    im <span style=color:#f92672>=</span> gaussian_blur(im, gaussian_kernel_size, verbose<span style=color:#f92672>=</span>verbose)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># sobel 算子进行边缘检测</span>
</span></span><span style=display:flex><span>    gradient_v <span style=color:#f92672>=</span> functional_conv2d_vertical(im, verbose<span style=color:#f92672>=</span>verbose) <span style=color:#75715e># 竖直梯度</span>
</span></span><span style=display:flex><span>    gradient_h <span style=color:#f92672>=</span> functional_conv2d_horizontal(im, verbose<span style=color:#f92672>=</span>verbose) <span style=color:#75715e># 水平梯度</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 计算梯度幅值</span>
</span></span><span style=display:flex><span>    gradient_magnitude <span style=color:#f92672>=</span> get_gradient_magnitude(gradient_v, gradient_h, verbose<span style=color:#f92672>=</span>verbose)
</span></span><span style=display:flex><span>    <span style=color:#75715e># 计算梯度方向</span>
</span></span><span style=display:flex><span>    gradient_direction_quantized <span style=color:#f92672>=</span> get_gradient_direction_quantized(gradient_v, gradient_h, verbose<span style=color:#f92672>=</span>verbose)
</span></span><span style=display:flex><span>    <span style=color:#75715e># 非极大值抑制</span>
</span></span><span style=display:flex><span>    nms_tensor <span style=color:#f92672>=</span> nms(gradient_magnitude, gradient_direction_quantized, verbose<span style=color:#f92672>=</span>verbose)
</span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010> </span> <span style=color:#960050;background-color:#1e0010> </span> <span style=color:#75715e># 阈值处理</span>
</span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010> </span> <span style=color:#960050;background-color:#1e0010> </span> <span style=color:#75715e># edge_detect = threshold(nms_tensor, low=threshold_low, high=threshold_high, weak=50, strong=255)</span>
</span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010> </span> <span style=color:#960050;background-color:#1e0010> </span> <span style=color:#75715e># 滞后阈值</span>
</span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010> </span> <span style=color:#960050;background-color:#1e0010> </span> edge_detect <span style=color:#f92672>=</span> hysteresis_threshold(nms_tensor, low<span style=color:#f92672>=</span>threshold_low, high<span style=color:#f92672>=</span>threshold_high)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> verbose:
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#34;edge_detect.shape: &#34;</span>, edge_detect<span style=color:#f92672>.</span>shape, <span style=color:#e6db74>&#34;im.shape: &#34;</span>, im<span style=color:#f92672>.</span>shape)
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>imshow(edge_detect<span style=color:#f92672>.</span>squeeze()<span style=color:#f92672>.</span>detach()<span style=color:#f92672>.</span>numpy(), cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;gray&#39;</span>)
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#34;Edge Detection&#34;</span>)
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>show()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 保存图片</span>
</span></span><span style=display:flex><span>    save_edge_detect_as_image(edge_detect, <span style=color:#e6db74>&#34;data/edge_detect.png&#34;</span>, verbose<span style=color:#f92672>=</span>verbose)
</span></span><span style=display:flex><span>    save_edge_detect_and_origin_image_as_image(edge_detect, args[<span style=color:#e6db74>&#34;image&#34;</span>], <span style=color:#e6db74>&#34;data/edge_detect_and_origin_image.png&#34;</span>, verbose<span style=color:#f92672>=</span>verbose)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;__main__&#34;</span>:
</span></span><span style=display:flex><span>    start_time <span style=color:#f92672>=</span> time<span style=color:#f92672>.</span>time()
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;programming strat&#34;</span>)
</span></span><span style=display:flex><span>    main()
</span></span><span style=display:flex><span>    end_time <span style=color:#f92672>=</span> time<span style=color:#f92672>.</span>time()
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;time: &#34;</span>, end_time <span style=color:#f92672>-</span> start_time)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;programming end&#34;</span>)
</span></span></code></pre></div><h2 id=高斯滤波>高斯滤波</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>dnorm</span>(x: int, mu:int , sd:int)<span style=color:#f92672>-&gt;</span> np<span style=color:#f92672>.</span>float32:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>1</span> <span style=color:#f92672>/</span> (np<span style=color:#f92672>.</span>sqrt(<span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>pi) <span style=color:#f92672>*</span> sd) <span style=color:#f92672>*</span> np<span style=color:#f92672>.</span>e <span style=color:#f92672>**</span> (<span style=color:#f92672>-</span>np<span style=color:#f92672>.</span>power((x <span style=color:#f92672>-</span> mu) <span style=color:#f92672>/</span> sd, <span style=color:#ae81ff>2</span>) <span style=color:#f92672>/</span> <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>gaussian_kernel</span>(size: int, sigma: int<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, verbose: bool<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>) <span style=color:#f92672>-&gt;</span> np<span style=color:#f92672>.</span>ndarray:
</span></span><span style=display:flex><span>    kernel_1D <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>linspace(<span style=color:#f92672>-</span>(size <span style=color:#f92672>//</span> <span style=color:#ae81ff>2</span>), size <span style=color:#f92672>//</span> <span style=color:#ae81ff>2</span>, size)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(size):
</span></span><span style=display:flex><span>        kernel_1D[i] <span style=color:#f92672>=</span> dnorm(kernel_1D[i], <span style=color:#ae81ff>0</span>, sigma)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> verbose:
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#34;kernel_1D: &#34;</span>, kernel_1D)
</span></span><span style=display:flex><span>    kernel_2D <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>outer(kernel_1D, kernel_1D)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> verbose:
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#34;kernel_2D: &#34;</span>, kernel_2D)
</span></span><span style=display:flex><span>    kernel_2D <span style=color:#f92672>*=</span> <span style=color:#ae81ff>1.0</span> <span style=color:#f92672>/</span> (kernel_2D<span style=color:#f92672>.</span>max() <span style=color:#f92672>*</span> size <span style=color:#f92672>*</span> size)<span style=color:#75715e># 归一化, 使得kernel_2D的最大值为1</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> verbose:
</span></span><span style=display:flex><span>        print(kernel_2D<span style=color:#f92672>.</span>max())
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#34;kernel_2D: &#34;</span>, kernel_2D)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> verbose:
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>imshow(kernel_2D, interpolation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;none&#39;</span>, cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;gray&#39;</span>)
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#34;Kernel ( </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>X</span><span style=color:#e6db74>{}</span><span style=color:#e6db74> )&#34;</span><span style=color:#f92672>.</span>format(size, size))
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>show()    
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> kernel_2D
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 对图像进行高斯滤波，平滑图像，去除噪声</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>gaussian_blur</span>(image: torch<span style=color:#f92672>.</span>tensor, kernel_size: int, verbose<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>) <span style=color:#f92672>-&gt;</span> torch<span style=color:#f92672>.</span>tensor:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> kernel_size <span style=color:#f92672>%</span> <span style=color:#ae81ff>2</span> <span style=color:#f92672>==</span> <span style=color:#ae81ff>1</span> <span style=color:#f92672>and</span> kernel_size <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>1</span> <span style=color:#f92672>and</span> kernel_size <span style=color:#f92672>&lt;</span> <span style=color:#ae81ff>20</span>:
</span></span><span style=display:flex><span>        kernel <span style=color:#f92672>=</span> gaussian_kernel(kernel_size, sigma<span style=color:#f92672>=</span>math<span style=color:#f92672>.</span>sqrt(kernel_size), verbose<span style=color:#f92672>=</span>verbose)
</span></span><span style=display:flex><span>        kernel <span style=color:#f92672>=</span> kernel<span style=color:#f92672>.</span>reshape((<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, kernel_size, kernel_size))
</span></span><span style=display:flex><span>        weight <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>from_numpy(kernel)<span style=color:#f92672>.</span>to(torch<span style=color:#f92672>.</span>float32)
</span></span><span style=display:flex><span>        <span style=color:#75715e># image padding kernel_size // 2, 使用原始图像的边缘像素进行填充</span>
</span></span><span style=display:flex><span>        image <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>pad(image, (kernel_size <span style=color:#f92672>//</span> <span style=color:#ae81ff>2</span>, kernel_size <span style=color:#f92672>//</span> <span style=color:#ae81ff>2</span>, kernel_size <span style=color:#f92672>//</span> <span style=color:#ae81ff>2</span>, kernel_size <span style=color:#f92672>//</span> <span style=color:#ae81ff>2</span>), mode<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;reflect&#39;</span>)
</span></span><span style=display:flex><span>        blur <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>conv2d(image, weight, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> verbose:
</span></span><span style=display:flex><span>            plt<span style=color:#f92672>.</span>imshow(blur<span style=color:#f92672>.</span>squeeze()<span style=color:#f92672>.</span>numpy(), cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;gray&#39;</span>)
</span></span><span style=display:flex><span>            plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#34;blur&#34;</span>)
</span></span><span style=display:flex><span>            plt<span style=color:#f92672>.</span>show()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> blur
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> image
</span></span></code></pre></div><p>函数<code>gaussian_blur</code> :</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>gaussian_blur</span>(image: torch<span style=color:#f92672>.</span>tensor, kernel_size: int, verbose<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>) <span style=color:#f92672>-&gt;</span> torch<span style=color:#f92672>.</span>tensor:
</span></span></code></pre></div><p><code>gaussian_blur</code> 实现了高斯滤波，首先调 <code>gaussian_kernel</code> 获取高斯核，然后转换为<code>tensor</code>类型，作为接下卷积的权重。
使用<code>F.conv2d</code> 进行卷积，卷积核为高斯核，卷积结果就是高斯模糊化后的图片。</p><h2 id=sobel-算子计算梯度>sobel 算子计算梯度</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># sobel 算子进行边缘检测</span>
</span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010> </span> <span style=color:#960050;background-color:#1e0010> </span> gradient_v <span style=color:#f92672>=</span> functional_conv2d_vertical(im, verbose<span style=color:#f92672>=</span>verbose) <span style=color:#75715e># 竖直梯度</span>
</span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010> </span> <span style=color:#960050;background-color:#1e0010> </span> gradient_h <span style=color:#f92672>=</span> functional_conv2d_horizontal(im, verbose<span style=color:#f92672>=</span>verbose) <span style=color:#75715e># 水平梯度</span>
</span></span></code></pre></div><p>同样使用了卷积来计算梯度：<code>F.conv2d(im, weight, stride=1, padding=0)</code>, 注意padding：<code>im = F.pad(im, (1, 1, 1, 1), mode='replicate')</code> ， 这里使用了复制模式。使用补零或翻转的模式都不如复制模式好。opencv 的实现也是复制模式。</p><p>关于sobel 算子的原理，可以参考另外一篇文章：
<a href=https://qyzhizi.github.io/pytorch-Edge-detection-using-convolution.html#sobel%E7%B4%A2%E8%B4%9D%E5%B0%94-%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B title="# Pytorch卷积实现边缘检测" rel="noopener external nofollow noreferrer" target=_blank class=exturl># Pytorch卷积实现边缘检测
<i class="fa fa-external-link-alt"></i></a></p><p><code>functional_conv2d_vertical</code> 函数 与 <code>functional_conv2d_horizontal</code>函数的代码：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>functional_conv2d_horizontal</span>(im, verbose<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;使用F.Conv2d进行边缘检测, 检测竖直方向的轮廓, 水平梯度，右方向为正方向
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    Args:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        im (tensor): 输入的tensor图像
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    Returns:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        tensor: 输出的tensor图像
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;&#34;&#34;</span>    
</span></span><span style=display:flex><span>    sobel_kernel <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([[<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>], [<span style=color:#f92672>-</span><span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>2</span>], [<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>]], dtype<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;float32&#39;</span>)
</span></span><span style=display:flex><span>    sobel_kernel <span style=color:#f92672>=</span> sobel_kernel<span style=color:#f92672>.</span>reshape((<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>))
</span></span><span style=display:flex><span>    weight <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>from_numpy(sobel_kernel)
</span></span><span style=display:flex><span>    im <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>pad(im, (<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), mode<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;replicate&#39;</span>)
</span></span><span style=display:flex><span>    edge_detect <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>conv2d(im, weight, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> verbose:
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>imshow(edge_detect<span style=color:#f92672>.</span>squeeze()<span style=color:#f92672>.</span>detach()<span style=color:#f92672>.</span>numpy(), cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;gray&#39;</span>)
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#34;horizontal&#34;</span>)
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>show()
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> edge_detect
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>functional_conv2d_vertical</span>(im, verbose<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;使用F.Conv2d进行边缘检测, 检测水平方向的轮廓， 垂直梯度，向上为正方向
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    Args:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        im (tensor): 输入的tensor图像
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    Returns:
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        tensor: 输出的tensor图像
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;&#34;&#34;</span>    
</span></span><span style=display:flex><span>    sobel_kernel <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([[<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>2</span>, <span style=color:#ae81ff>1</span>], [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>], [<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>2</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>]], dtype<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;float32&#39;</span>)
</span></span><span style=display:flex><span>    sobel_kernel <span style=color:#f92672>=</span> sobel_kernel<span style=color:#f92672>.</span>reshape((<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>))
</span></span><span style=display:flex><span>    weight <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>from_numpy(sobel_kernel)
</span></span><span style=display:flex><span>    im <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>pad(im, (<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>), mode<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;replicate&#39;</span>)
</span></span><span style=display:flex><span>    edge_detect <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>conv2d(im, weight, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> verbose:
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>imshow(edge_detect<span style=color:#f92672>.</span>squeeze()<span style=color:#f92672>.</span>detach()<span style=color:#f92672>.</span>numpy() , cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;gray&#39;</span>)
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#34;vertical&#34;</span>)
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>show()
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> edge_detect
</span></span></code></pre></div><h2 id=计算梯度的幅值与方向>计算梯度的幅值与方向</h2><p>梯度幅值与方向将用于极大值抑制。</p><p>函数调用：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 计算梯度幅值</span>
</span></span><span style=display:flex><span>gradient_magnitude <span style=color:#f92672>=</span> get_gradient_magnitude(gradient_v, gradient_h, verbose<span style=color:#f92672>=</span>verbose)
</span></span><span style=display:flex><span><span style=color:#75715e># 计算梯度方向</span>
</span></span><span style=display:flex><span>gradient_direction_quantized <span style=color:#f92672>=</span> get_gradient_direction_quantized(gradient_v, gradient_h, verbose<span style=color:#f92672>=</span>verbose)
</span></span></code></pre></div><h3 id=计算幅值>计算幅值</h3><p>默认使用<code>L1</code>范数， 在opencv 的实现中，如果sobel卷积核比较大，比如<code>16x16</code> 会使用<code>L2</code>范数。
参数：<code>gradient_v</code> 代表垂直方向的梯度，有正负值，向上为正方向。
<code>gradient_h</code> 代表水平方向的梯度，有正负值，右方向为正方向。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_gradient_magnitude</span>(gradient_v: torch<span style=color:#f92672>.</span>tensor, gradient_h: torch<span style=color:#f92672>.</span>tensor, verbose<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>, use_l2_norm<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>) <span style=color:#f92672>-&gt;</span> torch<span style=color:#f92672>.</span>tensor:
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;计算梯度幅值
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 计算梯度的幅值</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> use_l2_norm:
</span></span><span style=display:flex><span>        <span style=color:#75715e># use l2 norm</span>
</span></span><span style=display:flex><span>        gradient_magnitude <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>sqrt(gradient_v<span style=color:#f92672>**</span><span style=color:#ae81ff>2</span> <span style=color:#f92672>+</span> gradient_h<span style=color:#f92672>**</span><span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>        <span style=color:#75715e># use l1 norm</span>
</span></span><span style=display:flex><span>        gradient_magnitude <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>abs(gradient_v) <span style=color:#f92672>+</span> torch<span style=color:#f92672>.</span>abs(gradient_h)
</span></span><span style=display:flex><span>    <span style=color:#75715e># 将梯度幅值限制在0-255之间</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># gradient_magnitude = gradient_magnitude * 255.0 / gradient_magnitude.max()</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> verbose:
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>imshow(gradient_magnitude<span style=color:#f92672>.</span>squeeze()<span style=color:#f92672>.</span>numpy(), cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;gray&#39;</span>)
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#34;Gradient Magnitude&#34;</span>)
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>show()
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> gradient_magnitude
</span></span></code></pre></div><h3 id=计算梯度方向>计算梯度方向</h3><p>这里判断梯度方向时，会将梯度方向判定为<code>[0, 45, 90, 135]</code>之一，用如下图表示：
<img src=https://qyzhizi.cn/img/202307031852659.png style=width:200></p><p>这里的划分标准是：
位于<code>[(360-22.5), 360] [0,22.5] [(180-22.5), (180+22.5)]</code> 区间判方向为<code>0</code>度
下图所示：
<img src=https://qyzhizi.cn/img/202307041526158.png style=width:200></p><p>位于<code>[(90-22.5), (90+22.5)] [(270-22.5), (270+22.5)]</code> 区间判方向为<code>90</code>度.
如下图所示：
<img src=https://qyzhizi.cn/img/202307041529413.png style=width:200>
同理，位于<code>[135-22.5, 135+22.5] or [315-22.5, 315+22.5]</code>区间判方向为<code>135</code>度. 位于<code>[45-22.5, 45+22.5] or [225-22.5, 225+22.5]</code>判方向为<code>45</code>度
如下图所示：
<img src=https://qyzhizi.cn/img/202307041534369.png style=width:200></p><p>实际计算过程中，<code>[0, 45, 90, 135]</code> 4个方向分别用<code>[0, 1, 2, 3]</code>表示。
例如：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 将角度值转换为四个方向之一：0度，45度，90度，135度</span>
</span></span><span style=display:flex><span>    gradient_direction_quantized <span style=color:#f92672>=</span> (torch<span style=color:#f92672>.</span>round(gradient_direction_deg <span style=color:#f92672>/</span> <span style=color:#ae81ff>45</span>) <span style=color:#f92672>%</span> <span style=color:#ae81ff>4</span>)<span style=color:#f92672>.</span>int()
</span></span></code></pre></div><p><code>gradient_direction_quantized</code> 是一个包含<code>[0, 1, 2, 3]</code>的tensor.</p><p><code>torch.round(gradient_direction_deg / 45)</code> 这里会进行四舍五入，比如：<code>torch.round((135+22.5) / 45) == torch.round(3.5) == 4</code></p><p>计算梯度方向函数：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_gradient_direction_quantized</span>(gradient_v: torch<span style=color:#f92672>.</span>tensor, gradient_h: torch<span style=color:#f92672>.</span>tensor, verbose<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>) <span style=color:#f92672>-&gt;</span> torch<span style=color:#f92672>.</span>tensor:
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;计算梯度方向
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    将梯度方向转换为四个方向之一: 0度，45度，90度，135度, 分别用 0,1,2,3 表示。
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 计算梯度方向, 以弧度为单位</span>
</span></span><span style=display:flex><span>    gradient_direction <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>atan2(gradient_v, gradient_h)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 将梯度方向转换为角度值, 并将角度值转换为0-360度之间</span>
</span></span><span style=display:flex><span>    gradient_direction_deg <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>rad2deg(gradient_direction) <span style=color:#f92672>+</span> <span style=color:#ae81ff>180</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 将角度值转换为四个方向之一：0度，45度，90度，135度</span>
</span></span><span style=display:flex><span>    gradient_direction_quantized <span style=color:#f92672>=</span> (torch<span style=color:#f92672>.</span>round(gradient_direction_deg <span style=color:#f92672>/</span> <span style=color:#ae81ff>45</span>) <span style=color:#f92672>%</span> <span style=color:#ae81ff>4</span>)<span style=color:#f92672>.</span>int()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> verbose:
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#34;gradient_direction_quantized: &#34;</span>, gradient_direction_quantized)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> gradient_direction_quantized
</span></span></code></pre></div><h2 id=梯度的极大值抑制>梯度的极大值抑制</h2><p><code>极大值抑制算法：</code>
进行极大值抑制时会对周边先padding一圈0，然后对某个像素进行极大值抑制时，然后判断当前像素的方向，方向分别用<code>0, 1, 2, 3</code>表示，代表着<code>0度、45度、90度，135度</code>。假设当前像素是<code>135度</code>的方向，所以会比较<code>135度</code>方向上另外2个像素，如果当前像素的坐标是<code>(0,0)</code>, 那么另两个像素的坐标就是<code>(-1,1）(1,-1)</code>，注意即使另两个像素不是135度，依然选这两个坐标，另两个像素是不是135度不重要，至于为什么，我也不知道如何解释。这种情况下，遍历每个像素就得到了极大值抑制的结果。</p><p>可以使用pytorch 的卷积来实现, 先定义一个卷积：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span>nms_conv_op <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>nn<span style=color:#f92672>.</span>Conv2d(in_channels<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>,out_channels<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, bias<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span></code></pre></div><p>它的输出通道为3， 这意味着卷积的通道为3
例如：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span>quantized_0_list <span style=color:#f92672>=</span> [[[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]],
</span></span><span style=display:flex><span>					[[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]],
</span></span><span style=display:flex><span>					[[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]]]
</span></span></code></pre></div><p>这是选取<code>0</code>度方向的卷积核，作用是选取该方向上的3个元素，每个卷积核选中某个方向上的一个元素。
第一个通道：<code>[[0, 0, 0],[1, 0, 0],[0, 0, 0]]</code> 将会选择当前元素左边的元素。第二个通道选择当前元素，第3个通道选择当前元素右边的元素。
<code>45度、90度，135度</code> 的情况也是类似，这里就不多赘述了。
由于有4个方向，因此会进行4次卷积.
假设输入<code>gradient_magnitude</code>的shape 是<code>(1,1,n,m)</code>, 那么输出的<code>nms_edge</code> 的shape 是 <code>(1,3,n,m)</code> , 这里3 表示3通道，保存着对应位置某个方向上的3个元素。</p><p><code>mask_i = (gradient_direction_quantized == i).int()</code>: 获取某个方向上的<code>mask</code>.
<code>nms_direction_conv_mask_i = nms_direction_conv_i * mask_i</code>: 将某次卷积的结果与<code>mask_i</code> 相乘，只选择掩码所标识位置的值。shape 是 <code>(1,3,n,m)</code>，
<code>nms_direction_conv_mask_max_i, _ = torch.max(nms_direction_conv_mask_i, dim=1)</code>: 最后选择<code>nms_direction_conv_mask_i</code> 维度<code>1</code>上（3通道）最大的值, <code>nms_direction_conv_mask_max_i</code> 的形状变为<code>(1,1,n,m)</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span>nms_edge <span style=color:#f92672>=</span> nms_edge <span style=color:#f92672>+</span> ((gradient_magnitude <span style=color:#f92672>==</span> nms_direction_conv_mask_max_i) <span style=color:#f92672>*</span> nms_direction_conv_mask_max_i) 
</span></span></code></pre></div><p><code>nms_direction_conv_mask_max_i</code> 中每个元素，表示该元素在i方向上最大的值， 但是这个最大值不一定是当前的元素。
<code>(gradient_magnitude == nms_direction_conv_mask_max_i)</code>: 当前元素如果是最大的，那么选中，否者放弃。
<code>(gradient_magnitude == nms_direction_conv_mask_max_i)</code> 返回的<code>0, 1</code>的矩阵，所以还需乘<code>nms_direction_conv_mask_max_i</code> 来选中对应的元素，最后加入到最终的输出<code>nms_edge</code>。</p><p>完整程序：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>nms</span>(gradient_magnitude: torch<span style=color:#f92672>.</span>tensor, 
</span></span><span style=display:flex><span>        gradient_direction_quantized: torch<span style=color:#f92672>.</span>tensor,
</span></span><span style=display:flex><span>        verbose<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>) <span style=color:#f92672>-&gt;</span> torch<span style=color:#f92672>.</span>tensor:
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;非极大值抑制&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    nms_edge <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>zeros_like(gradient_magnitude)
</span></span><span style=display:flex><span>    nms_conv_op <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>nn<span style=color:#f92672>.</span>Conv2d(in_channels<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>,out_channels<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>,
</span></span><span style=display:flex><span>                                  kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>                                  padding<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, bias<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    quantized_0_list <span style=color:#f92672>=</span> [[[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]],
</span></span><span style=display:flex><span>                        [[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]],
</span></span><span style=display:flex><span>                        [[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]]]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    quantized_1_list <span style=color:#f92672>=</span> [[[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]],
</span></span><span style=display:flex><span>                        [[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]],
</span></span><span style=display:flex><span>                        [[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>]]]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    quantized_2_list <span style=color:#f92672>=</span> [[[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]],
</span></span><span style=display:flex><span>                        [[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]],
</span></span><span style=display:flex><span>                        [[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>]]]
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    quantized_3_list <span style=color:#f92672>=</span> [[[<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]],
</span></span><span style=display:flex><span>                        [[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>]],
</span></span><span style=display:flex><span>                        [[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>],[<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>]]]    
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    kernel_0 <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>tensor(quantized_0_list, dtype<span style=color:#f92672>=</span>torch<span style=color:#f92672>.</span>float32)
</span></span><span style=display:flex><span>    kernel_1 <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>tensor(quantized_1_list, dtype<span style=color:#f92672>=</span>torch<span style=color:#f92672>.</span>float32)
</span></span><span style=display:flex><span>    kernel_2 <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>tensor(quantized_2_list, dtype<span style=color:#f92672>=</span>torch<span style=color:#f92672>.</span>float32)
</span></span><span style=display:flex><span>    kernel_3 <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>tensor(quantized_3_list, dtype<span style=color:#f92672>=</span>torch<span style=color:#f92672>.</span>float32)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    kernel_direction_quantized <span style=color:#f92672>=</span> [kernel_0,
</span></span><span style=display:flex><span>                                  kernel_1,
</span></span><span style=display:flex><span>                                  kernel_2,
</span></span><span style=display:flex><span>                                  kernel_3]
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>4</span>):
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        mask_i <span style=color:#f92672>=</span> (gradient_direction_quantized <span style=color:#f92672>==</span> i)<span style=color:#f92672>.</span>int()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> verbose:
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>&#34;mask_i: &#34;</span>, mask_i)
</span></span><span style=display:flex><span>        nms_conv_op<span style=color:#f92672>.</span>weight<span style=color:#f92672>.</span>data <span style=color:#f92672>=</span> kernel_direction_quantized[i]<span style=color:#f92672>.</span>reshape((<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>))
</span></span><span style=display:flex><span>        nms_direction_conv_i <span style=color:#f92672>=</span> nms_conv_op(gradient_magnitude)
</span></span><span style=display:flex><span>        nms_direction_conv_mask_i <span style=color:#f92672>=</span> nms_direction_conv_i <span style=color:#f92672>*</span> mask_i
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        nms_direction_conv_mask_max_i, _ <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>max(nms_direction_conv_mask_i, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> verbose:
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>&#34;nms_direction_conv_mask_max_i: &#34;</span>, nms_direction_conv_mask_max_i)
</span></span><span style=display:flex><span>            print(<span style=color:#e6db74>&#34;nms_direction_i: &#34;</span>, nms_direction_conv_mask_max_i)
</span></span><span style=display:flex><span>        nms_edge <span style=color:#f92672>=</span> nms_edge <span style=color:#f92672>+</span> ((gradient_magnitude <span style=color:#f92672>==</span> nms_direction_conv_mask_max_i) <span style=color:#f92672>*</span>
</span></span><span style=display:flex><span>                               nms_direction_conv_mask_max_i) 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> verbose:
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>&#34;nms_edge: &#34;</span>, nms_edge)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># verbose = True</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> verbose:
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>imshow(nms_edge<span style=color:#f92672>.</span>squeeze()<span style=color:#f92672>.</span>detach()<span style=color:#f92672>.</span>numpy(), cmap<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;gray&#39;</span>)
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#34;Non-Maximum Suppression&#34;</span>)
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>show()
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> nms_edge
</span></span></code></pre></div><h2 id=滞后阈值>滞后阈值</h2><p>滞后阈值的目的是为了连接间断点，具有更好的鲁棒性。
例如：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#960050;background-color:#1e0010> </span> <span style=color:#960050;background-color:#1e0010> </span> <span style=color:#75715e># 普通双边阈值处理</span>
</span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010> </span> <span style=color:#960050;background-color:#1e0010> </span> edge_detect <span style=color:#f92672>=</span> threshold(nms_edge, low<span style=color:#f92672>=</span>threshold_low, high<span style=color:#f92672>=</span>threshold_high, weak<span style=color:#f92672>=</span><span style=color:#ae81ff>50</span>, strong<span style=color:#f92672>=</span><span style=color:#ae81ff>255</span>)
</span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010> </span> <span style=color:#960050;background-color:#1e0010> </span> <span style=color:#75715e># 滞后阈值</span>
</span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010> </span> <span style=color:#960050;background-color:#1e0010> </span> edge_detect <span style=color:#f92672>=</span> hysteresis_threshold(nms_edge, low<span style=color:#f92672>=</span>threshold_low, high<span style=color:#f92672>=</span>threshold_high)
</span></span></code></pre></div><p>同样的命令：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-shell data-lang=shell><span style=display:flex><span>python pytorch-canny.py -v -i data/lena.png -gk <span style=color:#ae81ff>0</span> -L <span style=color:#ae81ff>100</span> -H <span style=color:#ae81ff>200</span>
</span></span></code></pre></div><p>使用滞后阈值的结果，普通双边阈值处理的结果分别是：</p><div>    <img src=https://qyzhizi.cn/img/202307041413380.png style=display:inline-block;width:49%>
    <img src=https://qyzhizi.cn/img/202307041638437.png style=display:inline-block;width:49%></div><p>算法步骤：</p><ul><li><code>hysteresis_threshold</code> 输入:<ul><li><code>nms_edge</code> 是一个极大值值抑制后的tensor</li><li><code>low</code> 低阈值</li><li><code>high</code> 高阈值</li></ul></li><li>分类：<ul><li>不考虑低于<code>low</code> 的元素</li><li>高于 <code>high</code> 的元素 记为强边缘，<code>strong_mask</code>记录位置</li><li>大于<code>low</code> 小于 <code>high</code> 的元素记为弱边缘，<code>weak_mask</code>记录位置</li></ul></li><li>将强边缘放入栈中，然后开始循环栈中的元素，先弹出栈中一个元素（强边缘），然后判断周围8个位置中是否存在弱边缘，如果存在，将弱边缘元素入栈，然后将当前元素输出到<code>output_index</code>中，表示该强边缘元素处理结束。另外由于周围8个位置中的弱边缘已经入栈，为了防止重复入栈，将<code>weak_mask</code>对应位置设置为0。直到栈为空。</li><li>最后根据 <code>output_index</code> 中的位置，返回最后的边缘检测图。</li></ul><p>程序：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>hysteresis_threshold</span>(nms_edge: torch<span style=color:#f92672>.</span>tensor, low: int, high: int) <span style=color:#f92672>-&gt;</span> torch<span style=color:#f92672>.</span>tensor:
</span></span><span style=display:flex><span>    nms_edge <span style=color:#f92672>=</span> nms_edge<span style=color:#f92672>.</span>squeeze()
</span></span><span style=display:flex><span>    strong_mask <span style=color:#f92672>=</span> nms_edge <span style=color:#f92672>&gt;=</span> high
</span></span><span style=display:flex><span>    weak_mask <span style=color:#f92672>=</span> (nms_edge <span style=color:#f92672>&gt;</span> low) <span style=color:#f92672>&amp;</span> (nms_edge <span style=color:#f92672>&lt;</span> high)<span style=color:#f92672>.</span>int()
</span></span><span style=display:flex><span>    output_index <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>    <span style=color:#75715e># get strong_mask index</span>
</span></span><span style=display:flex><span>    strong_index <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>nonzero(strong_mask)<span style=color:#f92672>.</span>tolist()
</span></span><span style=display:flex><span>    <span style=color:#75715e># create stack and push strong_index</span>
</span></span><span style=display:flex><span>    stack <span style=color:#f92672>=</span> deque(strong_index)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>while</span> len(stack) <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0</span>:
</span></span><span style=display:flex><span>        <span style=color:#75715e># pop item</span>
</span></span><span style=display:flex><span>        item <span style=color:#f92672>=</span> stack<span style=color:#f92672>.</span>pop()
</span></span><span style=display:flex><span>        <span style=color:#75715e># get item index</span>
</span></span><span style=display:flex><span>        i, j <span style=color:#f92672>=</span> item[<span style=color:#ae81ff>0</span>], item[<span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>        <span style=color:#75715e># get weak_mask index</span>
</span></span><span style=display:flex><span>        local_index <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>nonzero(weak_mask[i<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>:i<span style=color:#f92672>+</span><span style=color:#ae81ff>2</span>, j<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>:j<span style=color:#f92672>+</span><span style=color:#ae81ff>2</span>])<span style=color:#f92672>.</span>tolist()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> local_index_item <span style=color:#f92672>in</span> local_index:
</span></span><span style=display:flex><span>            <span style=color:#75715e># stack.append(weak_index[i])</span>
</span></span><span style=display:flex><span>            weak_index_item <span style=color:#f92672>=</span> [i<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span><span style=color:#f92672>+</span>local_index_item[<span style=color:#ae81ff>0</span>], j<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span><span style=color:#f92672>+</span>local_index_item[<span style=color:#ae81ff>1</span>]]
</span></span><span style=display:flex><span>            stack<span style=color:#f92672>.</span>append(weak_index_item)
</span></span><span style=display:flex><span>            weak_mask[weak_index_item[<span style=color:#ae81ff>0</span>], weak_index_item[<span style=color:#ae81ff>1</span>]] <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>        output_index<span style=color:#f92672>.</span>append(item)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># create output tensor use output_index</span>
</span></span><span style=display:flex><span>    output_index_tensor <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>tensor(output_index)  <span style=color:#75715e># (N, 2) </span>
</span></span><span style=display:flex><span>    output <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>zeros_like(nms_edge)
</span></span><span style=display:flex><span>    output[output_index_tensor[:, <span style=color:#ae81ff>0</span>], output_index_tensor[:, <span style=color:#ae81ff>1</span>]] <span style=color:#f92672>=</span> <span style=color:#ae81ff>255</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> output
</span></span></code></pre></div><h2 id=与opencv-算法对比>与opencv 算法对比</h2><p>opencv canny算法:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> cv2
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> matplotlib <span style=color:#f92672>import</span> pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> time
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;__main__&#39;</span>:
</span></span><span style=display:flex><span>    img <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>imread(<span style=color:#e6db74>&#39;data/lena.png&#39;</span>,<span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>    start_time <span style=color:#f92672>=</span> time<span style=color:#f92672>.</span>time()
</span></span><span style=display:flex><span>    edges <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>Canny(img,<span style=color:#ae81ff>100</span>,<span style=color:#ae81ff>200</span>)
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;time: &#34;</span>, time<span style=color:#f92672>.</span>time() <span style=color:#f92672>-</span> start_time)
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>subplot(<span style=color:#ae81ff>121</span>),plt<span style=color:#f92672>.</span>imshow(img,cmap <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;gray&#39;</span>)
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#39;Original Image&#39;</span>), plt<span style=color:#f92672>.</span>xticks([]), plt<span style=color:#f92672>.</span>yticks([])
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>subplot(<span style=color:#ae81ff>122</span>),plt<span style=color:#f92672>.</span>imshow(edges,cmap <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;gray&#39;</span>)
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#39;Edge Image&#39;</span>), plt<span style=color:#f92672>.</span>xticks([]), plt<span style=color:#f92672>.</span>yticks([])
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>show()
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;end&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 保存图片</span>
</span></span><span style=display:flex><span>    cv2<span style=color:#f92672>.</span>imwrite(<span style=color:#e6db74>&#34;data/opencv_edge_detect.png&#34;</span>, edges)
</span></span></code></pre></div><p>同样的输入图片：
<img src=https://qyzhizi.cn/img/202306291745926.png style=width:200>
opencv 输出与本文pytorch 实现的输出一样：
<img src=https://qyzhizi.cn/img/202307041413380.png style=width:200>
都使用cpu 的情况下，opencv 的处理速度非常快：是本文pytorch 实现的30倍。
本文pytorch 实现需要的时间：time: 0.0885
而opencv 实现需要的时间：time: 0.0030
非常amazing, 竟然慢这么多，笔者还运行过别人
<a href=https://github.com/adeveloperdiary/blog/tree/master/Computer_Vision/Canny_Edge_Detection title=纯python的实现 rel="noopener external nofollow noreferrer" target=_blank class=exturl>纯python的实现
<i class="fa fa-external-link-alt"></i>
</a>，结论是非常慢。</p><h2 id=参考>参考</h2><p><a href=https://github.com/opencv/opencv/blob/2.2/modules/imgproc/src/canny.cpp title=https://github.com/opencv/opencv/blob/2.2/modules/imgproc/src/canny.cpp rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://github.com/opencv/opencv/blob/2.2/modules/imgproc/src/canny.cpp
<i class="fa fa-external-link-alt"></i></a>
<a href=https://github.com/adeveloperdiary/blog/tree/master/Computer_Vision/Canny_Edge_Detection title=https://github.com/adeveloperdiary/blog/tree/master/Computer_Vision/Canny_Edge_Detection rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://github.com/adeveloperdiary/blog/tree/master/Computer_Vision/Canny_Edge_Detection
<i class="fa fa-external-link-alt"></i></a></p></div><footer class=post-footer><div class=post-tags><a href=/tags/opencv>opencv</a>
<a href=/tags/pytorch>pytorch</a>
<a href=/tags/canny>canny</a></div><div class=addthis_inline_share_toolbox style=text-align:center></div><hr><div class=reward-container><div><i class="fa-solid fa-mug-hot"></i>请我喝杯咖啡吧 ヾ(^▽^*)))</div><button>赞赏</button><div class=post-reward></div></div><div class=post-copyright><img src=/imgs/cc/cc.svg width=75 height=75 align=right><ul><li class=post-copyright-title><strong>文章标题：</strong>
PyTorch 实现 Opencv Canny 算法</li><li class=post-copyright-author><strong>原文作者：</strong>
Hollis</li><li class=post-copyright-link><strong>本文链接：</strong>
<a id=post-cr-link href=/pytorch-implement-opencv-canny-algorithm.html title="PyTorch 实现 Opencv Canny 算法">/pytorch-implement-opencv-canny-algorithm.html</a></li><li class=post-copyright-license><strong>版权声明：</strong>
本博客所有文章除特别声明外，均采用 <i class="fab fa-fw fa-creative-commons"></i><a target=_blank href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class=followme><span>欢迎关注我的其它发布渠道</span><div class=social-list><div class=social-item><a target=_blank class=social-link href=/images/wechat_channel.jpg><span class=icon><i class="fab fa-weixin"></i></span>
<span class=label>WeChat</span></a></div><div class=social-item><a target=_blank class=social-link href=/rss.xml><span class=icon><i class="fa fa-rss"></i></span>
<span class=label>RSS</span></a></div></div></div><div class=post-nav><div class="post-nav-next post-nav-item"></div><div class="post-nav-prev post-nav-item"><a href=/opencv-canny-source-code-analysis.html rel=prev title="Opencv Canny 源码解析">Opencv Canny 源码解析
<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div></main><footer class=footer><div class=footer-inner><div id=gtranslate class=google-translate><i class="fa fa-language"></i><div id=google_translate_element></div></div><div class=copyright>&copy;
<span itemprop=copyrightYear>2010 - 2023</span>
<span class=with-love><i class="fa fa-heart"></i></span>
<span class=author itemprop=copyrightHolder>Hollis</span></div></div></footer><script type=text/javascript src=https://cdn.staticfile.org/animejs/3.2.1/anime.min.js defer></script>
<script type=text/javascript src=https://cdn.staticfile.org/viewerjs/1.11.0/viewer.min.js defer></script>
<script class=next-config data-name=main type=application/json>{"bookmark":{"color":"#222","enable":true,"save":"manual"},"copybtn":true,"darkmode":true,"giscus":{"cfg":{"category":"Comments","categoryid":null,"emit":false,"inputposition":"top","mapping":"title","reactions":false,"repo":"username/repo-name","repoid":null,"theme":"preferred_color_scheme"},"js":"https://giscus.app/client.js"},"hostname":"/","i18n":{"ds_day":" 天前","ds_days":" 天 ","ds_hour":" 小时前","ds_hours":" 小时 ","ds_just":"刚刚","ds_min":" 分钟前","ds_mins":" 分钟","ds_month":" 个月前","ds_years":" 年 ","empty":"没有找到任何搜索结果：${query}","hits":"","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","placeholder":"搜索..."},"lang":"zh-CN","lazyload":false,"localSearch":{"enable":true,"path":"/searchindexes.xml","preload":false,"topnperarticle":-1,"trigger":"auto","unescape":false},"motion":{"async":true,"enable":true,"transition":{"collheader":"fadeInLeft","postblock":"fadeIn","postbody":"fadeInDown","postheader":"fadeInDown","sidebar":"fadeInUp"}},"root":"/","scheme":"Gemini","sidebar":{"display":"post","offset":12,"padding":18,"position":"left","width":256},"statis":{"enable":true,"plugin":"busuanzi"},"vendor":{"plugins":"qiniu","router":"https://cdn.staticfile.org"},"version":"4.4.1","waline":{"cfg":{"comment":true,"emoji":false,"imguploader":false,"pageview":true,"placeholder":"请文明发言哟 ヾ(≧▽≦*)o","reaction":true,"reactiontext":["点赞","踩一下","得意","不屑","尴尬","睡觉"],"reactiontitle":"你认为这篇文章怎么样？","requiredmeta":["nick","mail"],"serverurl":"https://walinejs.comment.lithub.cc","sofa":"快来发表你的意见吧 (≧∀≦)ゞ","wordlimit":200},"css":{"alias":"waline","file":"dist/waline.css","name":"@waline/client","version":"2.13.0"},"js":{"alias":"waline","file":"dist/waline.js","name":"@waline/client","version":"2.13.0"}}}</script><script type=text/javascript src=/js/main.min.37028fbafbd97fd89808b4c7b5a3a81f01ed0ab24001d273d774f9546a0e9170.js defer></script></body></html>