<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>转置卷积与卷积的理解</title><url>/post/trans-conv-and-conv.html</url><categories><category>programming</category></categories><tags><tag>转置卷积</tag><tag>卷积</tag><tag>programming</tag></tags><content type="html"><![CDATA[转置卷积与卷积的理解，本文将介绍：
转置卷积含义与矩阵形式 转置卷积的一种简单理解 pytorch 转置卷积参数的理解及其Shape的公式推导 卷积与数学上的卷积，卷积核旋转180度 阅读前提：
理解深度学习中普通卷积的概念与shape的计算公式 了解深度学习框架pytorch卷积api的调用 了解卷积的矩阵运算形式 转置卷积含义与矩阵形式 文档： A guide to convolution arithmetic for deep learning 介绍了转置卷积一个概念：The need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution.
翻译一下就是：一个普通卷积的反向操作，已知一个卷积操作L，它输入是A，输出是B，现在需要将B重新变回具有与A形状线相同的C,并且C与A依然保持一种与卷积操作L相容（一致性）的连接特性。注意：C与B只是形状相同，但是数值一般是不同的。 另外转置卷积的作用：以一个已经编码的layer进行解码，或者将特征图映射到高维空间（or project feature maps to a higher-dimensional space.）
转置卷积也有其他的概念，而转置卷积的名称与使用矩阵运算来计算卷积有关（Convolution as a matrix operation）：
以图2.1所表示的卷积为例。如果将输入和输出从左到右、从上到下展开成向量，那么卷积可以表示为一个稀疏矩阵$C$，其中非零元素是卷积核的元素$W(i,j)$（其中 $i$ 和 $j$ 分别是卷积核的行和列）：
图2.1 展开的卷积核 这个线性运算将输入矩阵展平为一个16维向量$X$，并产生一个4维向量$Z$，之后被重新整形为2×2的输出矩阵。利用这种表示方法，反向传播很容易通过转置$C$来获取；换句话说，误差通过将损失与$C^T$相乘来进行反向传播。该运算以一个4维向量作为输入，并产生一个16维向量作为输出，其连接模式与$C$的构造方式兼容。 值得注意的是，核$W$定义了用于正向和反向传播的矩阵$C$和$C^T$。梯度反向传播的过程中，在计算输入$X$的梯度时，是通过该4维向量$Z$的梯度（也是反向传播过来的）与$C^T$相乘来计算的。
转置卷积是相对原卷积来说的。原卷积的不同卷积方式，对应的转置卷积也是不一样的。转置卷积可以通过普通的卷积来实现。
具体的实现方式参考： A guide to convolution arithmetic for deep learning ，在第4章有详细的介绍。
原卷积如果是No zero padding, unit strides，那么转置卷积将采用full-conv，例如： 图4.1 图4.1 解释： Relationship 8. A convolution described by s = 1, p = 0 and k has an associated transposed convolution described by k′= k, s′= s and p′= k −1 and its output size is o′= i′+ (k −1). 其中i&rsquo; = (i-k+2*p)/s + 1
值得注意：pytorch 的转置卷积默认是full-conv，pytorch 转置卷积将再第3节介绍。
另外的参考：https://zh-v2.d2l.ai/chapter_computer-vision/transposed-conv.html 其中有解释转置卷积的名称由来：抽象来看，给定输入向量$\mathbf{x}$和权重矩阵$W$，卷积的前向传播函数可以通过将其输入与权重矩阵相乘并输出向量$\mathbf{y}=\mathbf{W}\mathbf{x}$来实现。 由于反向传播遵循链式法则和$\nabla_{\mathbf{x}}\mathbf{y}=\mathbf{W}^\top$，卷积的反向传播函数可以通过将其输入与转置的权重矩阵$\mathbf{W}^\top$相乘来实现。 因此，转置卷积层能够交换卷积层的正向传播函数和反向传播函数：它的正向传播和反向传播函数将输入向量分别与$\mathbf{W}^\top$和$\mathbf{W}$相乘。
转置卷积的一种简单理解 文档 https://zh-v2.d2l.ai/chapter_computer-vision/transposed-conv.html 介绍了一种简单的转置卷积理解方式： 输入$i$ 是[[0,1],[2,3]], 转置卷积核也为：[[0,1],[2,3]]（注意：该卷积与pytorch的实现方式不一样，但这是另外一种理解，而且与pytorch的转置卷积api计算结果一致）
图13.10.1 该转置卷积设步幅为1且没有填充。输入张量中的每个元素都要乘以卷积核，然后产生了4个中间结果，然后加起来得到就是转置卷积的结果。 注意：图13.10.1转置卷积对应的原卷积的参数是：stride = 1, padding = 0。这样输出的shape : i' = (i-k+2*padding)/stride + 1 == i-(k-1)，而转置卷积的目的是在形状上将$i&rsquo;$恢复为 $i$ ，且保持卷积的一种一致性。可以用一下代码实现，定义函数trans_conv，输入矩阵$X$和卷积核矩阵$K$实现基本的转置卷积运算：
def trans_conv(X, K): h, w = K.shape Y = torch.zeros((X.shape[0] + h - 1, X.shape[1] + w - 1)) for i in range(X.shape[0]): for j in range(X.shape[1]): Y[i: i + h, j: j + w] += X[i, j] * K return Y X = torch.tensor([[0.0, 1.0], [2.0, 3.0]]) K = torch.tensor([[0.0, 1.0], [2.0, 3.0]]) trans_conv(X, K) 输出：
tensor([[ 0., 0., 1.], [ 0., 4., 6.], [ 4., 12., 9.]]) 当输入X和卷积核K都是四维张量时，我们可以使用高级API(pytorch)获得相同的结果。
X = torch.tensor([[0.0, 1.0], [2.0, 3.0]]) K = torch.tensor([[0.0, 1.0], [2.0, 3.0]]) X, K = X.reshape(1, 1, 2, 2), K.reshape(1, 1, 2, 2) tconv = nn.ConvTranspose2d(1, 1, kernel_size=2, bias=False) tconv.weight.data = K tconv(X) 结果也是一样：
tensor([[[[ 0., 0., 1.], [ 0., 4., 6.], [ 4., 12., 9.]]]], grad_fn=&lt;ConvolutionBackward0&gt;) 更详细的内容，下面两个链接不错： 转置卷积 Transposed Convolutions explained with… MS Excel! pytorch 转置卷积参数的理解及其Shape的公式推导 pytorch 转置卷积 的文档： torch.nn.ConvTranspose2d 另外下面这个文档比较重要，也是本文主要的参考文章 A guide to convolution arithmetic for deep learning pytorch 转置卷积shape的计算公式 pytorch 的转置卷积包含很多参数，它的基本含义是，如果转置卷积使用原卷积相同的参数，那么转置卷积结果的shape与原卷积的输入保持一致, 这个概念很重要。 pytorch 转置卷积的函数签名：
CLASS torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode=&#39;zeros&#39;, device=None, dtype=None) pytorch转置卷积输出的shape是有计算公式的：
$$H_{out} = (H_{in} - 1) \times \text{stride}[0] - 2 \times \text{padding}[0] + \text{dilation}[0]\times (\text{kernel_size}[0] - 1) + \text{output_padding}[0] + 1 $$
$$W_{out} = (W_{in} - 1) \times \text{stride}[1] - 2 \times \text{padding}[1] + \text{dilation}[1] \times (\text{kernel_size}[1] - 1) + \text{output_padding}[1] + 1$$
pytorch 转置卷积 的计算过程 接下来介绍该算式的含义。 为了理解转置卷积，需要结合原卷积来理解，下面一起考虑原卷积和对应的转置卷积：
假设原卷积输入特征图 $H_{in}$= $i$ ，卷积核设置（kernel= $k$ , stride= $s$ , padding= $p$ , dilation= $d$ 等）输出的特征图为 $i&rsquo;$ 。对应的转置卷积，当给一个特征图 $i&rsquo;$, 以及给定相同的卷积核设置（stride=$s$, padding=$p$, dilation= $d$ 等），在pytorch中这个设置将会输出特征图形状 $o_t$ 与特征图 $i$ 一致（值是不保证相同的，值通常也不相同）。
接下来我们分为2步1进行转置卷积操作:
第一步：对输入的特征图 $i&rsquo;$ 进行一些变换，例如：元素之间插入0，特征图周围进行padding，得到新的特征图 $\tilde{i&rsquo;}$ 第二步：在新的特征图上做普通卷积（kernel=$k$, stride=1，dilation=$d$ 等)，得到的结果 $o_t$ 就是转置卷积的结果，就是我们要求的结果。 第一步，对输入的特征图进行一些变换 pytorch 转置卷积有一些重要的默认设置： stride=1, padding=0, dilation=1
其中stride 控制互相关的步幅（原文是：controls the stride for the cross-correlation.）。它对应的是原卷积的stride，例如：原卷积的stride 是2，那么转置卷积的stride也设置2，如图4.6所示。但是转置卷积处理与原卷积不同：在特征图a元素中间隔插入(stride-1)=1 个零元素。这么做的原因是考虑一种原卷积与转置卷积具有某种相同的连接模式， 这个后面再解释。
转置卷积的padding 控制方式与原卷积看似比较奇怪，直接看pytorch的处理方式：不考虑dilation的情况下，dilation 后面再解释，转置卷积paddding计算公式为：(kernel_size - 1) - padding ，例如：转置卷积 kernel_size=3，padding=1, 那么实际的padding为 (3-1)-1 = 1, 注意这里的padding 指的是单边padding的大小。如果考虑两边要乘2。 这里有个规律2 : 当原卷积padding=0时，转置卷积: padding=(kernel_size -1), 这种padding表明转置卷积是一种全卷积(full-convolution), 也称为：full padding。当原卷积是全卷积时，考虑上面转置卷积paddding计算公式，那么转置卷积的padding=0，即: padding=(kernel_size-1) - (kernel_size-1)=0 。当然还有half-padding: 原卷积与转置卷积此时有相同的padding: $\lfloor (k -1)/2 \rfloor$。
转置卷积 padding 的控制方式同样要考虑 dilation 的情况（dilation 参考 2 中 5.1 Dilated convolutions)。转置卷积paddding公式为：dilation * (kernel_size - 1) - padding ，例如：转置卷积 kernel_size=3，padding=1 , dilation=1, 那么实际的padding为 2*(3-1)-1 = 3。直观理解dilation（空洞卷积）就是某种程度上卷积核变大了，那么对应的padding也要变大。才能保证原卷积与转置卷积具有某种相同的连接模式。 注意：dilation * (kernel_size - 1) - padding， 这里padding 是指原卷积的padding, 也就是说pytorch 中输入的参数：strides， padding 都是指原卷积的padding。
第一步：对输入的特征图 $i&rsquo;$ 进行一些变换得到$\tilde{i&rsquo;}$ 就介绍到这里，虽然不止这些，但对理解pytorch的转置卷积输出shape的计算公式差不多够了。由参数strides和padding变换得到$\tilde{i&rsquo;}$大小为：$$H_{\tilde{i&rsquo;}}= i&rsquo; + (i&rsquo;-1) * (s-1) + 2[d*(k-1)-p]$$
转置卷积、padding 之所以这样处理是有原因的2，原卷积与转置卷积具有某种相同的连接模式的直观理解： One way to understand the logic behind zero padding is to consider the connectivity pattern of the transposed convolution and use it to guide the design of the equivalent convolution. For example, the top left pixel of the input of the direct convolution only contribute to the top left pixel of the output, the top right pixel is only connected to the top right output pixel, and so on.
To maintain the same connectivity pattern in the equivalent convolution it is necessary to zero pad the input in such a way that the first (top-left) application of the kernel only touches the top-left pixel, i.e., the padding has to be equal to the size of the kernel minus one. 翻译一下就是：理解零填充背后的逻辑的一种方法是考虑反卷积的连接模式，并使用它来指导等价的卷积（转置卷积实际的实现方式）设计。例如，直接卷积输入的左上角像素仅对输出的左上角像素有贡献，右上角像素仅连接到右上角输出像素，依此类推。以图4.1为例，为了在等价卷积（转置卷积实际的实现方式）中保持相同的连接模式，需要以零填充输入，使得核的第一次（左上角）卷积仅接触左上角像素，即填充必须等于核大小减一（仅仅是图4.1的情况，）。 例如： 图4.12是一个转置卷积的例子，原卷积是：3*3 kernel over a 4*4 input using unit strides(i.e., i = 4, k=3, s=1 and p=0), 转置卷积的等价卷积是：3*3 kernel over a 2*2 input , padding=2, strides = 1. (i.e., i'=2, k'=k=3, s'=1, and p'= 2 = (k-1) - p
总的来说，输入的特征图 $i&rsquo;$ 进行一些变换之所以要这样处理(stride 、padding等)是为了保持同样的连接性：这是指从A到B（AB分别表示卷积前和卷积后的特征图），如果A中一个位置与B中一个位置通过kernel有关系，那么在卷积核逆卷积中有相同的连通。1
另外一个例子： 图4.62
第二步，对变换得到特征图进行普通的卷积 第二步思路比较简单，对变换得到$\tilde{i&rsquo;}$ 进行普通的卷积，kernel = k, strides=1, padding=0， dilation=d, 由于考虑dialation, 等效的卷积核（感受野）大小为：$k+(k-1)(d-1)$ 由第一步可知：由参数strides和padding变换得到特征图$\tilde{i&rsquo;}$大小为：$$H_{\tilde{i&rsquo;}}= i&rsquo; + (i&rsquo;-1) * (s-1) + 2[d(k-1)-p]$$ 转置卷积shape计算：$o_t=\frac{H_{i&rsquo;} - [k+(k-1)(d-1)]}{1} + 1$ 公式化简一下就是：$o_t=(i&rsquo;-1)s -2p + d(k-1) +1$ 但是pytorch 的计算公式是：$$H_{out} = (H_{in} - 1) \times \text{stride}[0] - 2 \times \text{padding}[0] + \text{dilation}[0]\times (\text{kernel_size}[0] - 1) + \text{output_padding}[0] + 1 $$ 对比一下发现少了一项：$\text{output_padding}[0]$ $\text{output_padding}[0]$ 这一项是为了解决转置卷积同一个 $i&rsquo;$ 对应多个 $i$ 的问题，即原卷积的输出$i&rsquo;$ 可能因为不同的strides、padding设置而对应多个不同shape的 $i$ , 这时候需要添加额外的参数$\text{output_padding}[0]$使得转置卷积还原为一个特定的 $i$ 的形状，它的操作是单边补零的，pytorch 参数解释：Additional size added to one side of each dimension in the output shape. Default: 0。
例如： 于是加上$\text{output_padding}$的转置卷积shape计算公式：$o_t=(i&rsquo;-1)s -2p + d*(k-1) +\text{output_padding} +1$ 。它与pytorch 的给出的公式一致。
参考： 转置卷积 Transposed Convolutions explained with… MS Excel! 卷积与数学上的卷积 pytorch 的转置卷积的核旋转了180度 将第一节（转置卷积的直观理解）与第二节（pytorch 转置卷积参数的理解，以及转置卷积Shape的公式推导）进行对比，你会发现这里两种操作完全不同，但是得到了相同的结果。这其中必然有某种联系。 还是考虑第一节的例子： 图13.10.1 采用pytorch 的做法，第一步先将输入$i&rsquo;$ （转置卷积的输入，另外$i$表示的是原卷积的输入）进行变换，假设原卷积的参数是：kernel = 2, strides = 1，padding=0。 strides =1, 输入$i&rsquo;$ 元素之间不需要插入0 padding=0, 实际的padding = (k-1)-p = (2-1)-0 = 1 那么变换后的 $\tilde{i&rsquo;}$ （转置卷积的输出）： $$\begin{bmatrix} 0&amp;0&amp;0&amp;0\ 0&amp;0&amp;1&amp;0 \ 0&amp;2&amp;3&amp;0 \ 0&amp;0&amp;0&amp;0\ \end{bmatrix} $$ 然后进行第二步：对变换后的 $\tilde{i&rsquo;}$ 进行普通的卷积：k=2, s=1, p=0 k =[[0,1],[2,3]] 看起来不复杂，可以直接手算，得到卷积的结果：$o_1$ = [[0,3,2],[6,14, 6],[2,3,0]]，这与图13.10.1的输出完全不同。 但是你如果用pytorch的转置卷积api 算一下，又会发现结果与13.10.1的输出完全一致。例如：
X = torch.tensor([[0.0, 1.0], [2.0, 3.0]]) K = torch.tensor([[0.0, 1.0], [2.0, 3.0]]) X, K = X.reshape(1, 1, 2, 2), K.reshape(1, 1, 2, 2) tconv = nn.ConvTranspose2d(1, 1, kernel_size=2, bias=False) tconv.weight.data = K tconv(X) 输出： tensor([[[[ 0., 0., 1.], [ 0., 4., 6.], [ 4., 12., 9.]]]], grad_fn=&lt;ConvolutionBackward0&gt;) 那么是哪里出了问题呢？ 问题在第二步，对变换后的 $\tilde{i&rsquo;}$ 进行普通的卷积时，卷积核需要旋转180度。新的卷积核是： k_new = [[3.0, 2.0], [1.0, 0.0]], 对变换后的 $\tilde{i&rsquo;}$ 进行普通的卷积（k=2, s=1, p=0）。结果是：$o_2$ = [[0,0,1],[0,4, 6],[4,12,9]] 这就与pytorch的计算一致了。 这里用pytorch Conv2d (普通卷积api) 进行了验证：
import torch from torch import nn X = torch.tensor([[0.0, 1.0], [2.0, 3.0]]) K = torch.tensor([[0.0, 1.0], [2.0, 3.0]]) T_K = torch.tensor([[3.0, 2.0], [1.0, 0.0]]) X, K, T_K = X.reshape(1, 1, 2, 2), K.reshape(1, 1, 2, 2), T_K.reshape(1, 1, 2, 2) def nn_conv2d(im, kernel): # 用nn.Conv2d定义卷积操作 conv_op = nn.Conv2d(1, 1, kernel_size=2, stride=1, padding=1, bias=False) # 给卷积操作的卷积核赋值 conv_op.weight.data = kernel # 对图像进行卷积操作 conv_res = conv_op(im) return conv_res res = nn_conv2d(X, K) print(res) res2 = nn_conv2d(X, T_K) print(res2) 结果是：
tensor([[[[ 0., 3., 2.], [ 6., 14., 6.], [ 2., 3., 0.]]]], grad_fn=&lt;ConvolutionBackward0&gt;) tensor([[[[ 0., 0., 1.], [ 0., 4., 6.], [ 4., 12., 9.]]]], grad_fn=&lt;ConvolutionBackward0&gt;) 可以看到nn_conv2d(X, T_K)函数输出了正确结果，这说明nn.Conv2d 没有对卷积核进行180度旋转，但是转置卷积nn.ConvTranspose2d对卷积核进行180度旋转。
旋转卷积核后与第一节中的计算结果保持一致，第一节中的计算简单描述就是：每个元素直接与卷积核相乘，然后将所有的中间结果进行叠加。当然这种操作还涉及到strides大于1的情况3,这里就不解释了。
数学上定义的卷积 其实原本数学上的卷积就是要将卷积核进行旋转180度，数学上的卷积与图13.10.1 的操作应该存在着联系。即：图13.10.1 的操作 与使用翻转180度的[[0,1],[2,3]]对 $\tilde{i&rsquo;}$ 进行卷积是等价的。 这种联系不打算深究。接下来本文打算给出一些直观的例子。
在此之前先解释一下数学上的卷积是怎么回事。
在数学上，连续形式的卷积定义如下：
设 $f(x)$ 和 $g(x)$ 是在实数域上的两个可积函数，定义它们的卷积 $h(x)$ 为：
$h(x) = (f*g)(x) = \int_{-\infty}^{\infty} f(\tau)g(x-\tau) d\tau$
其中，$*$ 表示卷积操作，$h(x)$ 表示卷积的输出，$f(x)$ 和 $g(x)$ 分别表示卷积的输入函数，$\tau$ 是积分变量。
卷积的计算过程可以理解为将 $f(x)$ 和 $g(x)$ 进行平移、翻转、相乘和积分的过程。具体来说，对于 $g(\tau)$，首先将其进行翻转得到 $g(-\tau)$，然后将其在 $x$ 轴上平移 $x$ 个单位得到 $g(x-\tau)$，然后再与 $f(\tau)$ 相乘，并对 $\tau$ 进行积分，最终得到卷积的输出 $h(x)$。
图像的卷积是离散形式，离散形式的卷积定义如下：
设 $f[n]$ 和 $g[n]$ 是在整数域上的两个离散序列，定义它们的卷积 $h[n]$ 为：
$h[n] = (f*g)[n] = \sum_{m=-\infty}^{\infty} f[m]g[n-m]$
离散形式与连续形式类似，当确定一个n后，计算 $\sum_{m=-\infty}^{\infty} f[m]g[n-m]$ 时，不是积分而是求和。如果与图像的卷积类别。每个n 对应卷积核的一次平移，计算$\sum_{m=-\infty}^{\infty} f[m]g[n-m]$对应一次将卷积核旋转180度然后对应元素直接进行相乘求和。
卷积可以用概括为：翻转、平移、相乘再求和 先对g函数进行翻转，相当于在数轴上把g函数从右边褶到左边去，也就是卷积的“卷”的由来。 然后再把g函数平移到n，在这个位置对两个函数的对应点相乘，然后相加，这个过程是卷积的“积”的过程。4 例如： 更具体的例子可看 如何通俗易懂地解释卷积？ - palet的回答 - 知乎 中的信号分析、丢骰子与图像处理的例子。
多项式系数卷积与意义 接下来是一个一维矩阵的卷积，希望有更直观数学意义5，这里只是给出一种直观的感觉，不解释这么做的原因，因为笔者也不太清楚。
考虑两个多项式函数： $y=3x+2$ $y=2x^2+3x-1$ 将这两个函数相乘：$y=(3x+2)(2x^2+3x-1)= 6x^2+13x+3x-2$ 可以将这两个函数的系数按x的阶数从大到小考虑为两个矩阵，然后进行卷积： $y=3x+2$ 的系数矩阵：i=[3,2] $y=2x^2+3x-1$ 的系数矩阵：K=[2, 3, -1]，当成卷积核。旋转180度后卷积核：T_K=[-1, 3, 2]
将两个矩阵进行卷积：
首先将系数矩阵[3,2] 进行padding: [0,0,3,2,0,0], padding= 2 = kernel_size -1 = 3 - 1。 移动卷积核：T_K=[-1, 3, 2]进行计算： 例如： 0 0 3 2 0 0 -1 3 2 0 0 3 2 0 0 -1 3 2 0 0 3 2 0 0 -1 3 2 0 0 3 2 0 0 -1 3 2 最后结果是：[2*3, 3*3+2*2, 2*3-1*3, -1*2] = [6, 13, 3, 2] 恰好是$6x^2+13x+3x-2$ 的系数。感觉翻转180度进行卷积与多项式的计算有关联，计算的结果是有意义的，这些系数是$x^n$的系数，或者说是某种特征的系数。
另外考虑另外一种实现方式，类似于图13.10.1，也类似于$y=(3x+2)(2x^2+3x-1)= 6x^2+13x+3x-2$的化简过程： 将矩阵：i=[3,2]的每个元素与系数矩阵：K=[2, 3, -1]相乘，例如： [3]*[2,3,-1] -&gt; [6, 9, -3] [2]*[2,3,-1] -&gt; [4, 6, -2]
然后将这两个中间结果矩阵按下面的形式相加，最后也得到了同样的系数。
6 9 -3 4 6 -2 6 13 3 -2 思考：这里的中间结果相加对齐了两个元素（考虑$x^n$的合并)，而图13.10.1 中间结果只是对齐了一个元素，这是为什么？可能与卷积核的大小有关，如果卷积核是4x4 那么中间结果相加是不是要对齐3个元素？
参考： 如何通俗易懂地解释卷积？ - palet的回答 - 知乎 https://blog.csdn.net/qq_27261889/article/details/86304061 &#160;&#x21a9;&#xfe0e;&#160;&#x21a9;&#xfe0e;
A guide to convolution arithmetic for deep learning &#160;&#x21a9;&#xfe0e;&#160;&#x21a9;&#xfe0e;&#160;&#x21a9;&#xfe0e;&#160;&#x21a9;&#xfe0e;&#160;&#x21a9;&#xfe0e;
Transposed Convolutions explained with… MS Excel! &#160;&#x21a9;&#xfe0e;
如何通俗易懂地解释卷积？ - palet的回答 - 知乎 &#160;&#x21a9;&#xfe0e;
理解卷积的数学意义 卷积分 &#160;&#x21a9;&#xfe0e;
]]></content></entry><entry><title>Handwriting Dl Framework</title><url>/handwriting-dl-framework.html</url><categories><category><no value=/></categories><tags><tag>DL</tag><tag>code</tag><tag>algorithm</tag></tags><content type="html"><![CDATA[主要程序 general_neural_network_framework.py github 仓库 计算图的建立 在基类Node中 初始化中 self.inputs 与self.outputs 记录了节点之间的关系，以此将计算图建立好。
class Node: &#34;&#34;&#34; 我们把这个Node类作为这个神经网络的基础模块 &#34;&#34;&#34; def __init__(self,inputs=[],name=None,is_trainable=False): self.inputs = inputs #这个节点的输入，输入的是Node组成的列表 self.outputs = [] #这个节点的输出节点 self.name = name self.is_trainable = is_trainable for n in self.inputs: n.outputs.append(self) #这个节点正好对应了这个输人的输出节点，从而建立了连接关系 self.value = None #每个节点必定对应有一个值 self.gradients = {} #每个节点对上个节点的梯度， def forward(self): &#34;&#34;&#34; 先预留一个方法接口不实现，在其子类中实现,且要求其子类一定要实现，不实现的时话会报错。 &#34;&#34;&#34; raise NotImplemented def backward(self): raise NotImplemented def __repr__(self): return &#34;Node:{}&#34;.format(self.name) 拓扑排序 拓扑排序的目的是，获得一个排好顺序的节点列表. 前向计算一个节点的输出值时，保证这个节点的输入值已经计算好了，换句话说，与这个节点相连的父节点已经算好值了。 同样反向传播时，将拓扑排序好的列表进行倒序计算，在计算一个节点的梯度，保证该节点的子节点已经算好梯度了。
下面是个简单的例子：
# Write a topological sort algorithm def topological_sort(graph): visited = set() stack = [] def dfs(node): if node in visited: return visited.add(node) for neighbor in graph[node]: dfs(neighbor) stack.append(node) for node in graph: dfs(node) # stack.reverse() return stack[::-1] # 拓扑排序的输入是一个有向无环图，输出是一个序列，该序列满足：如果图中存在一条从节点 A 到节点 B 的路径，那么在序列中节点 A 出现在节点 B 的前面。 graph = {&#34;a&#34;: [&#34;b&#34;, &#34;c&#34;], &#34;b&#34;: [&#34;d&#34;], &#34;c&#34;: [&#34;d&#34;], &#34;d&#34;: []} print(topological_sort(graph)) 输入：
输出结果是：
[&#39;a&#39;, &#39;c&#39;, &#39;b&#39;, &#39;d&#39;] 前向计算与梯度反向传播 将计算图进行拓扑排序后，按照排序后的顺序调用每个节点的forward进行前向计算，然后在反向传播的时候调用backward 进行梯度更新。 多维度的前向计算与反向传播 是采用矩阵运算的形式进行运算的。
包的发布 https://blog.csdn.net/qq_43790749/article/details/112134520 参考 https://blog.csdn.net/qq_43790749/article/details/112130630 ]]></content></entry><entry><title>vscode远程调试docker中的python服务</title><url>/post/vscode-remote-debugging-python-service.html</url><categories><category>programming</category></categories><tags><tag>vscode</tag><tag>python</tag></tags><content type="html"><![CDATA[vscode远程调试docker中的python服务
环境：windows Docker Desktop , Vscode
阅读前，默认你对以下内容有基本了解：docker-compose.yml, Dockerfile, Vscode python 调试配置, flask 服务
原本想使用python pdb来调试，但是在容器环境中使用pdb，需要直接在容器终端中启动python程序，不方便 然后找到一个远程调试工具：debugpy，它将在容器中运行，等待vscode的连接（可配置等待模式），然后启动python程序。 配置好后就可以在vscode中调试容器中的python程序了。
远程调试flask服务 在docker 中调试flask服务时不要开启debug模式
例如：
if __name__ == &#39;__main__&#39;: # 本机访问：http://127.0.0.1:5000/ app.run(host=&#34;0.0.0.0&#34;, port=5000, debug=False) 原因是，开启debug后意味着开启了flask的重新加载机制，由于使用debugpy远程调试的某种原因，flask的重载机制触发了，这会导致Python 会创建一个新的进程来运行新的代码。但是,原来的进程还在监听 debug 调试端口,所以当新进程尝试绑定同一个端口时会报 &ldquo;Address already in use&rdquo; 错误。
远程调试flask服务时，Dockerfile的示例 Dockerfile
# Use the Python 3.10 image as the base image FROM python:3.10 # Keeps Python from generating .pyc files in the container ENV PYTHONDONTWRITEBYTECODE=1 # Turns off buffering for easier container logging ENV PYTHONUNBUFFERED=1 # Set the working directory to /app WORKDIR /app # Copy all files in the current directory to /app COPY . /app # Dependencies required by the installation script RUN pip install -r requirements.txt -i https://mirrors.cloud.tencent.com/pypi/simple # Expose the port of the container EXPOSE 5000 EXPOSE 5678 # run script CMD [&#34;python&#34;, &#34;server.py&#34;] 远程调试flask服务时，docker-compose.debug.yml 配置 这里使用的是docker-compose.debug.yml，是为了区别于docker-compose.yml
启动docker-compose.debug.yml的方式是：docker-compose -f docker-compose.debug.yml up
version: &#34;3.9&#34; services: pic_server: build: ./ # tty: true # stdin_open: true # image: web_dl-main_server:latest ports: - &#34;5000:5000&#34; - &#34;5678:5678&#34; restart: always volumes: - &#34;.:/app&#34; command: [&#34;python&#34;, &#34;-m&#34;, &#34;debugpy&#34;, &#34;--listen&#34;, &#34;0.0.0.0:5678&#34;, &#34;--wait-for-client&#34;, &#34;server.py&#34;] 容器启动后，会自动执行command的设置的命令
这个命令会覆盖Dockerfile中的CMD命令，例如会覆盖Dockerfile原来的命令：CMD [&quot;python&quot;, &quot;server.py&quot;]
远程调试flask服务时，vscode 的调试客户端配置 .vscode\launch.json 见后文：vscode 的调试客户端配置
调试我的web-dl服务 web-dl service github address: https://github.com/qyzhizi/web_dl docker-compose.debug.yml 配置 这里使用的是docker-compose.debug.yml，是为了区别于docker-compose.yml
启动docker-compose.debug.yml的方式是：docker-compose -f docker-compose.debug.yml up
docker-compose.debug.yml的内容是：
version: &#34;3.9&#34; services: main_server: depends_on: - redis build: ./ env_file: - .env ports: - &#34;9000:9000&#34; - &#34;5678:5678&#34; restart: always volumes: - &#34;.:/app&#34; command: &gt; sh -c &#34;python web_dl/cmd/celery_work &gt; celery_work.log 2&gt;&amp;1 &amp; python -m debugpy --listen 0.0.0.0:5678 --wait-for-client web_dl/cmd/main&#34; redis: image: &#34;redis/redis-stack-server:latest&#34; 容器启动后，会自动执行command的设置的命令
command: &gt; sh -c &#34;python web_dl/cmd/celery_work &gt; celery_work.log 2&gt;&amp;1 &amp; python -m debugpy --listen 0.0.0.0:5678 --wait-for-client web_dl/cmd/main&#34; 这个命令会覆盖Dockerfile中的CMD命令，例如会覆盖Dockerfile原来的命令：CMD [&quot;bash&quot;, &quot;-c&quot;, &quot;web_dl/cmd/run.sh&quot;]
第一个命令：python web_dl/cmd/celery_work &gt; celery_work.log 2&gt;&amp;1 &amp;，它是在后台执行一个python脚本web_dl/cmd/celery_work,最后的&amp;表示后台执行 这里一定要后台执行，因为这个脚本不会终止。否者第二个命令就无法被终端执行，而是一直等第一个命令执行结束。
第二个命令：python -m debugpy --listen 0.0.0.0:5678 --wait-for-client web_dl/cmd/main&quot;, 它是启动docker远端调试服务的关键，python 启动debugpy， 并且监听0.0.0.0:5678, --wait-for-client表示等待客户端的连接接（docker这边启动的是服务端），客户端本文采用的vscode的python调试模块（后文再介绍相关配置）。
最后启动python 脚本web_dl/cmd/main，这个脚本是python web服务的入口点。
vscode 的调试客户端配置 安装python 扩展插件 打开vscode的调试界面，如果你之前没有创建过launch.json, 那就选择创建launch.json 文件，然后选择调试器Docker: Debug in Container,然后生成一个文件launch.json 接下来配置这个launch.json,如下：
{ // Use IntelliSense to understand related attributes。 // Hover to see descriptions of existing properties。 // For more information, please visit: https://go.microsoft.com/fwlink/?linkid=830387 &#34;version&#34;: &#34;0.2.0&#34;, &#34;configurations&#34;: [ { &#34;name&#34;: &#34;Python: remote attach&#34;, &#34;type&#34;: &#34;python&#34;, &#34;request&#34;: &#34;attach&#34;, &#34;connect&#34;: { &#34;host&#34;: &#34;localhost&#34;, &#34;port&#34;: 5678 }, &#34;pathMappings&#34;: [ { &#34;localRoot&#34;: &#34;${workspaceFolder}&#34;, &#34;remoteRoot&#34;: &#34;/app&#34; } ], &#34;justMyCode&#34;: true } ] } 其中：
&#34;connect&#34;: { &#34;host&#34;: &#34;localhost&#34;, &#34;port&#34;: 5678 }, 这个表示连接到本地的5678端口，因为调试的服务端是本地， 如果你的docker服务在其他地方，比如云端，那么这里需要填写机器的ip地址，可能还会有密码需要配置， 目前笔者还没有试过远程连接docker服务，先就不管了。 &quot;justMyCode&quot;: true 表示只是调试你写的代码，第三方库的代码就不调试了，这里笔者也没有试过，先记录一下。
另外：
&#34;pathMappings&#34;: [ { &#34;localRoot&#34;: &#34;${workspaceFolder}&#34;, &#34;remoteRoot&#34;: &#34;/app&#34; } ], 这个表示本地代码到docker容器的代码映射，因为在Dockerfile中，代码的根目录是/app,所以&quot;remoteRoot&quot;: &quot;/app&quot; ${workspaceFolder}表示vscode的工作目录，这里是把当前工作目录与容器的/app进行映射。 之所以要做映射，是因为在调试时，可以准确找到对应的代码。
参考 https://blog.hipolabs.com/remote-debugging-with-vscode-docker-and-pico-fde11f0e5f1c https://github.com/Microsoft/ptvsd/issues/1131 ]]></content></entry><entry><title>没有H1-6标题头和评论的文章</title><url>/post/no-header-title.html</url><categories><category>示例</category></categories><tags><tag>toc</tag><tag>标题</tag></tags><content type="html">刘慈欣2018克拉克奖获奖感言（部分内容节选）。
用于测试在没有H1-6标题头时，文章的目录导航是否会直接关闭，并关闭评论功能。
先生们、女士们，晚上好，
很荣幸获得Clarke Award for Imagination in Service to Society Award。
这个奖项是对想象力的奖励，而想象力是人类所拥有的一种似乎只应属于神的能力，它存在的意义也远超出我们的想象。有历史学家说过，人类之所以能够超越地球上的其它物种建立文明，主要是因为他们能够在自己的大脑中创造出现实中不存在的东西。在未来，当人工智能拥有超过人类的智力时，想象力也许是我们对于它们所拥有的惟一优势。
科幻小说是基于想象力的文学，而最早给我留下深刻印象的是Arthur . Clarke的作品。除了Jules Verne和George Wells外，Clarke的作品是最早进入中国的西方现代科幻小说。在上世纪八十年代初，中国出版了他的《2001:A Space Odyssey》和《Rendezvous With Rama》。当时文革刚刚结束，旧的生活和信仰已经崩塌，新的还没有建立起来，我和其他年轻人一样，心中一片迷茫。这两本书第一次激活了我想象力，思想豁然开阔许多，有小溪流进大海的感觉。读完《2001:A Space Odyssey》的那天深夜，我走出家门仰望星空，那时的中国的天空还没有太多的污染，能够看到银河，在我的眼中，星空与过去完全不一样了，我第一次对宇宙的宏大与神秘产生了敬畏感，这是一种宗教般的感觉。而后来读到的《Rendezvous With Rama》，也让我惊叹如何可以用想象力构造一个栩栩如生的想象世界。正是Clarke带给我的这些感受，让我后来成为一名科幻作家。
现在，三十多年过去了，我渐渐发现，我们这一代在上世纪六十年代出生于中国的人，很可能是人类历史上最幸运的人，因为之前没有任何一代人，像我们这样目睹周围的世界发生了如此巨大的变化，我们现在生活的世界，与我们童年的世界已经完全是两个不同的世界，而这种变化还在加速发生着。中国是一个充满着未来感的国度，中国的未来可能充满着挑战和危机，但从来没有像现在这样具有吸引力，这就给科幻小说提供了肥沃的土壤，使其在中国受到了空前的关注，作为一个在六十年代出生在中国的科幻小说家，则是幸运中的幸运。
我期待有那么一天，像那些曾经描写过信息时代的科幻小说一样，描写太空航行的科幻小说也变的平淡无奇了，那时的火星和小行星带都是乏味的地方，有无数的人在那里谋生；木星和它众多的卫星已成为旅游胜地，阻止人们去那里的唯一障碍就是昂贵的价格。
但即使在这个时候，宇宙仍是一个大的无法想象的存在，距我们最近的恒星仍然遥不可及。浩瀚的星空永远能够承载我们无穷的想象力。
谢谢大家。
点击阅读全文</content></entry><entry><title>Mermaid支持流程图</title><url>/post/mermaid-charts.html</url><categories><category>示例</category></categories><tags><tag>流程图</tag><tag>时序图</tag></tags><content type="html"><![CDATA[本主题已支持 Mermaid 实现以纯文本的方式绘制流程图、序列图、甘特图、状态图、关系图行等等，随着 Mermaid 也在逐步发展，后续还会有各种各样的图被引入进来，更多的类型及使用方式可关注其官方网站： https://mermaid-js.github.io/ 。
使用说明 通过 hugo new 命令创建一篇新的文章 在文章头部配置 mermaid: true 使用短代码书写各种类型的图，自带2个参数： align（对齐） 和 bc（背景色），可参考如下使用示例 流程图 {{&lt; mermaid align=&#34;left&#34; &gt;}} graph TD; A--&gt;B; A--&gt;C; B--&gt;D; C--&gt;D; {{&lt; /mermaid &gt;}} graph TD; A-->B; A-->C; B-->D; C-->D; 时序图 {{&lt; mermaid bc=&#34;#eee&#34; &gt;}} sequenceDiagram participant Alice participant Bob Alice-&gt;&gt;John: Hello John, how are you? loop Healthcheck John-&gt;&gt;John: Fight against hypochondria end Note right of John: Rational thoughts &lt;br/&gt;prevail! John--&gt;&gt;Alice: Great! John-&gt;&gt;Bob: How about you? Bob--&gt;&gt;John: Jolly good! {{&lt; /mermaid &gt;}} sequenceDiagram participant Alice participant Bob Alice->>John: Hello John, how are you? loop Healthcheck John->>John: Fight against hypochondria end Note right of John: Rational thoughts prevail! John-->>Alice: Great! John->>Bob: How about you? Bob-->>John: Jolly good! 类图 {{&lt; mermaid &gt;}} classDiagram Class01 &lt;|-- AveryLongClass : Cool Class03 *-- Class04 Class05 o-- Class06 Class07 .. Class08 Class09 --&gt; C2 : Where am i? Class09 --* C3 Class09 --|&gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla Class08 &lt;--&gt; C2: Cool label {{&lt; /mermaid &gt;}} classDiagram Class01 <|-- AveryLongClass : Cool Class03 *-- Class04 Class05 o-- Class06 Class07 .. Class08 Class09 --> C2 : Where am i? Class09 --* C3 Class09 --|> Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla Class08 <--> C2: Cool label 甘特图 {{&lt; mermaid &gt;}} gantt dateFormat YYYY-MM-DD title Adding GANTT diagram to mermaid excludes weekdays 2014-01-10 section A section Completed task :done, des1, 2014-01-06,2014-01-08 Active task :active, des2, 2014-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d {{&lt; /mermaid &gt;}} gantt dateFormat YYYY-MM-DD title Adding GANTT diagram to mermaid excludes weekdays 2014-01-10 section A section Completed task :done, des1, 2014-01-06,2014-01-08 Active task :active, des2, 2014-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d 实体关系图 {{&lt; mermaid &gt;}} erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses {{&lt; /mermaid &gt;}} erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses 用户旅程 {{&lt; mermaid &gt;}} journey title My working day section Go to work Make tea: 5: Me Go upstairs: 3: Me Do work: 1: Me, Cat section Go home Go downstairs: 5: Me Sit down: 5: Me {{&lt; /mermaid &gt;}} journey title My working day section Go to work Make tea: 5: Me Go upstairs: 3: Me Do work: 1: Me, Cat section Go home Go downstairs: 5: Me Sit down: 5: Me ]]></content></entry><entry><title>数学公式渲染</title><url>/post/math-formula.html</url><categories><category>示例</category></categories><tags><tag>数学公式</tag><tag>mathjax</tag><tag>katex</tag></tags><content type="html"><![CDATA[本主题支持 mathjax 和 katex 两种不的方案支持数学公式的渲染，可根据自已的需求进行选择。
接下的示例中，将使用 MathJax 方案来展示渲染效果。
使用 hugo new 命令创建一篇新的文章 可以全局启用数据公式渲染，请在项目配置参数 math: katex 或 math: mathjax 或是将该参数配置到需要显示数学公式的页面头部（减少不必要的加载消耗） 注意： 使用 支持的TeX功能 的联机参考资料。
例子 重复的分数 $$ \frac{1}{\Bigl(\sqrt{\phi \sqrt{5}}-\phi\Bigr) e^{\frac25 \pi}} \equiv 1+\frac{e^{-2\pi}} {1+\frac{e^{-4\pi}} {1+\frac{e^{-6\pi}} {1+\frac{e^{-8\pi}} {1+\cdots} } } } $$
总和记号 $$ \left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right) $$
几何级数之和 我把接下来的两个例子分成了几行，这样它在手机上表现得更好。这就是为什么它们包含 \displaystyle。
$$ \displaystyle\sum_{i=1}^{k+1}i $$
$$ \displaystyle= \left(\sum_{i=1}^{k}i\right) +(k+1) $$
$$ \displaystyle= \frac{k(k+1)}{2}+k+1 $$
$$ \displaystyle= \frac{k(k+1)+2(k+1)}{2} $$
$$ \displaystyle= \frac{(k+1)(k+2)}{2} $$
$$ \displaystyle= \frac{(k+1)((k+1)+1)}{2} $$
乘记号 $$ \displaystyle 1 + \frac{q^2}{(1-q)}+\frac{q^6}{(1-q)(1-q^2)}+\cdots = \displaystyle \prod_{j=0}^{\infty}\frac{1}{(1-q^{5j+2})(1-q^{5j+3})}, \displaystyle\text{ for }\lvert q\rvert &lt; 1. $$
随文数式 这是一些线性数学: $$ k_{n+1} = n^2 + k_n^2 - k_{n-1} $$ ， 然后是更多的文本。
希腊字母 $$ \Gamma\ \Delta\ \Theta\ \Lambda\ \Xi\ \Pi\ \Sigma\ \Upsilon\ \Phi\ \Psi\ \Omega \alpha\ \beta\ \gamma\ \delta\ \epsilon\ \zeta\ \eta\ \theta\ \iota\ \kappa\ \lambda\ \mu\ \nu\ \xi \ \omicron\ \pi\ \rho\ \sigma\ \tau\ \upsilon\ \phi\ \chi\ \psi\ \omega\ \varepsilon\ \vartheta\ \varpi\ \varrho\ \varsigma\ \varphi $$
箭头 $$ \gets\ \to\ \leftarrow\ \rightarrow\ \uparrow\ \Uparrow\ \downarrow\ \Downarrow\ \updownarrow\ \Updownarrow $$
$$ \Leftarrow\ \Rightarrow\ \leftrightarrow\ \Leftrightarrow\ \mapsto\ \hookleftarrow \leftharpoonup\ \leftharpoondown\ \rightleftharpoons\ \longleftarrow\ \Longleftarrow\ \longrightarrow $$
$$ \Longrightarrow\ \longleftrightarrow\ \Longleftrightarrow\ \longmapsto\ \hookrightarrow\ \rightharpoonup $$
$$ \rightharpoondown\ \leadsto\ \nearrow\ \searrow\ \swarrow\ \nwarrow $$
符号 $$ \surd\ \barwedge\ \veebar\ \odot\ \oplus\ \otimes\ \oslash\ \circledcirc\ \boxdot\ \bigtriangleup $$
$$ \bigtriangledown\ \dagger\ \diamond\ \star\ \triangleleft\ \triangleright\ \angle\ \infty\ \prime\ \triangle $$
微积分学 $$ \int u \frac{dv}{dx},dx=uv-\int \frac{du}{dx}v,dx $$
$$ f(x) = \int_{-\infty}^\infty \hat f(\xi),e^{2 \pi i \xi x} $$
$$ \oint \vec{F} \cdot d\vec{s}=0 $$
洛伦茨方程 $$ \begin{aligned} \dot{x} &amp; = \sigma(y-x) \\ \dot{y} &amp; = \rho x - y - xz \\ \dot{z} &amp; = -\beta z + xy \end{aligned} $$
交叉乘积 这在KaTeX中是可行的，但在这种环境中馏分的分离不是很好。
$$ \mathbf{V}_1 \times \mathbf{V}_2 = \begin{vmatrix} \mathbf{i} &amp; \mathbf{j} &amp; \mathbf{k} \\ \frac{\partial X}{\partial u} &amp; \frac{\partial Y}{\partial u} &amp; 0 \\ \frac{\partial X}{\partial v} &amp; \frac{\partial Y}{\partial v} &amp; 0 \end{vmatrix} $$
这里有一个解决方案:使用“mfrac”类(在MathJax情况下没有区别)的额外类使分数更小:
$$ \mathbf{V}_1 \times \mathbf{V}_2 = \begin{vmatrix} \mathbf{i} &amp; \mathbf{j} &amp; \mathbf{k} \\ \frac{\partial X}{\partial u} &amp; \frac{\partial Y}{\partial u} &amp; 0 \\ \frac{\partial X}{\partial v} &amp; \frac{\partial Y}{\partial v} &amp; 0 \end{vmatrix} $$
强调 $$ \hat{x}\ \vec{x}\ \ddot{x} $$
有弹性的括号 $$ \left(\frac{x^2}{y^3}\right) $$
评估范围 $$ \left.\frac{x^3}{3}\right|_0^1 $$
诊断标准 $$ f(n) = \begin{cases} \frac{n}{2}, &amp; \text{if } n\text{ is even} \\ 3n+1, &amp; \text{if } n\text{ is odd} \end{cases} $$
麦克斯韦方程组 $$ \begin{aligned} \nabla \times \vec{\mathbf{B}} -, \frac1c, \frac{\partial\vec{\mathbf{E}}}{\partial t} &amp; = \frac{4\pi}{c}\vec{\mathbf{j}} \\ \nabla \cdot \vec{\mathbf{E}} &amp; = 4 \pi \rho \\ \nabla \times \vec{\mathbf{E}}, +, \frac1c, \frac{\partial\vec{\mathbf{B}}}{\partial t} &amp; = \vec{\mathbf{0}} \\ \nabla \cdot \vec{\mathbf{B}} &amp; = 0 \end{aligned} $$
统计学 固定词组：
$$ \frac{n!}{k!(n-k)!} = {^n}C_k {n \choose k} $$
分数在分数 $$ \frac{\frac{1}{x}+\frac{1}{y}}{y-z} $$
ｎ次方根 $$ \sqrt[n]{1+x+x^2+x^3+\ldots} $$
矩阵 $$ \begin{pmatrix} a_{11} &amp; a_{12} &amp; a_{13}\\ a_{21} &amp; a_{22} &amp; a_{23}\\ a_{31} &amp; a_{32} &amp; a_{33} \end{pmatrix} \begin{bmatrix} 0 &amp; \cdots &amp; 0 \\ \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; \cdots &amp; 0 \end{bmatrix} $$
标点符号 $$ f(x) = \sqrt{1+x} \quad (x \ge -1) f(x) \sim x^2 \quad (x\to\infty) $$
现在用标点符号:
$$ f(x) = \sqrt{1+x}, \quad x \ge -1 f(x) \sim x^2, \quad x\to\infty $$
]]></content></entry><entry><title>支持用户自定义设计</title><url>/post/custom-files.html</url><categories><category>示例</category></categories><tags><tag>自定义</tag><tag>个性化</tag><tag>布局</tag></tags><content type="html"><![CDATA[对于熟悉前端开发的用户来说，可以通过自定义文件配置，实现对站点的样式和布局进行个性化的调整。其中布局方面主要是支持左侧边栏的站点概览部分，以及站点底部2个位置，但样式的重置可以是整个站点的任意位置。
打开配置参数 首先要明确在配置文件的 params 区域中有配置如下参数：
customFilePath: sidebar: custom_sidebar.html footer: custom_footer.html style: /css/custom_style.css 注意： sidebar 和 footer 的文件命名不可以与它们的参数名称相同，不然会影响系统默认的布局设计，切记！！！ 😄 然后在站点的根目录下创建 layouts/partials 2个目录，用于存放自定布局设计文件，另外在站点根目录下创建 statics/css 2个目录，用于存放自定义 CSS 样式文件。一切就绪后，就可以参考如下的步骤，完成自己的设计想法。
侧边栏设计 在前面创建 partials 目录中新一个后缀名为 html 的文件，可以在里面书写你所想表达的设计或内容，比如引入一些第三方组件内容。示例如下：
&lt;div class=&#34;mydefined animated&#34; itemprop=&#34;custom&#34;&gt; &lt;span&gt;支持自定义CSS和Sidebar布局啦💄💄💄&lt;/span&gt; &lt;/div&gt; 再把该文件的路径配置到相应的参数中，效果请查看左侧边栏底部的效果。
底部设计 在前面创建 partials 目录中新一个后缀名为 html 的文件，可以在里面书写你所想表达的设计或内容，比如引入一些第三方组件内容。示例如下：
&lt;div class=&#34;custom-footer&#34;&gt; Website source code &lt;a href=&#34;https://github.com/hugo-next/hugo-theme-next/tree/develop/exampleSite/layouts/partials/custom-footer.html&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; &lt;/div&gt; 再把该文件的路径配置到相应的参数中，效果请查看站点底部的效果。
自定义样式 在前面创建 css 目录中新一个后缀名为 css 的文件，然后可以在里面把站点的样式进行重定义，或是增加一些自己定义的样式设计，在写文章时进行引用，示例如下：
.custom-head5 { font-size: 1.2em; color: #ed6c24; font-weight: bold; } 再把该文件的路径配置到相应的参数中，效果参考如下：
我是自定义的标题样式效果!!!
]]></content></entry><entry><title>自定义短语示例</title><url>/post/shortcodes.html</url><categories><category>示例</category></categories><tags><tag>短代码</tag><tag>语法</tag></tags><content type="html"><![CDATA[虽然 Markdown 语法已经非常丰富能够满足我们写文章的绝大部分需求，但是为更好的对文章内容进行更友好的排版，为引设计一套自定义的短语，便于在使用时能够快速引用。
块引用 在引用一些经典名言名句时，可以采用此短语，语法参考如下：
{{&lt; quote &gt;}} ### block quote 写下你想表达的话语！ {{&lt; /quote &gt;}} 实际效果：
希望是无所谓有，无所谓无的，这正如地上的路。
其实地上本没有路，走的人多了，也便成了路。
鲁迅
信息块 支持 default，info，success，warning，danger 等五种不同效果的展示，语法参考如下：
{{&lt; note [class] [no-icon] &gt;}} 书写表达的信息 支持 Markdown 语法 {{&lt; /note &gt;}} 实际效果：
Default Header without icon Welcome to Hugo NexT! Default Header Welcome to Hugo NexT! Info Header Welcome to Hugo NexT! Success Header Welcome to Hugo NexT! Warning Header Welcome to Hugo NexT! Danger Header Welcome to Hugo NexT! ]]></content></entry><entry><title>关于 Hugo NexT 组织</title><url>/about.html</url><categories/><tags/><content type="html">Hugo NexT 组织是由众多喜爱 NexT 主题及风格的世界各地友人共同组建而成，为的就是让这个主题继续在 Hugo 引擎中也能得到发扬光大，在此也欢迎你的加入！
我们的愿景 延续 NexT 经典的黑白调搭配，保持简单的易用性及强大的功能。
使用反馈 加入 GitHub Discussions 或 Gitter 在线讨论 🍻 GitHub Issues 提交错误报告 🐛 GitHub Feature 表新功能的想法 ✨ 同时国内用户也可加入 QQ 群交流： 604710815</content></entry><entry><title>Hugo 内置的 Chroma 语法高亮</title><url>/post/syntax-highlighting.html</url><categories><category>示例</category></categories><tags><tag>语法</tag><tag>高亮</tag><tag>Chroma</tag></tags><content type="html"><![CDATA[Hugo 通过 Chroma 提供非常快速的语法高亮显示，现 Hugo 中使用 Chroma 作为代码块高亮支持，它内置在 Go 语言当中，速度是真的非常、非常快，而且最为重要的是它也兼容之前我们使用的 Pygments 方式。
以下通过 Hugo 内置短代码 highlight 和 Markdown 代码块方式分别验证不同语言的代码块渲染效果并能正确高亮显示，有关优化语法突出显示的更多信息，请参阅 Hugo 文档 。
编程语言 GO 199 200 201 202 203 204 205 206 207 208 func GetTitleFunc(style string) func(s string) string { switch strings.ToLower(style) { case &#34;go&#34;: return strings.Title case &#34;chicago&#34;: return transform.NewTitleConverter(transform.ChicagoStyle) default: return transform.NewTitleConverter(transform.APStyle) } } Java import javax.swing.JFrame; //Importing class JFrame import javax.swing.JLabel; //Importing class JLabel public class HelloWorld { public static void main(String[] args) { JFrame frame = new JFrame(); //Creating frame frame.setTitle(&#34;Hi!&#34;); //Setting title frame frame.add(new JLabel(&#34;Hello, world!&#34;));//Adding text to frame frame.pack(); //Setting size to smallest frame.setLocationRelativeTo(null); //Centering frame frame.setVisible(true); //Showing frame } } Python print &#34;Hello, world!&#34; Git 对比 1*** /path/to/original &#39;&#39;timestamp&#39;&#39; 2--- /path/to/new &#39;&#39;timestamp&#39;&#39; 3*************** 4*** 1 **** 5! This is a line. 6--- 1 --- 7! This is a replacement line. 8It is important to spell 9-removed line 10+new line *** /path/to/original &#39;&#39;timestamp&#39;&#39; --- /path/to/new &#39;&#39;timestamp&#39;&#39; *************** *** 1 **** ! This is a line. --- 1 --- ! This is a replacement line. It is important to spell -removed line +new line 文件 Make 文件 CC=gcc CFLAGS=-I. hellomake: hellomake.o hellofunc.o $(CC) -o hellomake hellomake.o hellofunc.o -I. Markdown 文档 **bold** *italics* [link](www.example.com) 数据内容 JSON 数据 {&#34;employees&#34;:[ {&#34;firstName&#34;:&#34;John&#34;, &#34;lastName&#34;:&#34;Doe&#34;}, ]} XML 内容 &lt;employees&gt; &lt;employee&gt; &lt;firstName&gt;John&lt;/firstName&gt; &lt;lastName&gt;Doe&lt;/lastName&gt; &lt;/employee&gt; &lt;/employees&gt; SQL 查询 SELECT column_name,column_name FROM Table WHERE column_name = &#34;condition&#34; 除以上列举的代码高亮显示外，还支持诸如：C 语言、C++、HTML、CSS、Shell脚本等各主流的代码语言高亮显示，可自行测试效果。
]]></content></entry><entry><title>支持 Emoji 表情</title><url>/post/emoji-support.html</url><categories><category>示例</category></categories><tags><tag>表情</tag><tag>emoji</tag></tags><content type="html">Emoji 可以通过多种方式在 Hugo 项目中启用。
emojify 方法可以直接在模板中调用, 或者使用 行内 Shortcodes .
要全局使用 emoji, 需要在你的 网站配置 中设置 enableEmoji 为 true， 然后你就可以直接在文章中输入 emoji 的代码。
它们以冒号开头和结尾，并且包含 emoji 的 代码：
去露营啦! {:}tent: 很快就回来. 真开心! {:}joy: 呈现的输出效果如下:
去露营啦! ⛺ 很快就回来。
真开心! 😂
以下符号清单是 emoji 代码的非常有用的参考。
表情与情感 笑脸表情 图标 代码 图标 代码 😀 grinning 😃 smiley 😄 smile 😁 grin 😆 laughing satisfied 😅 sweat_smile 🤣 rofl 😂 joy 🙂 slightly_smiling_face 🙃 upside_down_face 😉 wink 😊 blush 😇 innocent 爱意表情 图标 代码 图标 代码 😍 heart_eyes 😘 kissing_heart 😗 kissing ☺️ relaxed 😚 kissing_closed_eyes 😙 kissing_smiling_eyes 吐舌头表情 图标 代码 图标 代码 😋 yum 😛 stuck_out_tongue 😜 stuck_out_tongue_winking_eye 😝 stuck_out_tongue_closed_eyes 🤑 money_mouth_face 国家和地区旗帜 图标 代码 图标 代码 🇦🇩 andorra 🇦🇪 united_arab_emirates 🇦🇫 afghanistan 🇦🇬 antigua_barbuda 🇦🇮 anguilla 🇦🇱 albania 🇦🇲 armenia 🇦🇴 angola 🇦🇶 antarctica 🇦🇷 argentina 🇦🇸 american_samoa 🇦🇹 austria 🇦🇺 australia 🇦🇼 aruba 🇦🇽 aland_islands 🇦🇿 azerbaijan 🇧🇦 bosnia_herzegovina 🇧🇧 barbados 🇧🇩 bangladesh 🇧🇪 belgium 🇧🇫 burkina_faso 🇧🇬 bulgaria 🇧🇭 bahrain 🇧🇮 burundi 🇧🇯 benin 🇧🇱 st_barthelemy 🇧🇲 bermuda 🇧🇳 brunei 🇧🇴 bolivia 🇧🇶 caribbean_netherlands 🇧🇷 brazil 🇧🇸 bahamas 🇧🇹 bhutan 🇧🇼 botswana 🇧🇾 belarus 🇧🇿 belize 🇨🇦 canada 🇨🇨 cocos_islands 🇨🇩 congo_kinshasa 🇨🇫 central_african_republic 🇨🇬 congo_brazzaville 🇨🇭 switzerland 🇨🇮 cote_divoire 🇨🇰 cook_islands 🇨🇱 chile 🇨🇲 cameroon 🇨🇳 cn 🇨🇴 colombia 🇨🇷 costa_rica 🇨🇺 cuba 🇨🇻 cape_verde 🇨🇼 curacao 🇨🇽 christmas_island 🇨🇾 cyprus 🇨🇿 czech_republic 🇩🇪 de 🇩🇯 djibouti 🇩🇰 denmark 🇩🇲 dominica 🇩🇴 dominican_republic 🇩🇿 algeria 🇪🇨 ecuador 🇪🇪 estonia 🇪🇬 egypt 🇪🇭 western_sahara 🇪🇷 eritrea 🇪🇸 es 🇪🇹 ethiopia 🇪🇺 eu european_union 🇫🇮 finland 🇫🇯 fiji 🇫🇰 falkland_islands 🇫🇲 micronesia 🇫🇴 faroe_islands 🇫🇷 fr 🇬🇦 gabon 🇬🇧 gb uk 🇬🇩 grenada 🇬🇪 georgia 🇬🇫 french_guiana 🇬🇬 guernsey 🇬🇭 ghana 🇬🇮 gibraltar 🇬🇱 greenland 🇬🇲 gambia 🇬🇳 guinea 🇬🇵 guadeloupe 🇬🇶 equatorial_guinea 🇬🇷 greece 🇬🇸 south_georgia_south_sandwich_islands 🇬🇹 guatemala 🇬🇺 guam 🇬🇼 guinea_bissau 🇬🇾 guyana 🇭🇰 hong_kong 🇭🇳 honduras 🇭🇷 croatia 🇭🇹 haiti 🇭🇺 hungary 🇮🇨 canary_islands 🇮🇩 indonesia 🇮🇪 ireland 🇮🇱 israel 🇮🇲 isle_of_man 🇮🇳 india 🇮🇴 british_indian_ocean_territory 🇮🇶 iraq 🇮🇷 iran 🇮🇸 iceland 🇮🇹 it 🇯🇪 jersey 🇯🇲 jamaica 🇯🇴 jordan 🇯🇵 jp 🇰🇪 kenya 🇰🇬 kyrgyzstan 🇰🇭 cambodia 🇰🇮 kiribati 🇰🇲 comoros 🇰🇳 st_kitts_nevis 🇰🇵 north_korea 🇰🇷 kr 🇰🇼 kuwait 🇰🇾 cayman_islands 🇰🇿 kazakhstan 🇱🇦 laos 🇱🇧 lebanon 🇱🇨 st_lucia 🇱🇮 liechtenstein 🇱🇰 sri_lanka 🇱🇷 liberia 🇱🇸 lesotho 🇱🇹 lithuania 🇱🇺 luxembourg 🇱🇻 latvia 🇱🇾 libya 🇲🇦 morocco 🇲🇨 monaco 🇲🇩 moldova 🇲🇪 montenegro 🇲🇬 madagascar 🇲🇭 marshall_islands 🇲🇰 macedonia 🇲🇱 mali 🇲🇲 myanmar 🇲🇳 mongolia 🇲🇴 macau 🇲🇵 northern_mariana_islands 🇲🇶 martinique 🇲🇷 mauritania 🇲🇸 montserrat 🇲🇹 malta 🇲🇺 mauritius 🇲🇻 maldives 🇲🇼 malawi 🇲🇽 mexico 🇲🇾 malaysia 🇲🇿 mozambique 🇳🇦 namibia 🇳🇨 new_caledonia 🇳🇪 niger 🇳🇫 norfolk_island 🇳🇬 nigeria 🇳🇮 nicaragua 🇳🇱 netherlands 🇳🇴 norway 🇳🇵 nepal 🇳🇷 nauru 🇳🇺 niue 🇳🇿 new_zealand 🇴🇲 oman 🇵🇦 panama 🇵🇪 peru 🇵🇫 french_polynesia 🇵🇬 papua_new_guinea 🇵🇭 philippines 🇵🇰 pakistan 🇵🇱 poland 🇵🇲 st_pierre_miquelon 🇵🇳 pitcairn_islands 🇵🇷 puerto_rico 🇵🇸 palestinian_territories 🇵🇹 portugal 🇵🇼 palau 🇵🇾 paraguay 🇶🇦 qatar 🇷🇪 reunion 🇷🇴 romania 🇷🇸 serbia 🇷🇺 ru 🇷🇼 rwanda 🇸🇦 saudi_arabia 🇸🇧 solomon_islands 🇸🇨 seychelles 🇸🇩 sudan 🇸🇪 sweden 🇸🇬 singapore 🇸🇭 st_helena 🇸🇮 slovenia 🇸🇰 slovakia 🇸🇱 sierra_leone 🇸🇲 san_marino 🇸🇳 senegal 🇸🇴 somalia 🇸🇷 suriname 🇸🇸 south_sudan 🇸🇹 sao_tome_principe 🇸🇻 el_salvador 🇸🇽 sint_maarten 🇸🇾 syria 🇸🇿 swaziland 🇹🇨 turks_caicos_islands 🇹🇩 chad 🇹🇫 french_southern_territories 🇹🇬 togo 🇹🇭 thailand 🇹🇯 tajikistan 🇹🇰 tokelau 🇹🇱 timor_leste 🇹🇲 turkmenistan 🇹🇳 tunisia 🇹🇴 tonga 🇹🇷 tr 🇹🇹 trinidad_tobago 🇹🇻 tuvalu 🇹🇼 taiwan 🇹🇿 tanzania 🇺🇦 ukraine 🇺🇬 uganda 🇺🇸 us 🇺🇾 uruguay 🇺🇿 uzbekistan 🇻🇦 vatican_city 🇻🇨 st_vincent_grenadines 🇻🇪 venezuela 🇻🇬 british_virgin_islands 🇻🇮 us_virgin_islands 🇻🇳 vietnam 🇻🇺 vanuatu 🇼🇫 wallis_futuna 🇼🇸 samoa 🇽🇰 kosovo 🇾🇪 yemen 🇾🇹 mayotte 🇿🇦 south_africa 🇿🇲 zambia 🇿🇼 zimbabwe</content></entry><entry><title>Markdown 语法支持</title><url>/post/markdown-syntax.html</url><categories><category>示例</category></categories><tags><tag>Markdown</tag><tag>语法</tag></tags><content type="html"><![CDATA[仅以此篇文章来测试下在 NexT 主题中在通过 Hugo 引擎来建站时，是否支持 Markdown 文件内容中所写的各种语法，并展示下实际的效果。
标题样式 让我们从所有可能的标题开始，在 HTML 中 &lt;h1&gt;-&lt;h6&gt;元素分别表示六个不同级别的标题样式，其中 &lt;h1&gt; 为最大标题，&lt;h6&gt;为最小标题，效果如下：
标题 1 标题 2 标题 3 标题 4 标题 5 标题 6 段落格式 根据 W3C 定义的 HTML5 规范 ，HTML 文档由元素和文本组成。每个元素的组成都由一个 开始标记 表示，例如： &lt;body&gt; ，和 结束标记 表示，例如： &lt;/body&gt; 。（某些开始标记和结束标记在某些情况下可以省略，并由其他标记暗示。） 元素可以具有属性，这些属性控制元素的工作方式。例如：超链接是使用 a 元素及其 href 属性形成的。
Markdown 语法 ![图像说明](图像地址) HTML IMG 标签 &lt;img src=&#34;图像地址&#34; width=&#34;宽度&#34; height=&#34;高度&#34; /&gt; SVG 格式 &lt;svg&gt;xxxxxx&lt;/svg&gt; 列表类型 有序列表 第一个元素 第二个元素 第三个元素 无序列表 列表元素 另一个元素 和其它元素 嵌套列表 借助 HTML 的 ul 元素来实现。
第一项 第二项 第二项第一个子项目 第二项第二个子项目 第二项第二分项第一分项 第二项第二分项第二分项 第二项第二分项第三分项 第二项第三个子项目 第二项第三分项第一分项 第二项第三分项第二分项 第二项第三分项第三分项 第三项 自定义列表 通过 HTML 的 dl 元素还支持自定义列表（表格列表）。
Hugo 目录结构 assets config.toml content data theme static Hugo 模板 基础模板 列表模板 单页模板 块引用 blockquote 元素表示从另一个源引用的内容，可以选择引用必须在 footer 或 cite 元素中，也可以选择使用注释和缩写等行内更改。
引用文本 这一行也是同样的引用 同样你也在 blockquote 中使用 Markdown 语法书写
带有引文的 Blockquote 元素效果。
我的目标不是赚大钱,是为了制造好的电脑。当我意识到我可以永远当工程师时，我才创办了这家公司。
— 史蒂夫·沃兹尼亚克 根据 Mozilla 的网站记录，Firefox 1.0 于 2004 年发布，并取得了巨大成功。
表格 表格并不算是 Markdown 的核心要素，但 Hugo 同样支持它。
ID 创建者 模型 年份 1 Honda Accord 2009 2 Toyota Camry 2012 3 Hyundai Elantra 2010 可以使用 : （英文格式冒号）来对表格内容进行对齐。
表格 可以是 很酷 左对齐 居中 右对齐 左对齐 居中 右对齐 左对齐 居中 右对齐 同样也可以在表格中使用 Markdown 语法。
表格 中 使用 Markdown 语法 斜体 粗体 中划线 代码块 Code &lt;!DOCTYPE html&gt; &lt;html lang=&#34;en&#34;&gt; &lt;head&gt; &lt;meta charset=&#34;UTF-8&#34;&gt; &lt;title&gt;Example HTML5 Document&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;Test&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; &lt;!DOCTYPE html&gt; &lt;html lang=&#34;en&#34;&gt; &lt;head&gt; &lt;meta charset=&#34;UTF-8&#34;&gt; &lt;title&gt;Example HTML5 Document&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;Test&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; 其它元素： abbr、sub、sup、kbd等等 GIF 是位图图像格式。
H2O
C6H12O6
Xn + Yn = Zn
按X获胜。或按CTRL+ALT+F显示 FPS 计数器。
比特作为信息论中的信息单位，也被称为 shannon ，以信息论领域的创始人 Claude shannon 的名字命名。
参考：
来自 Mainroad 主题的 Basic Elements 内容 ]]></content></entry><entry><title>站点示例</title><url>/flinks.html</url><categories/><tags/><content type="html">如想交换本站友情链接，请在评论区留下你的站点信息，格式参考如下：
- name: Hugo-NexT desc: Hugo NexT 官方预览网站。 avatar: https://hugo-next.eu.org/imgs/hugo_next_avatar.png link: https://hugo-next.eu.org</content></entry></search>