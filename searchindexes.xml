<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>Canny算法中sobel算子padding的方式对极大值抑制的影响</title><url>/canny-algorithm-sobel-padding-influence-for-NonMaximumSuppression.html</url><categories><category>programming</category></categories><tags><tag>canny</tag><tag>sobel</tag></tags><content type="html"><![CDATA[在使用sobel算子计算梯度时，需要注意padding的方式，一般采用复制像素的padding方式，不能使用补零与反射的padding方式。 应为会影响后续极大值抑制时，边缘像素的去留。
完整程序：https://github.com/qyzhizi/canny-algorithm.git 假设原图是： 这是一张非常小的图片，像素是大小（12，13），方便查看中间的计算过程。 原图放大后： 处理程序：python conv2d-canny.py -v -i data/test-small.png -gk 0 -L 10 -H 50 参数解释： -v : 打开verbose开关，显示中间过程的图片 -i data/test-small.png: 待处理的图片 -gk 0: 图片预处理的高斯核大小为0，意味着不使用高斯模糊 -L 10 -H 50 : 极大值抑制后，阈值处理，低阈值为10，高阈值为50，低于10的像素置为0，中间像素[10, 50]置为50，高于50的像素置为255。 结果： 梯度幅值图： 极大值抑制后的结果，开起来还不错： 查看sobel 算子计算梯度幅值的程序，可以看到这么一行im = F.pad(im, (1, 1, 1, 1), mode='replicate'), 这就是复制模式（replicate）的padding方式，在这个基础上修改 sobel 算子 padding 的方式，如果不进行复制模式（replicate）的padding会怎么样？ 修改前的程序：
def functional_conv2d_horizontal(im, verbose=False): &#34;&#34;&#34;使用F.Conv2d进行边缘检测, 检测竖直方向的轮廓, 水平梯度，右方向为正方向 Args: im (tensor): 输入的tensor图像 Returns: tensor: 输出的tensor图像 &#34;&#34;&#34; sobel_kernel = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=&#39;float32&#39;) sobel_kernel = sobel_kernel.reshape((1, 1, 3, 3)) weight = torch.from_numpy(sobel_kernel) im = F.pad(im, (1, 1, 1, 1), mode=&#39;replicate&#39;) edge_detect = F.conv2d(im, weight, stride=1, padding=0) if verbose: plt.imshow(edge_detect.squeeze().detach().numpy(), cmap=&#39;gray&#39;) plt.title(&#34;horizontal&#34;) plt.show() return edge_detect def functional_conv2d_vertical(im, verbose=False): &#34;&#34;&#34;使用F.Conv2d进行边缘检测, 检测水平方向的轮廓， 垂直梯度，向上为正方向 Args: im (tensor): 输入的tensor图像 Returns: tensor: 输出的tensor图像 &#34;&#34;&#34; sobel_kernel = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype=&#39;float32&#39;) sobel_kernel = sobel_kernel.reshape((1, 1, 3, 3)) weight = torch.from_numpy(sobel_kernel) im = F.pad(im, (1, 1, 1, 1), mode=&#39;replicate&#39;) edge_detect = F.conv2d(im, weight, stride=1, padding=0) if verbose: plt.imshow(edge_detect.squeeze().detach().numpy() , cmap=&#39;gray&#39;) plt.title(&#34;vertical&#34;) plt.show() return edge_detect 修改后的程序, 将这一行im = F.pad(im, (1, 1, 1, 1), mode='replicate')注释掉：
def functional_conv2d_horizontal(im, verbose=False): &#34;&#34;&#34;使用F.Conv2d进行边缘检测, 检测竖直方向的轮廓, 水平梯度，右方向为正方向 Args: im (tensor): 输入的tensor图像 Returns: tensor: 输出的tensor图像 &#34;&#34;&#34; sobel_kernel = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=&#39;float32&#39;) sobel_kernel = sobel_kernel.reshape((1, 1, 3, 3)) weight = torch.from_numpy(sobel_kernel) # im = F.pad(im, (1, 1, 1, 1), mode=&#39;replicate&#39;) edge_detect = F.conv2d(im, weight, stride=1, padding=0) if verbose: plt.imshow(edge_detect.squeeze().detach().numpy(), cmap=&#39;gray&#39;) plt.title(&#34;horizontal&#34;) plt.show() return edge_detect def functional_conv2d_vertical(im, verbose=False): &#34;&#34;&#34;使用F.Conv2d进行边缘检测, 检测水平方向的轮廓， 垂直梯度，向上为正方向 Args: im (tensor): 输入的tensor图像 Returns: tensor: 输出的tensor图像 &#34;&#34;&#34; sobel_kernel = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype=&#39;float32&#39;) sobel_kernel = sobel_kernel.reshape((1, 1, 3, 3)) weight = torch.from_numpy(sobel_kernel) # im = F.pad(im, (1, 1, 1, 1), mode=&#39;replicate&#39;) edge_detect = F.conv2d(im, weight, stride=1, padding=0) if verbose: plt.imshow(edge_detect.squeeze().detach().numpy() , cmap=&#39;gray&#39;) plt.title(&#34;vertical&#34;) plt.show() return edge_detect 执行程序：python conv2d-canny.py -v -i data/test-small.png -gk 0 -L 10 -H 50 梯度幅值图，可看到，长宽比之前少了2个像素，这是因为没有padding的缘故。 极大值抑制后的结果，可以看到靠近边缘的梯度最亮的像素被保留下来了，但是如何你看之前的梯度幅值图，它的边缘一定程度上维持了梯度的变化趋势，这是由于复制模式padding的结果。如果没有复制模式的padding，边缘像素在极大值抑制时可能会有问题，就像下面这样 ： 极大值抑制算法： 进行极大值抑制时会对周边先 padding 一圈0，然后对某个像素进行极大值抑制时，然后判断当前像素的方向，方向分别用0, 1, 2, 3表示，代表着0度、45度、90度，135度。这里的梯度幅值图的大部分像素都是135度的方向，所以会比较该方向上的3个像素，如果当前像素的坐标是(0,0),它的梯度方向假设是135度，那么另两个像素的坐标就是(-1,1）(1,-1)，注意即使另两个像素不是135度，依然选这两个坐标，另两个像素是不是135度不重要，至于为什么，我也不知道如何解释。这种情况下，遍历每个像素就得到了极大值抑制的结果。
下面是一个例子： 白色框中的是没有sobel算子没有padding的计算结果，那么在计算极大值抑制时，白色框外会先padding一圈0，这里没有画出来。 蓝色框中的是sobel算子正常padding的计算结果，那么在计算极大值抑制时，蓝色框外会先padding一圈0，如果黄色框所示。
白色框中每个梯度幅值的方向：
tensor([[[[2, 2, 2, 2, 2, 2, 2, 1, 0, 3, 3], [0, 2, 1, 3, 1, 0, 0, 3, 3, 3, 3], [2, 0, 0, 0, 0, 2, 3, 3, 3, 3, 3], [1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 3], [0, 0, 3, 2, 3, 3, 3, 3, 3, 3, 3], [2, 1, 0, 3, 3, 3, 3, 3, 3, 3, 1], [1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 0], [1, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2], [3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 2], [3, 3, 3, 3, 3, 3, 0, 0, 0, 1, 2]]]]) 蓝色框中每个梯度幅值的方向：
tensor([[[[2, 2, 2, 2, 2, 0, 0, 1, 1, 2, 3, 3, 2], [2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 3, 3, 2], [2, 0, 2, 1, 3, 1, 0, 0, 3, 3, 3, 3, 2], [2, 2, 0, 0, 0, 0, 2, 3, 3, 3, 3, 3, 2], [2, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 3, 3], [3, 0, 0, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2], [2, 2, 1, 0, 3, 3, 3, 3, 3, 3, 3, 1, 0], [2, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1], [1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2], [2, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 2, 2], [0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 1, 2, 3], [0, 0, 0, 3, 3, 3, 1, 0, 0, 0, 2, 2, 2]]]]) 根据极大值算法可以获得对应的极大值抑制后的图像。通过梯度幅值方向与梯度幅值图可以验证之前的极大值抑制的结果。
sobel 算了除了复制（replicate）模式的padding，还有反射，补零的方式，但是这两种方式在sobel算子中都不能使用。否者破坏梯度图边缘的一致性，这样 后续的极大值抑制会得到错误的边缘。
]]></content></entry><entry><title>解读canny算法opencl实现</title><url>/analyze-canny-algorithm-opencl-implemention.html</url><categories><category>programming</category></categories><tags><tag>canny</tag><tag>opencl</tag></tags><content type="html">在看完了canny 算法 c++ 实现细节以及完成 pytorch 版本的实现后，我在考虑如何对算法进行并行加速，我知道有opencl 加速 与 cuda 加速（pytorch api 可以实现），打算先考虑opencl 的加速。我之前已经知道 opencv 中是包含了对 opencl 的支持，我比较好奇如何使用 opencl 对 canny 算法的加速。在github 找到一个实现，虽然不是特别好，但是用了解 opencl 的使用还是可以的。
代码 github代码 源码解读 代码解读，drawio 格式 ， 下载后可在 https://app.diagrams.net/ 打开，方便查看。
代码解读，svg格式 ， 可在浏览器打开，不过查看不方便，因为画幅太大了。
总结 流程 总结 1 创建对象 类构构造函数执行步骤：
-1 获取设备信息 -2 使用设备信息，创建命令队列
-3 用于提交内核对象到设备执行生成内核对象（高斯滤波、sobel、极大值抑制、滞后阈值） 1.3 生成内核对象 步骤：
-1 读取 kernel 文件 -2 构造一个字符串对象，将文件全部内容转换为字符串 -3 由 字符串对象构造 kernel 程序对象，再使用 OpenCL 编程框架编译并构建一个内核对象 (cl::Kernel)
1.3.1 kernel 文件 这里以高斯模糊内核函数源码为例来解释 kernel 文件是c/c++ 代码，定义了工作组（后面解释）中的工作项的执行过程，你可以想象每个工作项用来执行一个像素相关的操作，而工作项是可以并行的 ，这意味着全部的像素可以再同时执行相关的操作，这就是并行。 步骤：
-1 每个工作组的工作项的边长是16，这里的工作项是：16*16 ，待处理的数据会划分给多个工作组，每个组会执行16*16 个工作项。 -2 内核函数的参数：__global uchar *data __global uchar *out 分别表示全局的输入数据的指针与全局输出数据指针 -3 每个工作项会执行一遍内核函数，完成一个像素的相关操作（比如卷积）然后将数据存入out指针所指向的数组的对应位置 2 加载图像，设置缓存 步骤：
-1 裁剪图片，保证图片可以划分为工作组的整数倍 -2 将裁剪后的图片拷贝一份，保存到input_， 这样可以保证工作组索引不会引用错误的像素。 -3 创建两个缓存，该缓存的生命周期由opencl 的运行时管理，不用担心内存回收的问题 -4 这两个缓存是个循环缓存，分别代表kernel 对象的输入与输出，后续还有几个kernel 对象需要执行，它们是串连的，将这个两个缓存的的名称转换，原来的输出变为输入，原来的输入将保存当前 kernel 的输出。最开始的输入就是原始裁剪后的图片。 -5 这里两个缓存是沟通主机内存与设备显存的桥梁，它们有opencl 运行时实现，缓存可以实现在主机申请内存，但设备需要数据时，自动把数据传输到设备。同样可以把设备的线显存的数据输出到主机内存。 3 opencl 队列 执行内核对象 步骤：
- 1 传参：待处理的数据由PrevBuff()提供,对应1.3.1 中的__global uchar *data， 保存输出数据到NextBuff() 对应1.3.1 中的__global uchar *out 。而这里两个缓存就是加载图像，设置缓存时所提到的两个缓存 -2 执行完内核函数后，会执行AdvanceBuff(); 将这个两个缓存的的名称转换，原来的输出变为输入，原来的输入将保存当前 kernel 的输出 , 此时PrevBuff()指向当前内核函数的输出，而 NextBuff() 指向当前内核函数的输入，不过 NextBuff() 指向的内容不会再用到，会被下一个 kernel 函数执行返回的数据覆盖。 4 opencl 队列所有需要执行的内核对象 - Gaussian(); - Sobel();
- NonMaxSuppression(); - HysteresisThresholding(); 这些内核对象 就是canny 算法的需要执行的步骤，执行完这些内核对象，可以从PrevBuff()指向的缓存获取最终的输出 5 从缓存对象中获取最终的输出 读取 PrevBuff()的内容，并返回</content></entry><entry><title>PyTorch 实现 Opencv Canny 算法</title><url>/pytorch-implement-opencv-canny-algorithm.html</url><categories><category>programming</category></categories><tags><tag>opencv</tag><tag>pytorch</tag><tag>canny</tag></tags><content type="html"><![CDATA[ 使用PyTorch 实现Canny算法，相比于纯python实现，速度会更快，因为PyTorch api 使用很多c语言的底层模块，比如卷积。另外使用Pytorch可以很方便得利用cuda的加速，所以也在GPU并行运算上也有优势。
不过相比OpenCV c++的高效，PyTorch的实现显得更冗余，效率一般。但是PyTorch 使用张量、卷积来实现图像处理，保证一定效率的同时代码更简洁，另外比较重要的是，全过程使用python语言所以程序比较方进行调试，展示算法的中间处理过程。
程序运行 完整程序：https://github.com/qyzhizi/canny-algorithm.git
运行命令：
python pytorch-canny.py -v -i data/lena.png -gk 0 -L 100 -H 200 命令行参数： -v: 展示中间过程处理的图片 -i: 图片路径 -gk: 高斯核大小，默认是3， 传入0则表示不使用高斯模糊处理 -L: 低阈值 -H: 高阈值
结果：
Canny 算法执行步骤 算法主要分为一下步骤：
高斯滤波 使用sobel 算子计算梯度(水平梯度, 垂直梯度) 计算梯度的幅值与方向 梯度的极大值抑制 滞后阈值 main 程序片段
def main(): ap = argparse.ArgumentParser() ap.add_argument(&#34;-i&#34;, &#34;--image&#34;, required=True, default=&#34;lena.png&#34;, help=&#34;Path to the image&#34;) ap.add_argument(&#34;-v&#34;, &#34;--verbose&#34;, action=&#39;store_true&#39;, default=False, help=&#34;Path to the image&#34;) ap.add_argument(&#34;-gk&#34;, &#34;--gaussian_kernel_size&#34;, type=int, default=3, help=&#34;Path to the image&#34;) ap.add_argument(&#34;-L&#34;, &#34;--threshold_low&#34;, type=int, default=20, help=&#34;Path to the image&#34;) ap.add_argument(&#34;-H&#34;, &#34;--threshold_high&#34;, type=int, default=50, help=&#34;Path to the image&#34;) args = vars(ap.parse_args()) verbose = args[&#34;verbose&#34;] threshold_low = args[&#34;threshold_low&#34;] threshold_high = args[&#34;threshold_high&#34;] gaussian_kernel_size = args[&#34;gaussian_kernel_size&#34;] print(&#34;args: &#34; , args) # 把工作目录切换到当前文件夹所在目录 os.chdir(os.path.dirname(os.path.abspath(__file__))) # 打印当前工作目录 if verbose: print(os.getcwd()) # 读入一张图片，并转换为灰度图 im = Image.open(args[&#34;image&#34;]).convert(&#39;L&#39;) # 将图片数据转换为矩阵 im = np.array(im, dtype=&#39;float32&#39;) # 将图片矩阵转换为pytorch tensor,并适配卷积输入的要求 im = torch.from_numpy(im.reshape((1, 1, im.shape[0], im.shape[1]))) if verbose: print(&#34;im.shape: &#34;, im.shape) # 对图像进行高斯滤波，平滑图像，去除噪声 im = gaussian_blur(im, gaussian_kernel_size, verbose=verbose) # sobel 算子进行边缘检测 gradient_v = functional_conv2d_vertical(im, verbose=verbose) # 竖直梯度 gradient_h = functional_conv2d_horizontal(im, verbose=verbose) # 水平梯度 # 计算梯度幅值 gradient_magnitude = get_gradient_magnitude(gradient_v, gradient_h, verbose=verbose) # 计算梯度方向 gradient_direction_quantized = get_gradient_direction_quantized(gradient_v, gradient_h, verbose=verbose) # 非极大值抑制 nms_tensor = nms(gradient_magnitude, gradient_direction_quantized, verbose=verbose) # 阈值处理 # edge_detect = threshold(nms_tensor, low=threshold_low, high=threshold_high, weak=50, strong=255) # 滞后阈值 edge_detect = hysteresis_threshold(nms_tensor, low=threshold_low, high=threshold_high) if verbose: print(&#34;edge_detect.shape: &#34;, edge_detect.shape, &#34;im.shape: &#34;, im.shape) plt.imshow(edge_detect.squeeze().detach().numpy(), cmap=&#39;gray&#39;) plt.title(&#34;Edge Detection&#34;) plt.show() # 保存图片 save_edge_detect_as_image(edge_detect, &#34;data/edge_detect.png&#34;, verbose=verbose) save_edge_detect_and_origin_image_as_image(edge_detect, args[&#34;image&#34;], &#34;data/edge_detect_and_origin_image.png&#34;, verbose=verbose) if __name__ == &#34;__main__&#34;: start_time = time.time() print(&#34;programming strat&#34;) main() end_time = time.time() print(&#34;time: &#34;, end_time - start_time) print(&#34;programming end&#34;) 高斯滤波 def dnorm(x: int, mu:int , sd:int)-&gt; np.float32: return 1 / (np.sqrt(2 * np.pi) * sd) * np.e ** (-np.power((x - mu) / sd, 2) / 2) def gaussian_kernel(size: int, sigma: int=1, verbose: bool=False) -&gt; np.ndarray: kernel_1D = np.linspace(-(size // 2), size // 2, size) for i in range(size): kernel_1D[i] = dnorm(kernel_1D[i], 0, sigma) if verbose: print(&#34;kernel_1D: &#34;, kernel_1D) kernel_2D = np.outer(kernel_1D, kernel_1D) if verbose: print(&#34;kernel_2D: &#34;, kernel_2D) kernel_2D *= 1.0 / (kernel_2D.max() * size * size)# 归一化, 使得kernel_2D的最大值为1 if verbose: print(kernel_2D.max()) print(&#34;kernel_2D: &#34;, kernel_2D) if verbose: plt.imshow(kernel_2D, interpolation=&#39;none&#39;, cmap=&#39;gray&#39;) plt.title(&#34;Kernel ( {}X{} )&#34;.format(size, size)) plt.show() return kernel_2D # 对图像进行高斯滤波，平滑图像，去除噪声 def gaussian_blur(image: torch.tensor, kernel_size: int, verbose=False) -&gt; torch.tensor: if kernel_size % 2 == 1 and kernel_size &gt; 1 and kernel_size &lt; 20: kernel = gaussian_kernel(kernel_size, sigma=math.sqrt(kernel_size), verbose=verbose) kernel = kernel.reshape((1, 1, kernel_size, kernel_size)) weight = torch.from_numpy(kernel).to(torch.float32) # image padding kernel_size // 2, 使用原始图像的边缘像素进行填充 image = F.pad(image, (kernel_size // 2, kernel_size // 2, kernel_size // 2, kernel_size // 2), mode=&#39;reflect&#39;) blur = F.conv2d(image, weight, padding=0) if verbose: plt.imshow(blur.squeeze().numpy(), cmap=&#39;gray&#39;) plt.title(&#34;blur&#34;) plt.show() return blur else: return image 函数gaussian_blur :
def gaussian_blur(image: torch.tensor, kernel_size: int, verbose=False) -&gt; torch.tensor: gaussian_blur 实现了高斯滤波，首先调 gaussian_kernel 获取高斯核，然后转换为tensor类型，作为接下卷积的权重。 使用F.conv2d 进行卷积，卷积核为高斯核，卷积结果就是高斯模糊化后的图片。
sobel 算子计算梯度 # sobel 算子进行边缘检测 gradient_v = functional_conv2d_vertical(im, verbose=verbose) # 竖直梯度 gradient_h = functional_conv2d_horizontal(im, verbose=verbose) # 水平梯度 同样使用了卷积来计算梯度：F.conv2d(im, weight, stride=1, padding=0), 注意padding：im = F.pad(im, (1, 1, 1, 1), mode='replicate') ， 这里使用了复制模式。使用补零或翻转的模式都不如复制模式好。opencv 的实现也是复制模式。
关于sobel 算子的原理，可以参考另外一篇文章： # Pytorch卷积实现边缘检测 functional_conv2d_vertical 函数 与 functional_conv2d_horizontal函数的代码：
def functional_conv2d_horizontal(im, verbose=False): &#34;&#34;&#34;使用F.Conv2d进行边缘检测, 检测竖直方向的轮廓, 水平梯度，右方向为正方向 Args: im (tensor): 输入的tensor图像 Returns: tensor: 输出的tensor图像 &#34;&#34;&#34; sobel_kernel = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=&#39;float32&#39;) sobel_kernel = sobel_kernel.reshape((1, 1, 3, 3)) weight = torch.from_numpy(sobel_kernel) im = F.pad(im, (1, 1, 1, 1), mode=&#39;replicate&#39;) edge_detect = F.conv2d(im, weight, stride=1, padding=0) if verbose: plt.imshow(edge_detect.squeeze().detach().numpy(), cmap=&#39;gray&#39;) plt.title(&#34;horizontal&#34;) plt.show() return edge_detect def functional_conv2d_vertical(im, verbose=False): &#34;&#34;&#34;使用F.Conv2d进行边缘检测, 检测水平方向的轮廓， 垂直梯度，向上为正方向 Args: im (tensor): 输入的tensor图像 Returns: tensor: 输出的tensor图像 &#34;&#34;&#34; sobel_kernel = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype=&#39;float32&#39;) sobel_kernel = sobel_kernel.reshape((1, 1, 3, 3)) weight = torch.from_numpy(sobel_kernel) im = F.pad(im, (1, 1, 1, 1), mode=&#39;replicate&#39;) edge_detect = F.conv2d(im, weight, stride=1, padding=0) if verbose: plt.imshow(edge_detect.squeeze().detach().numpy() , cmap=&#39;gray&#39;) plt.title(&#34;vertical&#34;) plt.show() return edge_detect 计算梯度的幅值与方向 梯度幅值与方向将用于极大值抑制。
函数调用：
# 计算梯度幅值 gradient_magnitude = get_gradient_magnitude(gradient_v, gradient_h, verbose=verbose) # 计算梯度方向 gradient_direction_quantized = get_gradient_direction_quantized(gradient_v, gradient_h, verbose=verbose) 计算幅值 默认使用L1范数， 在opencv 的实现中，如果sobel卷积核比较大，比如16x16 会使用L2范数。 参数：gradient_v 代表垂直方向的梯度，有正负值，向上为正方向。 gradient_h 代表水平方向的梯度，有正负值，右方向为正方向。
def get_gradient_magnitude(gradient_v: torch.tensor, gradient_h: torch.tensor, verbose=False, use_l2_norm=False) -&gt; torch.tensor: &#34;&#34;&#34;计算梯度幅值 &#34;&#34;&#34; # 计算梯度的幅值 if use_l2_norm: # use l2 norm gradient_magnitude = torch.sqrt(gradient_v**2 + gradient_h**2) else: # use l1 norm gradient_magnitude = torch.abs(gradient_v) + torch.abs(gradient_h) # 将梯度幅值限制在0-255之间 # gradient_magnitude = gradient_magnitude * 255.0 / gradient_magnitude.max() if verbose: plt.imshow(gradient_magnitude.squeeze().numpy(), cmap=&#39;gray&#39;) plt.title(&#34;Gradient Magnitude&#34;) plt.show() return gradient_magnitude 计算梯度方向 这里判断梯度方向时，会将梯度方向判定为[0, 45, 90, 135]之一，用如下图表示： 这里的划分标准是： 位于[(360-22.5), 360] [0,22.5] [(180-22.5), (180+22.5)] 区间判方向为0度 下图所示： 位于[(90-22.5), (90+22.5)] [(270-22.5), (270+22.5)] 区间判方向为90度. 如下图所示： 同理，位于[135-22.5, 135+22.5] or [315-22.5, 315+22.5]区间判方向为135度. 位于[45-22.5, 45+22.5] or [225-22.5, 225+22.5]判方向为45度 如下图所示： 实际计算过程中，[0, 45, 90, 135] 4个方向分别用[0, 1, 2, 3]表示。 例如：
# 将角度值转换为四个方向之一：0度，45度，90度，135度 gradient_direction_quantized = (torch.round(gradient_direction_deg / 45) % 4).int() gradient_direction_quantized 是一个包含[0, 1, 2, 3]的tensor.
torch.round(gradient_direction_deg / 45) 这里会进行四舍五入，比如：torch.round((135+22.5) / 45) == torch.round(3.5) == 4
计算梯度方向函数：
def get_gradient_direction_quantized(gradient_v: torch.tensor, gradient_h: torch.tensor, verbose=False) -&gt; torch.tensor: &#34;&#34;&#34;计算梯度方向 将梯度方向转换为四个方向之一: 0度，45度，90度，135度, 分别用 0,1,2,3 表示。 &#34;&#34;&#34; # 计算梯度方向, 以弧度为单位 gradient_direction = torch.atan2(gradient_v, gradient_h) # 将梯度方向转换为角度值, 并将角度值转换为0-360度之间 gradient_direction_deg = torch.rad2deg(gradient_direction) + 180 # 将角度值转换为四个方向之一：0度，45度，90度，135度 gradient_direction_quantized = (torch.round(gradient_direction_deg / 45) % 4).int() if verbose: print(&#34;gradient_direction_quantized: &#34;, gradient_direction_quantized) return gradient_direction_quantized 梯度的极大值抑制 极大值抑制算法： 进行极大值抑制时会对周边先padding一圈0，然后对某个像素进行极大值抑制时，然后判断当前像素的方向，方向分别用0, 1, 2, 3表示，代表着0度、45度、90度，135度。假设当前像素是135度的方向，所以会比较135度方向上另外2个像素，如果当前像素的坐标是(0,0), 那么另两个像素的坐标就是(-1,1）(1,-1)，注意即使另两个像素不是135度，依然选这两个坐标，另两个像素是不是135度不重要，至于为什么，我也不知道如何解释。这种情况下，遍历每个像素就得到了极大值抑制的结果。
可以使用pytorch 的卷积来实现, 先定义一个卷积：
nms_conv_op = torch.nn.Conv2d(in_channels=1,out_channels=3, kernel_size=3, stride=1, padding=1, bias=False) 它的输出通道为3， 这意味着卷积的通道为3 例如：
quantized_0_list = [[[0, 0, 0],[1, 0, 0],[0, 0, 0]], [[0, 0, 0],[0, 1, 0],[0, 0, 0]], [[0, 0, 0],[0, 0, 1],[0, 0, 0]]] 这是选取0度方向的卷积核，作用是选取该方向上的3个元素，每个卷积核选中某个方向上的一个元素。 第一个通道：[[0, 0, 0],[1, 0, 0],[0, 0, 0]] 将会选择当前元素左边的元素。第二个通道选择当前元素，第3个通道选择当前元素右边的元素。 45度、90度，135度 的情况也是类似，这里就不多赘述了。 由于有4个方向，因此会进行4次卷积. 假设输入gradient_magnitude的shape 是(1,1,n,m), 那么输出的nms_edge 的shape 是 (1,3,n,m) , 这里3 表示3通道，保存着对应位置某个方向上的3个元素。
mask_i = (gradient_direction_quantized == i).int(): 获取某个方向上的mask. nms_direction_conv_mask_i = nms_direction_conv_i * mask_i: 将某次卷积的结果与mask_i 相乘，只选择掩码所标识位置的值。shape 是 (1,3,n,m)， nms_direction_conv_mask_max_i, _ = torch.max(nms_direction_conv_mask_i, dim=1): 最后选择nms_direction_conv_mask_i 维度1上（3通道）最大的值, nms_direction_conv_mask_max_i 的形状变为(1,1,n,m)
nms_edge = nms_edge + ((gradient_magnitude == nms_direction_conv_mask_max_i) * nms_direction_conv_mask_max_i) nms_direction_conv_mask_max_i 中每个元素，表示该元素在i方向上最大的值， 但是这个最大值不一定是当前的元素。 (gradient_magnitude == nms_direction_conv_mask_max_i): 当前元素如果是最大的，那么选中，否者放弃。 (gradient_magnitude == nms_direction_conv_mask_max_i) 返回的0, 1的矩阵，所以还需乘nms_direction_conv_mask_max_i 来选中对应的元素，最后加入到最终的输出nms_edge。
完整程序：
def nms(gradient_magnitude: torch.tensor, gradient_direction_quantized: torch.tensor, verbose=False) -&gt; torch.tensor: &#34;&#34;&#34;非极大值抑制&#34;&#34;&#34; nms_edge = torch.zeros_like(gradient_magnitude) nms_conv_op = torch.nn.Conv2d(in_channels=1,out_channels=3, kernel_size=3, stride=1, padding=1, bias=False) quantized_0_list = [[[0, 0, 0],[1, 0, 0],[0, 0, 0]], [[0, 0, 0],[0, 1, 0],[0, 0, 0]], [[0, 0, 0],[0, 0, 1],[0, 0, 0]]] quantized_1_list = [[[0, 1, 0],[0, 0, 0],[0, 0, 0]], [[0, 0, 0],[0, 1, 0],[0, 0, 0]], [[0, 0, 0],[0, 0, 0],[0, 1, 0]]] quantized_2_list = [[[0, 1, 0],[0, 0, 0],[0, 0, 0]], [[0, 0, 0],[0, 1, 0],[0, 0, 0]], [[0, 0, 0],[0, 0, 0],[0, 1, 0]]] quantized_3_list = [[[1, 0, 0],[0, 0, 0],[0, 0, 0]], [[0, 0, 0],[0, 1, 0],[0, 0, 0]], [[0, 0, 0],[0, 0, 0],[0, 0, 1]]] kernel_0 = torch.tensor(quantized_0_list, dtype=torch.float32) kernel_1 = torch.tensor(quantized_1_list, dtype=torch.float32) kernel_2 = torch.tensor(quantized_2_list, dtype=torch.float32) kernel_3 = torch.tensor(quantized_3_list, dtype=torch.float32) kernel_direction_quantized = [kernel_0, kernel_1, kernel_2, kernel_3] for i in range(4): mask_i = (gradient_direction_quantized == i).int() if verbose: print(&#34;mask_i: &#34;, mask_i) nms_conv_op.weight.data = kernel_direction_quantized[i].reshape((3, 1, 3, 3)) nms_direction_conv_i = nms_conv_op(gradient_magnitude) nms_direction_conv_mask_i = nms_direction_conv_i * mask_i nms_direction_conv_mask_max_i, _ = torch.max(nms_direction_conv_mask_i, dim=1) if verbose: print(&#34;nms_direction_conv_mask_max_i: &#34;, nms_direction_conv_mask_max_i) print(&#34;nms_direction_i: &#34;, nms_direction_conv_mask_max_i) nms_edge = nms_edge + ((gradient_magnitude == nms_direction_conv_mask_max_i) * nms_direction_conv_mask_max_i) if verbose: print(&#34;nms_edge: &#34;, nms_edge) # verbose = True if verbose: plt.imshow(nms_edge.squeeze().detach().numpy(), cmap=&#39;gray&#39;) plt.title(&#34;Non-Maximum Suppression&#34;) plt.show() return nms_edge 滞后阈值 滞后阈值的目的是为了连接间断点，具有更好的鲁棒性。 例如：
# 普通双边阈值处理 edge_detect = threshold(nms_edge, low=threshold_low, high=threshold_high, weak=50, strong=255) # 滞后阈值 edge_detect = hysteresis_threshold(nms_edge, low=threshold_low, high=threshold_high) 同样的命令：
python pytorch-canny.py -v -i data/lena.png -gk 0 -L 100 -H 200 使用滞后阈值的结果，普通双边阈值处理的结果分别是：
算法步骤：
hysteresis_threshold 输入: nms_edge 是一个极大值值抑制后的tensor low 低阈值 high 高阈值 分类： 不考虑低于low 的元素 高于 high 的元素 记为强边缘，strong_mask记录位置 大于low 小于 high 的元素记为弱边缘，weak_mask记录位置 将强边缘放入栈中，然后开始循环栈中的元素，先弹出栈中一个元素（强边缘），然后判断周围8个位置中是否存在弱边缘，如果存在，将弱边缘元素入栈，然后将当前元素输出到output_index中，表示该强边缘元素处理结束。另外由于周围8个位置中的弱边缘已经入栈，为了防止重复入栈，将weak_mask对应位置设置为0。直到栈为空。 最后根据 output_index 中的位置，返回最后的边缘检测图。 程序：
def hysteresis_threshold(nms_edge: torch.tensor, low: int, high: int) -&gt; torch.tensor: nms_edge = nms_edge.squeeze() strong_mask = nms_edge &gt;= high weak_mask = (nms_edge &gt; low) &amp; (nms_edge &lt; high).int() output_index = [] # get strong_mask index strong_index = torch.nonzero(strong_mask).tolist() # create stack and push strong_index stack = deque(strong_index) while len(stack) &gt; 0: # pop item item = stack.pop() # get item index i, j = item[0], item[1] # get weak_mask index local_index = torch.nonzero(weak_mask[i-1:i+2, j-1:j+2]).tolist() for local_index_item in local_index: # stack.append(weak_index[i]) weak_index_item = [i-1+local_index_item[0], j-1+local_index_item[1]] stack.append(weak_index_item) weak_mask[weak_index_item[0], weak_index_item[1]] = 0 output_index.append(item) # create output tensor use output_index output_index_tensor = torch.tensor(output_index) # (N, 2) output = torch.zeros_like(nms_edge) output[output_index_tensor[:, 0], output_index_tensor[:, 1]] = 255 return output 与opencv 算法对比 opencv canny算法:
import cv2 import numpy as np from matplotlib import pyplot as plt import time if __name__ == &#39;__main__&#39;: img = cv2.imread(&#39;data/lena.png&#39;,0) start_time = time.time() edges = cv2.Canny(img,100,200) print(&#34;time: &#34;, time.time() - start_time) plt.subplot(121),plt.imshow(img,cmap = &#39;gray&#39;) plt.title(&#39;Original Image&#39;), plt.xticks([]), plt.yticks([]) plt.subplot(122),plt.imshow(edges,cmap = &#39;gray&#39;) plt.title(&#39;Edge Image&#39;), plt.xticks([]), plt.yticks([]) plt.show() print(&#34;end&#34;) # 保存图片 cv2.imwrite(&#34;data/opencv_edge_detect.png&#34;, edges) 同样的输入图片： opencv 输出与本文pytorch 实现的输出一样： 都使用cpu 的情况下，opencv 的处理速度非常快：是本文pytorch 实现的30倍。 本文pytorch 实现需要的时间：time: 0.0885 而opencv 实现需要的时间：time: 0.0030 非常amazing, 竟然慢这么多，笔者还运行过别人 纯python的实现 ，结论是非常慢。
sobel算子的 padding 对极大值抑制的影响 Canny算法中sobel算子padding的方式对极大值抑制的影响 参考 https://github.com/opencv/opencv/blob/2.2/modules/imgproc/src/canny.cpp https://github.com/adeveloperdiary/blog/tree/master/Computer_Vision/Canny_Edge_Detection ]]></content></entry><entry><title>Opencv Canny 源码解析</title><url>/opencv-canny-source-code-analysis.html</url><categories><category>programming</category></categories><tags><tag>opencv</tag><tag>c++</tag></tags><content type="html"><![CDATA[void cv::Canny( const Mat&amp; image, Mat&amp; edges, double threshold1, double threshold2, int apertureSize, bool L2gradient ) { Mat src = image; edges.create(src.size(), CV_8U); CvMat _src = src, _dst = edges; cvCanny( &amp;_src, &amp;_dst, threshold1, threshold2, apertureSize + (L2gradient ? CV_CANNY_L2_GRADIENT : 0)); } 这里使用的代码是opencv 2.2 版本的代码，也是最早的代码，与最新版本的代码相比，基本思想不变，最重要的是代码结构简单，是最容易理解的版本。 本文主要是对代码进行了行间注释，解释canny 算法的c++实现细节。
阅读前提：
已经理解canny 算法的基本原理，包括sobel 算子获取梯度图，canny 算法使用的极大值抑制与滞后阈值。 希望了解opencv 的c++ 算法实现。 源码地址：https://github.com/opencv/opencv/blob/2.2/modules/imgproc/src/canny.cpp
canny函数接口 canny函数 调用了cvCanny， cvCanny 是主要的函数。 默认计算梯度幅值，使用L1范数，如果使用L2范数，实际的sobel 算子 大小= apertureSize + CV_CANNY_L2_GRADIENT 。CV_CANNY_L2_GRADIENT 的值为16
为了减少计算复杂度，使用L1范数更快。
void cv::Canny( const Mat&amp; image, Mat&amp; edges, double threshold1, double threshold2, int apertureSize, bool L2gradient ) { Mat src = image; edges.create(src.size(), CV_8U); CvMat _src = src, _dst = edges; cvCanny( &amp;_src, &amp;_dst, threshold1, threshold2, apertureSize + (L2gradient ? CV_CANNY_L2_GRADIENT : 0)); } cvCanny函数签名 CV_IMPL void cvCanny( const void* srcarr, void* dstarr, double low_thresh, double high_thresh, int aperture_size ) CV_IMPL: 这是一个宏定义，值为：extern &quot;C&quot;, 在 C++ 中，函数名会被编译器进行符号重载，即会根据函数参数的类型和数量生成不同的符号名。然而，C 函数没有符号重载的概念，因此在 C++ 代码中调用 C 函数时，需要使用 extern &quot;C&quot; 来告诉编译器使用 C 的链接规则来编译和链接这个函数。这样可以保证 C++ 代码和 C 代码之间的函数调用正确地进行。
cvCanny 函数的参数：
srcarr: 输入图片的指针
dstarr: 保存输出图片的指针
low_thresh: 低阈值，在cvCanny函数中，有一个步骤叫做极大值抑制，它处理的是梯度幅值图（稍后解释），其中它会将低于阈值的像素标记为非边缘，注意极大值抑制不止是标记像素，极大值抑制还有很多其他的步骤, 这里只是稍微解释low_thresh参数的一点含义。
high_thresh: 高阈值,同理,Canny算法处理过程中,会将高于该值的像素标记轮廓,而处于低阈值与高阈值中间的值标记为弱轮廓。注意:canny 算法最后输出的轮廓点包含:轮廓点与经过滞后阈值(稍后解释)的弱轮廓点.
aperture_size: sobel kernel size，一般是3x3的矩阵，soebel算法是为了得到梯度图。
接下来都是cvCanny函数的实现细节
获取梯度图 // get the src size size = cvGetMatSize( src ); // horizontal gradient dx = cvCreateMat( size.height, size.width, CV_16SC1 ); // vertical gradient dy = cvCreateMat( size.height, size.width, CV_16SC1 ); // get the horizontal gradient cvSobel( src, dx, 1, 0, aperture_size ); // get the vertical gradient cvSobel( src, dy, 0, 1, aperture_size ); 环形缓存区与边缘点缓存(map) 定义了3个缓存区：mag_buf[0]， mag_buf[1]， mag_buf[2]，之所以说它们是环形缓存区后面再解释。 边缘点缓存(map)，是用于保存轮廓点映射，在极大值抑制与滞后阈值中会使用，后面再具体解释。
这里贴出了代码，并进行了较为详细注释。
// allocates buffer, because 2 padding added, so size.width and size.height should add 2 buffer.allocate( (size.width+2)*(size.height+2) + (size.width+2)*3*sizeof(int) ); // First convert it to a char* type, and then convert it to an int* type. mag_buf[0] = (int*)(char*)buffer; // mag_buf[1] points to the second gradient cache, and the width is increased by 2 here because the gradient map needs to be padded with 1 on the left and right sides. mag_buf[1] = mag_buf[0] + size.width + 2; // Similarly, mag_buf[2] points to the third cache. mag_buf[2] = mag_buf[1] + size.width + 2; // Get the end position of the mag_buf[2] cache and then convert it to a uchar* type. The area pointed to by the pointer will be used for mapping contour points in the future. The mapped values ​​are 0, 1, and 2, which represent weak contour, non-contour, and strong contour, respectively. map = (uchar*)(mag_buf[2] + size.width + 2); // represents map area width mapstep = size.width + 2; // 1 &lt;&lt; 10 represents 1024 maxsize = MAX( 1 &lt;&lt; 10, size.width*size.height/10 ); // the stack is used to restore strong contour points, and the stack used for Hysteresis threshold stack.resize( maxsize ); // &amp;stack[0] is the stack[0] pointer stack_top = stack_bottom = &amp;stack[0]; // mag_buf[0] is the first gradient cache, and (size.width+2)*sizeof(int) bytes is set 0 memset( mag_buf[0], 0, (size.width+2)*sizeof(int) ); // Consider the area pointed by th map pointer. the area&#39;s fisrt row and last row set to 1 which represents non-contour memset( map, 1, mapstep ); memset( map + mapstep*(size.height + 1), 1, mapstep ); 极大值抑制，边缘点入栈 入栈与出栈宏定义：d 代表着 轮廓点的地址。
#define CANNY_PUSH(d) *(d) = (uchar)2, *stack_top++ = (d) #define CANNY_POP(d) (d) = *--stack_top 接下来继续介绍实现细节，这里贴出了代码，并进行了较为详细注释。
// calculate magnitude and angle of gradient, perform non-maxima supression. // fill the map with one of the following values: // 0 - the pixel might belong to an edge // 1 - the pixel can not belong to an edge // 2 - the pixel does belong to an edge for( i = 0; i &lt;= size.height; i++ ) { // get the latest mag_buf, firstly is mag_buf[1], later is magbuf[2] int* _mag = mag_buf[(i &gt; 0) + 1] + 1; // there float and int have same bytes float* _magf = (float*)_mag; // get dx i-th row pointer const short* _dx = (short*)(dx-&gt;data.ptr + dx-&gt;step*i); // get dy i-th row pointer const short* _dy = (short*)(dy-&gt;data.ptr + dy-&gt;step*i); uchar* _map; int x, y; ptrdiff_t magstep1, magstep2; // in the same row , if The previous one pixel belong to an edge, then the flag is 1 int prev_flag = 0; if( i &lt; size.height ) { // in i-th row, first and last pixel set to 0 _mag[-1] = _mag[size.width] = 0; if( !(flags &amp; CV_CANNY_L2_GRADIENT) ) for( j = 0; j &lt; size.width; j++ ) // calculate the magnitude _mag[j] = abs(_dx[j]) + abs(_dy[j]); /*else if( icvFilterSobelVert_8u16s_C1R_p != 0 ) // check for IPP { // use vectorized sqrt mag_row.data.fl = _magf; for( j = 0; j &lt; size.width; j++ ) { x = _dx[j]; y = _dy[j]; _magf[j] = (float)((double)x*x + (double)y*y); } cvPow( &amp;mag_row, &amp;mag_row, 0.5 ); }*/ else { for( j = 0; j &lt; size.width; j++ ) { x = _dx[j]; y = _dy[j]; _magf[j] = (float)std::sqrt((double)x*x + (double)y*y); } } } else // when reach the bottom, padding 0 to magbuf[2] memset( _mag-1, 0, (size.width + 2)*sizeof(int) ); // at the very beginning we do not have a complete ring // buffer of 3 magnitude rows for non-maxima suppression if( i == 0 ) continue; // get pointer in map which point to i-th row and 1 col pixel. add one is because padding 1 in map _map = map + mapstep*i + 1; // first and last pixel set 1 which means non-contour or non-edge _map[-1] = _map[size.width] = 1; // the central row , previous is mag_buf[0] the next one is mag_buf[2] _mag = mag_buf[1] + 1; // take the central row // get the previous row pointer of dx , the current one is i-th row, but the (i-1)-th row perform non-maxima supression _dx = (short*)(dx-&gt;data.ptr + dx-&gt;step*(i-1)); _dy = (short*)(dy-&gt;data.ptr + dy-&gt;step*(i-1)); // calculate distance, magstep1 is the distance next row to current row in the same col。magstep2 is current row to previous row in the same col magstep1 = mag_buf[2] - mag_buf[1]; magstep2 = mag_buf[0] - mag_buf[1]; if( (stack_top - stack_bottom) + size.width &gt; maxsize ) { int sz = (int)(stack_top - stack_bottom); maxsize = MAX( maxsize * 3/2, maxsize + 8 ); stack.resize(maxsize); stack_bottom = &amp;stack[0]; stack_top = stack_bottom + sz; } for( j = 0; j &lt; size.width; j++ ) { #define CANNY_SHIFT 15 // TG22 is Integer type, it is convenient for calculation, represent 22.5 degrees #define TG22 (int)(0.4142135623730950488016887242097*(1&lt;&lt;CANNY_SHIFT) + 0.5) x = _dx[j]; y = _dy[j]; // if x and y are same sign s = 1, else s = 0 int s = x ^ y; int m = _mag[j]; x = abs(x); y = abs(y); if( m &gt; low ) { int tg22x = x * TG22; int tg67x = tg22x + ((x + x) &lt;&lt; CANNY_SHIFT); y &lt;&lt;= CANNY_SHIFT; // y &lt; tg22x represent angle of gradient more than (360-22.5)) degrees and less than 22.5 degrees. more than (180-22.5) degrees and less than (180+22.5) degrees if( y &lt; tg22x ) { // Compare magnitude in the 0-degree direction if( m &gt; _mag[j-1] &amp;&amp; m &gt;= _mag[j+1] ) { // !prev_flag and _map[j-mapstep]!= 2 make nearby pixels Both are edges， It reduces the workload of hysteresis threshold. if( m &gt; high &amp;&amp; !prev_flag &amp;&amp; _map[j-mapstep] != 2 ) { // push postion of (_map+j) into stack, it is edges, it will set 2 CANNY_PUSH( _map + j ); prev_flag = 1; } else // maybe a edge _map[j] = (uchar)0; // if prev_flag == 1, next time !prev_flag != 1 continue; } } // y &gt; tg67x represent angle of gradient more than (90-22.5) degrees less than (90+22.5) degrees. more than (270-22.5) degress and less (270+22.5) degrees. else if( y &gt; tg67x ) { // Compare magnitude in the 90-degree direction if( m &gt; _mag[j+magstep2] &amp;&amp; m &gt;= _mag[j+magstep1] ) { if( m &gt; high &amp;&amp; !prev_flag &amp;&amp; _map[j-mapstep] != 2 ) { CANNY_PUSH( _map + j ); prev_flag = 1; } else _map[j] = (uchar)0; continue; } } else // when s == -1, represent angle of gradient is between the [135-22.5, 135+22.5] or [315-22.5, 315+22.5] // when s == 1, represent angle of gradient is between the [45-22.5, 45+22.5] or [225-22.5, 225+22.5] { s = s &lt; 0 ? -1 : 1; // Compare magnitude in the 45-degree or 135-degree direction if( m &gt; _mag[j+magstep2-s] &amp;&amp; m &gt; _mag[j+magstep1+s] ) { if( m &gt; high &amp;&amp; !prev_flag &amp;&amp; _map[j-mapstep] != 2 ) { CANNY_PUSH( _map + j ); prev_flag = 1; } else _map[j] = (uchar)0; continue; } } } // this loop no edge, set flag 0 , so next time !prev_flag will be true prev_flag = 0; // 1 represent not a edge _map[j] = (uchar)1; } // scroll the ring buffer _mag = mag_buf[0]; mag_buf[0] = mag_buf[1]; mag_buf[1] = mag_buf[2]; mag_buf[2] = _mag; } 极大值抑制采用了循环缓存，分别是mag_buf[0] mag_buf[1] mag_buf[2]， 并会进行循环移动，保证mag_buf[1]是用来执行极大值抑制的行。 并在边缘梯度周围补0，这个解释了 一开始mag_buf[0] 设置为0， 循环到最后时，mag_buf[2]也设置为0 另外缓存的第一个元素与最后一个元素都是0。
!prev_flag &amp;&amp; _map[j-mapstep] != 2 这个判断上次循环已经当前列的上一行是否已经存在边缘，如果存在，那么这个位置的像素就不算边缘，这样可以减少滞后阈值的计算量，因为滞后阈值会判断当前像素的周围是否标记为0的像素，如果存在，那么也记为边缘。为了减少重复计算，这里极大值抑制就通过这种方式减少了入栈的像素，以此来减少计算量。
这里判断梯度方向时，会将梯度方向判定为[0, 45, 90, 135]之一，用如下图表示： 滞后阈值 滞后阈值的的作用是将一些可能是边缘点的像素设置为边缘点，这可以连接一些间断了的边缘，提高边缘检测的鲁棒性。
滞后阈值的代码比较简短，主要是将边缘点出栈，然后判断改点8个方向上是否存在标记为0的边缘点，如果存在，那么该点也入栈，并标记为边缘点，一直到栈为空。
// now track the edges (hysteresis thresholding) while( stack_top &gt; stack_bottom ) { uchar* m; if( (stack_top - stack_bottom) + 8 &gt; maxsize ) { int sz = (int)(stack_top - stack_bottom); maxsize = MAX( maxsize * 3/2, maxsize + 8 ); stack.resize(maxsize); stack_bottom = &amp;stack[0]; stack_top = stack_bottom + sz; } CANNY_POP(m); if( !m[-1] ) CANNY_PUSH( m - 1 ); if( !m[1] ) CANNY_PUSH( m + 1 ); if( !m[-mapstep-1] ) CANNY_PUSH( m - mapstep - 1 ); if( !m[-mapstep] ) CANNY_PUSH( m - mapstep ); if( !m[-mapstep+1] ) CANNY_PUSH( m - mapstep + 1 ); if( !m[mapstep-1] ) CANNY_PUSH( m + mapstep - 1 ); if( !m[mapstep] ) CANNY_PUSH( m + mapstep ); if( !m[mapstep+1] ) CANNY_PUSH( m + mapstep + 1 ); } 构造最后的边缘图片 // the final pass, form the final image for( i = 0; i &lt; size.height; i++ ) { const uchar* _map = map + mapstep*(i+1) + 1; uchar* _dst = dst-&gt;data.ptr + dst-&gt;step*i; for( j = 0; j &lt; size.width; j++ ) _dst[j] = (uchar)-(_map[j] &gt;&gt; 1); } _map[j] 如果是0， (_map[j] &gt;&gt; 1) 还是0， -(_map[j] &gt;&gt; 1) 是0， (uchar)-(_map[j] &gt;&gt; 1) 是0 _map[j] 如果是1，(_map[j] &gt;&gt; 1) 还是0，-(_map[j] &gt;&gt; 1) 是0， (uchar)-(_map[j] &gt;&gt; 1) 是0 _map[j] 如果是2，(_map[j] &gt;&gt; 1) 是1，-(_map[j] &gt;&gt; 1) 是-1， (uchar)-(_map[j] &gt;&gt; 1) 是255
所以只有标记为2的像素会以225的值输出。
]]></content></entry><entry><title>PyTorch DataLoader的工作机制</title><url>/pytorch-dataloader.html</url><categories><category>programming</category></categories><tags><tag>进程</tag><tag>pytorch</tag><tag>死锁</tag></tags><content type="html"><![CDATA[ PyTorch-DataLoader的工作机制
dataset、sampler 与 dataloader的关系？ dataloader.py 主进程与工作进程的关系？ 数据时如何从迭代器DataLoaderIter返回的？ dataloader.py中主进程和工作进程是何时切换的？会发生死锁吗？ 阅读前提：
了解 pytorch dataloader 的基本用法 最近调试代码时，遇到了PyTorch多进程加载数据的问题，在windows中遇到多进程启动失败的问题，问题连接：https://pytorch.org/docs/stable/notes/windows.html#multiprocessing-error-without-if-clause-protection 然后在github的issue 找到了解决办法：在if __name__ == '__main__':中去启动dataloader的迭代，这样可以避免启动子进程时windows系统又去启动dataloader的迭代。虽然问题解决了，但是我比较好奇，DataLoader多进程加载数据的机制。
为了学习DataLoader的机制，最好是看它的源码，而且看最早期的源码，因为比较简单，但核心思想是一致的。因此我看了PyTorch v0.1.4 版本的源码，比现在最新版本的源码简单多了。看完之后总算对多进程加载数据有了更清楚的理解，也理解了其中进程之间队列的死锁问题及其处理方法。
代码： github v0.1.4 版本的 dataloader.py
https://github.com/pytorch/pytorch/blob/v0.1.4/torch/utils/data/dataloader.py https://github.com/pytorch/pytorch/blob/v0.1.4/torch/utils/data/dataset.py https://github.com/pytorch/pytorch/blob/v0.1.4/torch/utils/data/sampler.py dataset、sampler 与 dataloader的关系？ dataset 提供索引的数据 sampler 提供如何返回dataset的index,比如：顺序与随机 dataloader 提供一个batch的数据，并通过多进程的方式返回数据。它可以通过sampler 构造一个batch index ,然后利用多进程、队列的方法调用dataset的方法来返回一个batch的数据。
dataset源码：
class Dataset(object): def __getitem__(self, index): raise NotImplementedError def __len__(self): raise NotImplementedError class TensorDataset(Dataset): def __init__(self, data_tensor, target_tensor): assert data_tensor.size(0) == target_tensor.size(0) self.data_tensor = data_tensor self.target_tensor = target_tensor if self.data_tensor.dim() == 1: self.data_tensor = self.data_tensor.view(-1, 1) if self.target_tensor.dim() == 1: self.target_tensor = self.target_tensor.view(-1, 1) def __getitem__(self, index): return self.data_tensor[index], self.target_tensor[index] def __len__(self): return self.data_tensor.size(0) sampler 源码：
class Sampler(object): def __init__(self, data_source): pass def __iter__(self): raise NotImplementedError def __len__(self): raise NotImplementedError class SequentialSampler(Sampler): def __init__(self, data_source): self.num_samples = len(data_source) def __iter__(self): return iter(range(self.num_samples)) def __len__(self): return self.num_samples class RandomSampler(Sampler): def __init__(self, data_source): self.num_samples = len(data_source) def __iter__(self): return iter(torch.randperm(self.num_samples).long()) def __len__(self): return self.num_samples dataloader 源码：
class DataLoader(object): &#34;&#34;&#34; Data loader. Combines a dataset and a sampler, and provides single- or multi-process iterators over the dataset. &#34;&#34;&#34; def __init__(self, dataset, batch_size=1, shuffle=False, sampler=None, num_workers=0, collate_fn=default_collate): self.dataset = dataset self.batch_size = batch_size self.num_workers = num_workers self.collate_fn = collate_fn if sampler is not None: self.sampler = sampler elif shuffle: self.sampler = RandomSampler(dataset) elif not shuffle: self.sampler = SequentialSampler(dataset) def __iter__(self): return DataLoaderIter(self) def __len__(self): return len(self.sampler) dataloader.py 主进程与工作进程的关系？ DataLoader 类：
class DataLoader(object): &#34;&#34;&#34; Data loader. Combines a dataset and a sampler, and provides single- or multi-process iterators over the dataset. &#34;&#34;&#34; def __init__(self, dataset, batch_size=1, shuffle=False, sampler=None, num_workers=0, collate_fn=default_collate): self.dataset = dataset self.batch_size = batch_size self.num_workers = num_workers self.collate_fn = collate_fn if sampler is not None: self.sampler = sampler elif shuffle: self.sampler = RandomSampler(dataset) elif not shuffle: self.sampler = SequentialSampler(dataset) def __iter__(self): return DataLoaderIter(self) def __len__(self): return len(self.sampler) DataLoader 类中定义了__iter__， __iter__ 是一个特殊方法（special method），用于定义一个可迭代对象（iterable）。可迭代对象是指实现了 __iter__ 方法的对象，该方法返回一个迭代器（iterator）。 这个迭代器是：DataLoaderIter，它__init__方法中定义了两个队列，用于进程之间的通信，如下所示：
class DataLoaderIter(object): &#34;Iterates once over the DataLoader&#39;s dataset, as specified by the sampler&#34; # loader 是 DataLoader 的实例 def __init__(self, loader): self.dataset = loader.dataset self.batch_size = loader.batch_size self.collate_fn = loader.collate_fn self.sampler = loader.sampler self.num_workers = loader.num_workers self.samples_remaining = len(self.sampler) self.sample_iter = iter(self.sampler) if self.num_workers: self.index_queue = multiprocessing.Queue() self.data_queue = multiprocessing.Queue() self.batches_outstanding = 0 self.joined = False self.workers = [ multiprocessing.Process( target=_workerLoop, args=(self.dataset, self.index_queue, self.data_queue, self.collate_fn)) for i in range(self.num_workers)] for w in self.workers: w.daemon = True # ensure that the worker exits on process exit w.start() # prime the prefetch loop with exactly 1 batch per process # this ensures no deadlocks on the queues using the blocking queue API self._putBatch() 其中self.index_queue 表示一个batch的索引，数据的填入由主进程完成，工作进程会从self.index_queue队列中获取数据，然后将一个批量的数据放入另外一个队列：self.data_queue 然后又next函数返回给迭代器的调用者。
数据时如何从迭代器DataLoaderIter返回的？ 迭代器DataLoaderIter 中定义了__next__方法：
def next(self): if self.num_workers: # multi-process loading if self.batches_outstanding: assert(not self.joined) # maintain at most len(workers)+1 outstanding batches # to avoid deadlocks in the queues, using the blocking queue API # TODO: add and use non-blocking queue API self._putBatch() assert(self.batches_outstanding &lt;= len(self.workers) + 1) self.batches_outstanding -= 1 data = self.data_queue.get() if isinstance(data, ExceptionWrapper): raise data.exc_type(data.exc_msg) else: return data else: self._joinWorkers() raise StopIteration() else: # single-process loading if self.samples_remaining: return _processBatch(self.dataset, self._nextBatch(), self.collate_fn) else: raise StopIteration() __next__ = next 当dataloader开启多进程时，self.num_workers 表示进程的数量，self.batches_outstanding记录 self.index_queue batch index 的数量，然后先执行self._putBatch()往self.index_queue添加一个batch&rsquo;s index ,然后执行data = self.data_queue.get()来获取一个batch的数据，然后返回data, 这就完成一个迭代过程。
dataloader.py中主进程和工作进程是何时切换的？会发生死锁吗？ PyTorch 中的多进程数据加载机制使用了阻塞式队列（blocking queue）来进行进程间通信。阻塞式队列在队列为空或队列已满时会自动阻塞，直到有新的数据可用或队列中有空余空间为止。但是当工作进程A想要从空队列中取数据时，它首先会获得队列加锁，其他进程暂时无法访问队列。但是工作进程A由于取不到数据，也会被阻塞。这时候操作系统切换到主进程后，依然可以向空队列发送数据，因为工作进程A已经阻塞了。
具体解释是： 在阻塞式队列中，如果一个进程A想要从空队列（阻塞式队列）中获取数据，它会被自动阻塞，并等待队列中有新的数据可用。如果队列中一直没有数据，那么进程A会被阻塞并挂起。在这种情况下，工作进程A通常会释放对队列的锁，允许其他进程访问该队列。这是因为阻塞式队列的设计目的之一就是允许多个生产者和消费者并发地访问队列。
其它工作进程在空队列上等待，如果主进程取得cpu控制权，此时，由于工作队列已经释放了锁，主进程可以成功向队列中发送数据，并且有数据可用，它可以向队列中发送数据。后来当工作进程会被唤醒时，就可以获取到数据，并继续执行后续操作。
需要注意的是，当多个进程同时访问同一个队列时，可能会出现一些竞争条件和锁竞争的情况。这时候就需要使用线程安全的队列（如 queue.Queue）或者进程安全的队列（如 multiprocessing.Queue）来保证多个进程之间的数据交换安全可靠。此外，为了避免死锁和竞争条件等问题，还需要合理地设置队列的容量和缓冲策略。
启动多进程的过程：
for w in self.workers: w.daemon = True # ensure that the worker exits on process exit w.start() # prime the prefetch loop with exactly 1 batch per process # this ensures no deadlocks on the queues using the blocking queue API self._putBatch() w.daemon = True ： 将工作进程A放入后台 w.start() ：启动工作进程A self._putBatch() ：向 self.index_queue 发送一个批量的索引，免得在主进程执行next 函数时发送死锁。
当启动工作进程A后，就算主进程没来得及向执行self._putBatch()也没关系，因为工作进程A由于获取不到数据最后会被挂起，并且工作进程A通常会释放对队列的锁。那么切换到主进程后可以继续执行self._putBatch()，最后在主进程调用next()函数从队列（self.data_queue）中拿数据时能拿到数据，因为工作进程由于之前的self._putBatch()函数会往队列self.index_queue发送了数据，然后工作队列会根据self.index_queue的数据往队列（self.data_queue）发送数据，所有下一次主进程向队列（self.data_queue）中拿数据时，可以保证拿到数据，不会造成死锁的局面。
这种死锁的局面就是：主进程向空队列（self.data_queue）拿数据，但是由于是空队列，于是阻塞挂起了 而工作进程也在向空队列（self.index_queue）拿数据，但是由于是空队列，于是阻塞也挂起了。于是都挂起了，但是self.index_queue需要主进程往其中填数据，才能保证工作往队列（self.data_queue）填数据。这样这两个进程互相死锁了。
为了避免这种死锁的情况，在主进程向空队列（self.data_queue）拿数据前要先执行self._putBatch()
]]></content></entry><entry><title>Pytorch卷积实现边缘检测</title><url>/pytorch-Edge-detection-using-convolution.html</url><categories><category>programming</category></categories><tags><tag>pytorch</tag><tag>卷积</tag></tags><content type="html"><![CDATA[ 本文调用 pytorch 的卷积函数，实现两种边缘检测：
边缘检测（突出中间值） sobel(索贝尔) 边缘检测 对比这两种实现，sobel(索贝尔) 边缘检测 的检测效果看起来更清楚。
阅读前提：
了解深度学习卷积的概念 了解pytorch 的卷积函数、tensor数据类型 边缘检测（突出中间值） 卷积核：
[[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]] 检测效果 第一个例子 输入：cat.jpg
卷积参数： kernel_size=3, padding=1, stride=1，输出的图像与原图大小一致。 卷积效果： 第二个例子 原图 卷积参数： kernel_size=3, padding=1, stride=1，输出的图像与原图大小一致。
卷积结果（图片放大了）： 卷积函数 卷积核：
[[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]] def nn_conv2d_2(im): # 用nn.Conv2d定义卷积操作，padding=1, stride=1 conv_op = nn.Conv2d(1, 1, 3, bias=False, stride=1, padding=1) # 定义卷积算子参数 kernel = np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]], dtype=&#39;float32&#39;) # 将卷积算子转换为适配卷积操作的卷积核 kernel = kernel.reshape((1, 1, 3, 3)) # 给卷积操作的卷积核赋值 conv_op.weight.data = torch.from_numpy(kernel) # 对图像进行卷积操作, kernel_size=3, padding=1, stride=1，输出的图像与原图大小一致。 edge_detect = conv_op(im) # 将输出转换为图片格式 return edge_detect 完整程序 import torch import numpy as np from torch import nn from PIL import Image import torch.nn.functional as F import os def functional_conv2d(im): kernel = np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]], dtype=&#39;float32&#39;) kernel = kernel.reshape((1, 1, 3, 3)) weight = torch.from_numpy(kernel) # 对图像进行卷积操作, kernel_size=3,padding=1, stride=1， 输出的图像与原图大小一致。 edge_detect = F.conv2d(im, weight, padding=1) return edge_detect def nn_conv2d_2(im): # 用nn.Conv2d定义卷积操作，padding=1, stride=1 conv_op = nn.Conv2d(1, 1, 3, bias=False, stride=1, padding=1) # 定义卷积算子参数 kernel = np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]], dtype=&#39;float32&#39;) # 将卷积算子转换为适配卷积操作的卷积核 kernel = kernel.reshape((1, 1, 3, 3)) # 给卷积操作的卷积核赋值 conv_op.weight.data = torch.from_numpy(kernel) # 对图像进行卷积操作, kernel_size=3, padding=1, stride=1，输出的图像与原图大小一致。 edge_detect = conv_op(im) # 将输出转换为图片格式 return edge_detect def main(): # 把工作目录切换到当前文件夹所在目录 os.chdir(os.path.dirname(os.path.abspath(__file__))) # 打印当前工作目录 print(os.getcwd()) # 读入一张图片，并转换为灰度图 im = Image.open(&#39;./cat.jpg&#39;).convert(&#39;L&#39;) # 将图片数据转换为矩阵 im = np.array(im, dtype=&#39;float32&#39;) # 将图片矩阵转换为pytorch tensor,并适配卷积输入的要求 im = torch.from_numpy(im.reshape((1, 1, im.shape[0], im.shape[1]))) print(&#34;im.shape: &#34;, im.shape) # 边缘检测操作 # edge_detect = nn_conv2d_2(im) # 输出的图片与原图大小相同 edge_detect = functional_conv2d(im) # 将输出限制在0-255之间 edge_detect = torch.clamp(edge_detect, min=0, max=255) edge_detect = edge_detect.squeeze().detach().numpy() print(&#34;edge_dect shape:&#34;, edge_detect.shape) print(&#34;edge_dect: &#34;, edge_detect) # 将array数据转换为image im_image = Image.fromarray(edge_detect) # image数据转换为灰度模式 im_image = im_image.convert(&#39;L&#39;) # 将Image数据转换为numpy array im_L_numpy = np.array(im_image, dtype=&#39;uint8&#39;) print(&#34;im_L_numpy.shape: &#34;, im_L_numpy.shape) print(&#34;im_L_numpy: &#34;, im_L_numpy) # 保存图片 im_image.save(&#39;edge_result.jpg&#39;, quality=95) if __name__ == &#34;__main__&#34;: main() 检测竖直方向的轮廓 卷积核： 检查轮廓的效果不如上面的突出中间值的轮廓检测，因为该卷积核只会检测竖直方向的变化，而突出中间值的轮廓检测不会有这个问题。
[[1, 0, -1], [2, 0, -2], [1, 0, -1]] 检测效果 原图：
卷积参数： kernel_size=3, padding=0, stride=1，输出的图像与原图小2个像素。 卷积效果： 与突出中间值结果差不多，但是如果垂直方向的的轮廓（垂直方向的像素值的差值） 可以看到有些水平的轮廓没有显示出来。比如图片中洗衣机的圆环的轮廓出现断裂。 检测竖直方向的卷积函数 def functional_conv2d_vertical(im): &#34;&#34;&#34;使用F.Conv2d进行边缘检测, 检测竖直方向的轮廓 Args: im (tensor): 输入的tensor图像 Returns: tensor: 输出的tensor图像 &#34;&#34;&#34; sobel_kernel = np.array([[1, 0, -1], [2, 0, -2], [1, 0, -1]], dtype=&#39;float32&#39;) sobel_kernel = sobel_kernel.reshape((1, 1, 3, 3)) weight = torch.from_numpy(sobel_kernel) edge_detect = F.conv2d(im, weight, padding=0) # 将输出的tensor的数值都变为正数 edge_detect = torch.abs(edge_detect) return edge_detect 上面这段函数有个关键点：
# 将输出的tensor的数值都变为正数 edge_detect = np.abs(edge_detect) 这是因为卷积核是有方向的，计算时，卷积核第一列是正数，第3列是负数，如果卷积时，第一列对应的原图数值很小，而第3列对应原图的数值很大，那么卷积核与原图元素的卷积结果是负数，但这种情况是一个轮廓点，所以需要将负数变为正数。不然后续转换为灰度图时，负数会变为0。这样就丢失了轮廓。 虽然这种方式可以解决负数的问题，不过水平的轮廓还是无法解决的，如果需要考虑水平轮廓可以采用sobel 算子。
sobel(索贝尔) 边缘检测 sobel 的实现思路就是使用两个算子，一个检测水平方向的算子，另一个是检测垂直方向的算子，然后将两个方向的边缘进行叠加：将水平方向与竖直方向的边缘检测结果进行平方、相加，再开方
完整程序再最后面。
检测效果 原图： 效果还是不错的： sobel(索贝尔) 卷积函数 检测竖直方向轮廓的卷积函数：
def functional_conv2d_vertical(im): &#34;&#34;&#34;使用F.Conv2d进行边缘检测, 检测竖直方向的轮廓 Args: im (tensor): 输入的tensor图像 Returns: tensor: 输出的tensor图像 &#34;&#34;&#34; sobel_kernel = np.array([[1, 0, -1], [2, 0, -2], [1, 0, -1]], dtype=&#39;float32&#39;) sobel_kernel = sobel_kernel.reshape((1, 1, 3, 3)) weight = torch.from_numpy(sobel_kernel) edge_detect = F.conv2d(im, weight, padding=0) # 将输出的tensor的数值都变为正数 edge_detect = torch.abs(edge_detect) return edge_detect 卷积核：
[[1, 0, -1], [2, 0, -2], [1, 0, -1]] 检查轮廓的效果不如上面的突出中间值的轮廓检测，因为该卷积核只会检测竖直方向的变化，而突出中间值的轮廓检测不会有这个问题。
检测水平方向轮廓的卷积函数：
def functional_conv2d_horizontal(im): &#34;&#34;&#34;使用F.Conv2d进行边缘检测, 检测水平方向的轮廓 Args: im (tensor): 输入的tensor图像 Returns: tensor: 输出的tensor图像 &#34;&#34;&#34; sobel_kernel = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype=&#39;float32&#39;) sobel_kernel = sobel_kernel.reshape((1, 1, 3, 3)) weight = torch.from_numpy(sobel_kernel) edge_detect = F.conv2d(im, weight, padding=0) # 将输出的tensor的数值都变为正数 edge_detect = torch.abs(edge_detect) return edge_detect 检测水平方向卷积核：
[[1, 2, 1], [0, 0, 0], [-1,-2,-1]] 完整程序 import torch import numpy as np from torch import nn from PIL import Image import torch.nn.functional as F import os def functional_conv2d_vertical(im): &#34;&#34;&#34;使用F.Conv2d进行边缘检测, 检测竖直方向的轮廓 Args: im (tensor): 输入的tensor图像 Returns: tensor: 输出的tensor图像 &#34;&#34;&#34; sobel_kernel = np.array([[1, 0, -1], [2, 0, -2], [1, 0, -1]], dtype=&#39;float32&#39;) sobel_kernel = sobel_kernel.reshape((1, 1, 3, 3)) weight = torch.from_numpy(sobel_kernel) edge_detect = F.conv2d(im, weight, padding=0) # 将输出的tensor的数值都变为正数 edge_detect = torch.abs(edge_detect) return edge_detect def functional_conv2d_horizontal(im): &#34;&#34;&#34;使用F.Conv2d进行边缘检测, 检测水平方向的轮廓 Args: im (tensor): 输入的tensor图像 Returns: tensor: 输出的tensor图像 &#34;&#34;&#34; sobel_kernel = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype=&#39;float32&#39;) sobel_kernel = sobel_kernel.reshape((1, 1, 3, 3)) weight = torch.from_numpy(sobel_kernel) edge_detect = F.conv2d(im, weight, padding=0) # 将输出的tensor的数值都变为正数 edge_detect = torch.abs(edge_detect) return edge_detect def main(): # 把工作目录切换到当前文件夹所在目录 os.chdir(os.path.dirname(os.path.abspath(__file__))) # 打印当前工作目录 print(os.getcwd()) # 读入一张图片，并转换为灰度图 im = Image.open(&#39;./cat.jpg&#39;).convert(&#39;L&#39;) # 将图片数据转换为矩阵 im = np.array(im, dtype=&#39;float32&#39;) # 将图片矩阵转换为pytorch tensor,并适配卷积输入的要求 im = torch.from_numpy(im.reshape((1, 1, im.shape[0], im.shape[1]))) print(&#34;im.shape: &#34;, im.shape) # 使用nn.Conv2d进行边缘检测 edge_detect_h = functional_conv2d_horizontal(im) edge_detect_h = torch.clamp(edge_detect_h, min=0, max=255) dege_detect_v = functional_conv2d_vertical(im) dege_detect_v = torch.clamp(dege_detect_v, min=0, max=255) # 将水平方向与竖直方向的边缘检测结果进行平方、相加，再开方 edge_detect = torch.sqrt(edge_detect_h**2 + dege_detect_v**2) # 将输出限制在0-255之间 edge_detect = torch.clamp(edge_detect, min=0, max=255) edge_detect = edge_detect.squeeze().detach().numpy() print(&#34;edge_dect shape:&#34;, edge_detect.shape) print(&#34;edge_dect: &#34;, edge_detect) # 将array数据转换为image im_image = Image.fromarray(edge_detect) # image数据转换为灰度模式 im_image = im_image.convert(&#39;L&#39;) # 将Image数据转换为numpy array im_L_numpy = np.array(im_image, dtype=&#39;uint8&#39;) print(&#34;im_L_numpy.shape: &#34;, im_L_numpy.shape) print(&#34;im_L_numpy: &#34;, im_L_numpy) # 保存图片 im_image.save(&#39;edge_result.jpg&#39;, quality=95) if __name__ == &#34;__main__&#34;: main() 数值裁剪到0-255 注意这个函数： edge_detect_h = torch.clamp(edge_detect_h, min=0, max=255)
它的目的： torch.clamp 是 PyTorch 中的一个函数，它的作用是将输入张量中的每个元素限制在指定范围内，并返回一个新的张量。具体来说，torch.clamp(input, min, max) 函数将输入张量 input 中的每个元素限制在 [min, max] 的范围内，如果元素小于 min，则将其设置为 min；如果元素大于 max，则将其设置为 max；否则保持不变。
例如，如果有一个张量 x = torch.tensor([1, 2, 3, 4, 5])，我们可以使用 torch.clamp(x, 2, 4) 将其限制在 [2, 4] 的范围内，得到一个新的张量 torch.tensor([2, 2, 3, 4, 4])。
简单来说：它可以将小于0的数值变为0，大于255的数值变为255。 之前考虑过下面的操作：
edge_detect = edge_detect * 255.0 / edge_detect.max() 但是这种将数值拉到区间[0, 255], 容易受到一些很大值的干扰，这样最后的图片整体亮度偏低。 之前还考虑过使用直方图均衡化，来调节对比度，但是这样会凸显一些之前不明显的轮廓，这不符我的原意。最后使用torch.clamp效果就挺好了。
参考 第五章_卷积神经网络 https://neucrack.com/p/377 ]]></content></entry><entry><title>Pytorch Api 实现直方图均衡化</title><url>/pytorch-api-implementing-histogram-equalization.html</url><categories><category>programming</category></categories><tags><tag>pytorch</tag><tag>直方图</tag></tags><content type="html"><![CDATA[pytorch-api-实现直方图均衡化
完整代码 import torch import numpy as np from torch import nn from PIL import Image import torch.nn.functional as F import os def histogram_equalization(image_tensor): &#34;&#34;&#34;对图像进行直方图均衡化 Args: image_tensor (tensor): 输入的tensor图像, 是单通道的灰度图像 Returns: tensor: 输出的tensor图像 &#34;&#34;&#34; # 将图像转换为灰度图像 # image_tensor = 0.299*image[:,0,:,:] + 0.587*image[:,1,:,:] + 0.114*image[:,2,:,:] # 计算灰度图像的直方图 hist = torch.histc(image_tensor, bins=256, min=0, max=255) # 计算灰度图像的累积分布函数 cdf = hist.cumsum(dim=0) # 归一化累积分布函数 cdf = (cdf - cdf.min()) * 255 / (cdf.max() - cdf.min()) # 对灰度图像进行直方图均衡化 equalized_image = torch.gather(cdf.to(torch.int64), 0, image_tensor.to(torch.int64).reshape(-1)).float() # 将均衡化后的图像转换为 RGB 图像 # equalized_image = torch.stack([equalized_image, equalized_image, equalized_image], dim=1) return equalized_image.reshape(image_tensor.shape) def main(): # 把工作目录切换到当前文件夹所在目录 os.chdir(os.path.dirname(os.path.abspath(__file__))) # 打印当前工作目录 print(os.getcwd()) # 读入一张图片，并转换为灰度图 # im = Image.open(&#39;./test2.jpg&#39;).convert(&#39;L&#39;) im = Image.open(&#39;./test.png&#39;).convert(&#39;L&#39;) # 将图片数据转换为矩阵 im = np.array(im, dtype=&#39;float32&#39;) # 将图片矩阵转换为pytorch tensor,并适配卷积输入的要求 im = torch.from_numpy(im) print(&#34;im.shape: &#34;, im.shape) img_tensor = histogram_equalization(im.squeeze().detach()) print(&#34;img_tensor after equalization shape:&#34;, img_tensor.shape) print(&#34;img_tensor after equalization : &#34;, img_tensor) # edge_detect 阈值, 将小于阈值的元素设置为0 img_tensor[img_tensor &lt; 200] = 0 img_tensor = img_tensor.squeeze().detach().numpy() print(&#34;img_tensor to numpy : &#34;, img_tensor, type(img_tensor)) # 将array数据转换为image im_image = Image.fromarray(img_tensor) # image数据转换为灰度模式 im_image_L = im_image.convert(&#39;L&#39;) # 将Image数据转换为numpy array im_L_numpy = np.array(im_image, dtype=&#39;uint8&#39;) print(&#34;im_L_numpy.shape: &#34;, im_L_numpy.shape) print(&#34;im_L_numpy: &#34;, im_L_numpy) # 保存图片 im_image_L.save(&#39;res.png&#39;, quality=95) if __name__ == &#34;__main__&#34;: main() histogram_equalization 函数解释： hist = torch.histc(image_tensor, bins=256, min=0, max=255) 1. torch.histc()函数的作用是计算张量的直方图 2. bins: 直方图的柱数，即区间的个数，bins=256表示将0-255的像素值分为256个区间， 每个区间的宽度为1，即0-1, 1-2, 2-3, &hellip;, 254-255, 255-256，共256个区间 3. min: 统计的最小值，max: 统计的最大值 5. hist: 直方图的统计结果，是一个一维的tensor，长度为bins，即256，每个元素表示该区间的像素值的个数
cdf = hist.cumsum(dim=0) 1. hist.cumsum(dim=0) 表示对hist的每个元素进行累加，dim=0表示按照第0维进行累加， 例如：即将hist的第0个元素与第1个元素相加，结果作为第1个元素，再将第1个元素与第2个元素相加，结果作为第2个元素，以此类推。 2. cdf: 累积分布函数，是一个一维的tensor，长度为bins，即256，第x个元素表示区间[0,x]的像素值的个数.
cdf = (cdf - cdf.min()) * 255 / (cdf.max() - cdf.min()) 1. 将cdf的值归一化到0-255之间 2. cdf.min() 表示cdf中的最小值, cdf.max() 表示cdf中的最大值, (cdf - cdf.min()) 表示cdf中的每个元素减去cdf中的最小值, (cdf.max() - cdf.min()) 表示cdf中的最大值减去cdf中的最小值 3. (cdf - cdf.min()) * 255 / (cdf.max() - cdf.min()) 表示将cdf中的每个元素减去cdf中的最小值, 再乘以255, 再除以(cdf.max() - cdf.min())
equalized_image = torch.gather(cdf.to(torch.int64), 0, image_tensor.to(torch.int64).reshape(-1)).float() 1. cdf.to(torch.int64) 将cdf的数据类型转换为torch.int64 2. image_tensor.to(torch.int64).reshape(-1) 将image_tensor的数据类型转换为 torch.int64,并将其转换为一维的tensor 3. torch.gather(cdf.to(torch.int64), 0, image_tensor.to(torch.int64).reshape(-1)) 从cdf中按照image_tensor的值进行索引 4. equalized_image = torch.gather(cdf.to(torch.int64), 0, image_tensor.to(torch.int64).reshape(-1)).float() 将索引得到的值转换为float类型 equalized_image.reshape(image_tensor.shape) 1. 将equalized_image的形状转换为image_tensor的形状。
torch.gather 这个函数是什么意思？ torch.gather() 是 PyTorch 中的一个函数，用于在一个输入 Tensor 中按照指定的维度和索引聚合数据。具体来说，torch.gather() 函数的功能是从输入 Tensor 中按照指定的维度和索引收集数据，并返回一个新的 Tensor。
torch.gather() 函数的基本用法如下：
torch.gather(input, dim, index, out=None) 其中，input 表示输入的 Tensor，dim 表示指定的维度，index 表示索引，out 表示输出的 Tensor，如果不指定则会创建一个新的 Tensor。
下面是一个最简单的 torch.gather() 的例子，假设我们有一个 2x3 的 Tensor：
import torch x = torch.tensor([ [1, 2, 3], [4, 5, 6] ]) 我们希望从第一个维度（即行）中选择第 0 行和第 1 行的元素，可以使用以下代码：
indices = torch.tensor([ [0, 2, 1], [1, 0, 2] ]) result = torch.gather(x, 1, indices) 其中，indices 表示要选择的索引，1 表示要在第一个维度上进行聚合。运行上述代码后，result 的值为：
tensor([[1, 3, 2], [5, 4, 6]]) 可以看到，result 的第一行表示从 x 的第一行中选择了索引为 0、2、1 的元素，第二行表示从 x 的第二行中选择了索引为 1、0、2 的元素。
需要注意的是，torch.gather() 函数的输入和输出 Tensor 的形状必须满足一定的条件，具体可以参考 PyTorch 官方文档。
实验效果 输入：test.png 输出：res.png
阈值200后的输出：img_tensor[img_tensor &lt; 200] = 0 ]]></content></entry><entry><title>转置卷积与卷积的理解</title><url>/post/trans-conv-and-conv.html</url><categories><category>programming</category></categories><tags><tag>转置卷积</tag><tag>卷积</tag><tag>programming</tag></tags><content type="html"><![CDATA[转置卷积与卷积的理解，本文将介绍：
转置卷积含义与矩阵形式 转置卷积的一种简单理解 pytorch 转置卷积参数的理解及其Shape的公式推导 卷积与数学上的卷积，卷积核旋转180度 阅读前提：
理解深度学习中普通卷积的概念与shape的计算公式 了解深度学习框架pytorch卷积api的调用 了解卷积的矩阵运算形式 转置卷积含义与矩阵形式 文档： A guide to convolution arithmetic for deep learning 介绍了转置卷积一个概念：The need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution.
翻译一下就是：一个普通卷积的反向操作，已知一个卷积操作L，它输入是A，输出是B，现在需要将B重新变回具有与A形状线相同的C,并且C与A依然保持一种与卷积操作L相容（一致性）的连接特性。注意：C与B只是形状相同，但是数值一般是不同的。 另外转置卷积的作用：以一个已经编码的layer进行解码，或者将特征图映射到高维空间（or project feature maps to a higher-dimensional space.）
转置卷积也有其他的概念，而转置卷积的名称与使用矩阵运算来计算卷积有关（Convolution as a matrix operation）：
以图2.1所表示的卷积为例。如果将输入和输出从左到右、从上到下展开成向量，那么卷积可以表示为一个稀疏矩阵\(C\)，其中非零元素是卷积核的元素\(W(i,j)\)（其中 \(i\) 和 \(j\) 分别是卷积核的行和列）：
图2.1 展开的卷积核 这个线性运算将输入矩阵展平为一个16维向量\(X\)，并产生一个4维向量\(Z\)，之后被重新整形为2×2的输出矩阵。利用这种表示方法，反向传播很容易通过转置\(C\)来获取；换句话说，误差通过将损失与\(C^T\)相乘来进行反向传播。该运算以一个4维向量作为输入，并产生一个16维向量作为输出，其连接模式与\(C\)的构造方式兼容。 值得注意的是，核\(W\)定义了用于正向和反向传播的矩阵\(C\)和\(C^T\)。梯度反向传播的过程中，在计算输入\(X\)的梯度时，是通过该4维向量\(Z\)的梯度（也是反向传播过来的）与\(C^T\)相乘来计算的。
转置卷积是相对原卷积来说的。原卷积的不同卷积方式，对应的转置卷积也是不一样的。转置卷积可以通过普通的卷积来实现。
具体的实现方式参考： A guide to convolution arithmetic for deep learning ，在第4章有详细的介绍。
原卷积如果是No zero padding, unit strides，那么转置卷积将采用full-conv，例如： 图4.1 图4.1 解释： Relationship 8. A convolution described by s = 1, p = 0 and k has an associated transposed convolution described by k′= k, s′= s and p′= k −1 and its output size is o′= i′+ (k −1). 其中i&rsquo; = (i-k+2*p)/s + 1
值得注意：pytorch 的转置卷积默认是full-conv，pytorch 转置卷积将再第3节介绍。
另外的参考：https://zh-v2.d2l.ai/chapter_computer-vision/transposed-conv.html 其中有解释转置卷积的名称由来：抽象来看，给定输入向量\(\mathbf{x}\)和权重矩阵\(W\)，卷积的前向传播函数可以通过将其输入与权重矩阵相乘并输出向量\(\mathbf{y}=\mathbf{W}\mathbf{x}\)来实现。 由于反向传播遵循链式法则和\(\nabla_{\mathbf{x}}\mathbf{y}=\mathbf{W}^\top\)，卷积的反向传播函数可以通过将其输入与转置的权重矩阵\(\mathbf{W}^\top\)相乘来实现。 因此，转置卷积层能够交换卷积层的正向传播函数和反向传播函数：它的正向传播和反向传播函数将输入向量分别与\(\mathbf{W}^\top\)和\(\mathbf{W}\)相乘。
转置卷积的一种简单理解 文档 https://zh-v2.d2l.ai/chapter_computer-vision/transposed-conv.html 介绍了一种简单的转置卷积理解方式： 输入\(i\) 是[[0,1],[2,3]], 转置卷积核也为：[[0,1],[2,3]]（注意：该卷积与pytorch的实现方式不一样，但这是另外一种理解，而且与pytorch的转置卷积api计算结果一致）
图13.10.1 该转置卷积设步幅为1且没有填充。输入张量中的每个元素都要乘以卷积核，然后产生了4个中间结果，然后加起来得到就是转置卷积的结果。 注意：图13.10.1转置卷积对应的原卷积的参数是：stride = 1, padding = 0。这样输出的shape : i' = (i-k+2*padding)/stride + 1 == i-(k-1)，而转置卷积的目的是在形状上将\(i&rsquo;\)恢复为 \(i\) ，且保持卷积的一种一致性。可以用一下代码实现，定义函数trans_conv，输入矩阵\(X\)和卷积核矩阵\(K\)实现基本的转置卷积运算：
def trans_conv(X, K): h, w = K.shape Y = torch.zeros((X.shape[0] + h - 1, X.shape[1] + w - 1)) for i in range(X.shape[0]): for j in range(X.shape[1]): Y[i: i + h, j: j + w] += X[i, j] * K return Y X = torch.tensor([[0.0, 1.0], [2.0, 3.0]]) K = torch.tensor([[0.0, 1.0], [2.0, 3.0]]) trans_conv(X, K) 输出：
tensor([[ 0., 0., 1.], [ 0., 4., 6.], [ 4., 12., 9.]]) 当输入X和卷积核K都是四维张量时，我们可以使用高级API(pytorch)获得相同的结果。
X = torch.tensor([[0.0, 1.0], [2.0, 3.0]]) K = torch.tensor([[0.0, 1.0], [2.0, 3.0]]) X, K = X.reshape(1, 1, 2, 2), K.reshape(1, 1, 2, 2) tconv = nn.ConvTranspose2d(1, 1, kernel_size=2, bias=False) tconv.weight.data = K tconv(X) 结果也是一样：
tensor([[[[ 0., 0., 1.], [ 0., 4., 6.], [ 4., 12., 9.]]]], grad_fn=&lt;ConvolutionBackward0&gt;) 更详细的内容，下面两个链接不错： 转置卷积 Transposed Convolutions explained with… MS Excel! pytorch 转置卷积参数的理解及其Shape的公式推导 pytorch 转置卷积 的文档： torch.nn.ConvTranspose2d 另外下面这个文档比较重要，也是本文主要的参考文章 A guide to convolution arithmetic for deep learning pytorch 转置卷积shape的计算公式 pytorch 的转置卷积包含很多参数，它的基本含义是，如果转置卷积使用原卷积相同的参数，那么转置卷积结果的shape与原卷积的输入保持一致, 这个概念很重要。 pytorch 转置卷积的函数签名：
CLASS torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode=&#39;zeros&#39;, device=None, dtype=None) pytorch转置卷积输出的shape是有计算公式的：
$$H_{out} = (H_{in} - 1) \times \text{stride}[0] - 2 \times \text{padding}[0] + \text{dilation}[0]\times (\text{kernel_size}[0] - 1) + \text{output_padding}[0] + 1 $$
$$W_{out} = (W_{in} - 1) \times \text{stride}[1] - 2 \times \text{padding}[1] + \text{dilation}[1] \times (\text{kernel_size}[1] - 1) + \text{output_padding}[1] + 1$$
pytorch 转置卷积 的计算过程 接下来介绍该算式的含义。 为了理解转置卷积，需要结合原卷积来理解，下面一起考虑原卷积和对应的转置卷积：
假设原卷积输入特征图 \(H_{in}\)= \(i\) ，卷积核设置（kernel= \(k\) , stride= \(s\) , padding= \(p\) , dilation= \(d\) 等）输出的特征图为 \(i&rsquo;\) 。对应的转置卷积，当给一个特征图 \(i&rsquo;\), 以及给定相同的卷积核设置（stride=\(s\), padding=\(p\), dilation= \(d\) 等），在pytorch中这个设置将会输出特征图形状 \(o_t\) 与特征图 \(i\) 一致（值是不保证相同的，值通常也不相同）。
接下来我们分为2步1进行转置卷积操作:
第一步：对输入的特征图 \(i&rsquo;\) 进行一些变换，例如：元素之间插入0，特征图周围进行padding，得到新的特征图 \(\tilde{i&rsquo;}\) 第二步：在新的特征图上做普通卷积 (kernel=\(k\), stride=1，dilation=\(d\) 等)，得到的结果 \(o_t\) 就是转置卷积的结果，就是我们要求的结果。 第一步，对输入的特征图进行一些变换 pytorch 转置卷积有一些重要的默认设置： stride=1, padding=0, dilation=1
其中stride 控制互相关的步幅（原文是：controls the stride for the cross-correlation.）。它对应的是原卷积的stride，例如：原卷积的stride 是2，那么转置卷积的stride也设置2，如图4.6所示。但是转置卷积处理与原卷积不同：在特征图a元素中间隔插入(stride-1)=1 个零元素。这么做的原因是考虑一种原卷积与转置卷积具有某种相同的连接模式， 这个后面再解释。
转置卷积的padding 控制方式与原卷积看似比较奇怪，直接看pytorch的处理方式：不考虑dilation的情况下，dilation 后面再解释，转置卷积paddding计算公式为：(kernel_size - 1) - padding ，例如：转置卷积 kernel_size=3，padding=1, 那么实际的padding为 (3-1)-1 = 1, 注意这里的padding 指的是单边padding的大小。如果考虑两边要乘2。 这里有个规律2 : 当原卷积padding=0时，转置卷积: padding=(kernel_size -1), 这种padding表明转置卷积是一种全卷积(full-convolution), 也称为：full padding。当原卷积是全卷积时，考虑上面转置卷积paddding计算公式，那么转置卷积的padding=0，即: padding=(kernel_size-1) - (kernel_size-1)=0 。当然还有half-padding: 原卷积与转置卷积此时有相同的padding: \(\lfloor (k -1)/2 \rfloor\)。
转置卷积 padding 的控制方式同样要考虑 dilation 的情况 (dilation 参考 2 中 5.1 Dilated convolutions)。转置卷积paddding公式为：dilation * (kernel_size - 1) - padding ，例如：转置卷积 kernel_size=3，padding=1 , dilation=1, 那么实际的padding为 2*(3-1)-1 = 3。直观理解dilation（空洞卷积）就是某种程度上卷积核变大了，那么对应的padding也要变大。才能保证原卷积与转置卷积具有某种相同的连接模式。 注意：dilation * (kernel_size - 1) - padding， 这里padding 是指原卷积的padding, 也就是说pytorch 中输入的参数：strides， padding 都是指原卷积的padding。
第一步：对输入的特征图 \(i&rsquo;\) 进行一些变换得到\(\tilde{i&rsquo;}\) 就介绍到这里，虽然不止这些，但对理解pytorch的转置卷积输出shape的计算公式差不多够了。由参数strides和padding变换得到\(\tilde{i&rsquo;}\)大小为：$$H_{\tilde{i&rsquo;}}= i&rsquo; + (i&rsquo;-1) * (s-1) + 2[d*(k-1)-p]$$
转置卷积、padding 之所以这样处理是有原因的2，原卷积与转置卷积具有某种相同的连接模式的直观理解： One way to understand the logic behind zero padding is to consider the connectivity pattern of the transposed convolution and use it to guide the design of the equivalent convolution. For example, the top left pixel of the input of the direct convolution only contribute to the top left pixel of the output, the top right pixel is only connected to the top right output pixel, and so on.
To maintain the same connectivity pattern in the equivalent convolution it is necessary to zero pad the input in such a way that the first (top-left) application of the kernel only touches the top-left pixel, i.e., the padding has to be equal to the size of the kernel minus one. 翻译一下就是：理解零填充背后的逻辑的一种方法是考虑反卷积的连接模式，并使用它来指导等价的卷积（转置卷积实际的实现方式）设计。例如，直接卷积输入的左上角像素仅对输出的左上角像素有贡献，右上角像素仅连接到右上角输出像素，依此类推。以图4.1为例，为了在等价卷积（转置卷积实际的实现方式）中保持相同的连接模式，需要以零填充输入，使得核的第一次（左上角）卷积仅接触左上角像素，即填充必须等于核大小减一（仅仅是图4.1的情况，）。 例如： 图4.12是一个转置卷积的例子，原卷积是：3*3 kernel over a 4*4 input using unit strides(i.e., i = 4, k=3, s=1 and p=0), 转置卷积的等价卷积是：3*3 kernel over a 2*2 input , padding=2, strides = 1. (i.e., i'=2, k'=k=3, s'=1, and p'= 2 = (k-1) - p
总的来说，输入的特征图 \(i&rsquo;\) 进行一些变换之所以要这样处理(stride 、padding等)是为了保持同样的连接性：这是指从A到B（AB分别表示卷积前和卷积后的特征图），如果A中一个位置与B中一个位置通过kernel有关系，那么在卷积核逆卷积中有相同的连通。1
另外一个例子： 图4.62
第二步，对变换得到特征图进行普通的卷积 第二步思路比较简单，对变换得到\(\tilde{i&rsquo;}\) 进行普通的卷积，kernel = k, strides=1, padding=0， dilation=d, 由于考虑dialation, 等效的卷积核（感受野）大小为：\(k+(k-1)*(d-1)\)
由第一步可知：由参数strides和padding变换得到特征图\(\tilde{i&rsquo;}\)大小为： $$H_{\tilde{i&rsquo;}}= i&rsquo; + (i&rsquo;-1) * (s-1) + 2[d*(k-1)-p]$$
转置卷积shape计算：\(o_t=\frac{H_{i&rsquo;} - [k+(k-1)*(d-1)]}{1} + 1\)
公式化简一下就是：\(o_t=(i&rsquo;-1)s - 2p + d(k-1) + 1\)
但是pytorch 的计算公式是： $$H_{out} = (H_{in} - 1) \times \text{stride}[0] - 2 \times \text{padding}[0] + \text{dilation}[0]\times (\text{kernel_size}[0] - 1) + \text{output_padding}[0] + 1 $$ 对比一下发现少了一项：\(\text{output_padding}[0]\) \(\text{output_padding}[0]\) 这一项是为了解决转置卷积同一个 \(i&rsquo;\) 对应多个 \(i\) 的问题，即原卷积的输出\(i&rsquo;\) 可能因为不同的strides、padding设置而对应多个不同shape的 \(i\) , 这时候需要添加额外的参数\(\text{output_padding}[0]\)使得转置卷积还原为一个特定的 \(i\) 的形状，它的操作是单边补零的，pytorch 参数解释：Additional size added to one side of each dimension in the output shape. Default: 0。
例如： 于是加上\(\text{output_padding}\)的转置卷积shape计算公式：
\(o_t=(i&rsquo;-1)*s -2p + d(k-1) +\text{output_padding} +1\) 。它与pytorch 的给出的公式一致。
参考： 转置卷积 Transposed Convolutions explained with… MS Excel! 卷积与数学上的卷积 pytorch 的转置卷积的核旋转了180度 将第一节（转置卷积的直观理解）与第二节（pytorch 转置卷积参数的理解，以及转置卷积Shape的公式推导）进行对比，你会发现这里两种操作完全不同，但是得到了相同的结果。这其中必然有某种联系。 还是考虑第一节的例子： 图13.10.1 采用pytorch 的做法，第一步先将输入\(i&rsquo;\) （转置卷积的输入，另外\(i\)表示的是原卷积的输入）进行变换，假设原卷积的参数是：kernel = 2, strides = 1，padding=0。 strides =1, 输入\(i&rsquo;\) 元素之间不需要插入0 padding=0, 实际的padding = (k-1)-p = (2-1)-0 = 1 那么变换后的 \(\tilde{i&rsquo;}\) （转置卷积的输出）：
然后进行第二步：对变换后的 \(\tilde{i&rsquo;}\) 进行普通的卷积：k=2, s=1, p=0 k =[[0,1],[2,3]] 看起来不复杂，可以直接手算，得到卷积的结果：\(o_1\) = [[0,3,2],[6,14, 6],[2,3,0]]，这与图13.10.1的输出完全不同。 但是你如果用pytorch的转置卷积api 算一下，又会发现结果与图13.10.1的输出完全一致。例如：
X = torch.tensor([[0.0, 1.0], [2.0, 3.0]]) K = torch.tensor([[0.0, 1.0], [2.0, 3.0]]) X, K = X.reshape(1, 1, 2, 2), K.reshape(1, 1, 2, 2) tconv = nn.ConvTranspose2d(1, 1, kernel_size=2, bias=False) tconv.weight.data = K tconv(X) 输出： tensor([[[[ 0., 0., 1.], [ 0., 4., 6.], [ 4., 12., 9.]]]], grad_fn=&lt;ConvolutionBackward0&gt;) 那么是哪里出了问题呢？ 问题在第二步，对变换后的 \(\tilde{i&rsquo;}\) 进行普通的卷积时，卷积核需要旋转180度。新的卷积核是： k_new = [[3.0, 2.0], [1.0, 0.0]], 对变换后的 \(\tilde{i&rsquo;}\) 进行普通的卷积（k=2, s=1, p=0）。结果是：\(o_2\) = [[0,0,1],[0,4, 6],[4,12,9]] 这就与pytorch的计算一致了。 这里用pytorch Conv2d (普通卷积api) 进行了验证：
import torch from torch import nn X = torch.tensor([[0.0, 1.0], [2.0, 3.0]]) K = torch.tensor([[0.0, 1.0], [2.0, 3.0]]) T_K = torch.tensor([[3.0, 2.0], [1.0, 0.0]]) X, K, T_K = X.reshape(1, 1, 2, 2), K.reshape(1, 1, 2, 2), T_K.reshape(1, 1, 2, 2) def nn_conv2d(im, kernel): # 用nn.Conv2d定义卷积操作 conv_op = nn.Conv2d(1, 1, kernel_size=2, stride=1, padding=1, bias=False) # 给卷积操作的卷积核赋值 conv_op.weight.data = kernel # 对图像进行卷积操作 conv_res = conv_op(im) return conv_res res = nn_conv2d(X, K) print(res) res2 = nn_conv2d(X, T_K) print(res2) 结果是：
tensor([[[[ 0., 3., 2.], [ 6., 14., 6.], [ 2., 3., 0.]]]], grad_fn=&lt;ConvolutionBackward0&gt;) tensor([[[[ 0., 0., 1.], [ 0., 4., 6.], [ 4., 12., 9.]]]], grad_fn=&lt;ConvolutionBackward0&gt;) 可以看到nn_conv2d(X, T_K)函数输出了正确结果，这说明nn.Conv2d 没有对卷积核进行180度旋转，但是转置卷积nn.ConvTranspose2d对卷积核进行180度旋转。
旋转卷积核后与第一节中的计算结果保持一致，第一节中的计算简单描述就是：每个元素直接与卷积核相乘，然后将所有的中间结果进行叠加。当然这种操作还涉及到strides大于1的情况3,这里就不解释了。
数学上定义的卷积 其实原本数学上的卷积就是要将卷积核进行旋转180度，数学上的卷积与图13.10.1 的操作应该存在着联系。即：图13.10.1 的操作 与使用翻转180度的[[0,1],[2,3]]对 \(\tilde{i&rsquo;}\) 进行卷积是等价的。 这种联系不打算深究。接下来本文打算给出一些直观的例子。
在此之前先解释一下数学上的卷积是怎么回事。
在数学上，连续形式的卷积定义如下：
设 \(f(x)\) 和 \(g(x)\) 是在实数域上的两个可积函数，定义它们的卷积 \(h(x)\) 为：
\(h(x) = (f*g)(x) = \int_{-\infty}^{\infty} f(\tau)g(x-\tau) d\tau\)
其中，\(*\) 表示卷积操作，\(h(x)\) 表示卷积的输出，\(f(x)\) 和 \(g(x)\) 分别表示卷积的输入函数，\(\tau\) 是积分变量。
卷积的计算过程可以理解为将 \(f(x)\) 和 \(g(x)\) 进行平移、翻转、相乘和积分的过程。具体来说，对于 \(g(\tau)\)，首先将其进行翻转得到 \(g(-\tau)\)，然后将其在 \(x\) 轴上平移 \(x\) 个单位得到 \(g(x-\tau)\)，然后再与 \(f(\tau)\) 相乘，并对 \(\tau\) 进行积分，最终得到卷积的输出 \(h(x)\)。
图像的卷积是离散形式，离散形式的卷积定义如下：
设 \(f[n]\) 和 \(g[n]\) 是在整数域上的两个离散序列，定义它们的卷积 \(h[n]\) 为：
\(h[n] = (f*g)[n] = \sum_{m=-\infty}^{\infty} f[m]g[n-m]\)
离散形式与连续形式类似，当确定一个n后，计算 \(\sum_{m=-\infty}^{\infty} f[m]g[n-m]\) 时，不是积分而是求和。如果与图像的卷积类别。每个n 对应卷积核的一次平移，计算\(\sum_{m=-\infty}^{\infty} f[m]g[n-m]\)对应一次将卷积核旋转180度然后对应元素直接进行相乘求和。
卷积可以用概括为：翻转、平移、相乘再求和 先对g函数进行翻转，相当于在数轴上把g函数从右边褶到左边去，也就是卷积的“卷”的由来。 然后再把g函数平移到n，在这个位置对两个函数的对应点相乘，然后相加，这个过程是卷积的“积”的过程。4 例如： 更具体的例子可看 如何通俗易懂地解释卷积？ - palet的回答 - 知乎 中的信号分析、丢骰子与图像处理的例子。
多项式系数卷积与意义 接下来是一个一维矩阵的卷积，希望有更直观数学意义5，这里只是给出一种直观的感觉，不解释这么做的原因，因为笔者也不太清楚。
考虑两个多项式函数： \(y=3x+2\) \(y=2x^2+3x-1\) 将这两个函数相乘：\(y=(3x+2)(2x^2+3x-1)= 6x^2+13x+3x-2\) 可以将这两个函数的系数按x的阶数从大到小考虑为两个矩阵，然后进行卷积： \(y=3x+2\) 的系数矩阵：i=[3,2] \(y=2x^2+3x-1\) 的系数矩阵：K=[2, 3, -1]，当成卷积核。旋转180度后卷积核：T_K=[-1, 3, 2]
将两个矩阵进行卷积：
首先将系数矩阵[3,2] 进行padding: [0,0,3,2,0,0], padding= 2 = kernel_size -1 = 3 - 1。 移动卷积核：T_K=[-1, 3, 2]进行计算： 例如： 0 0 3 2 0 0 -1 3 2 0 0 3 2 0 0 -1 3 2 0 0 3 2 0 0 -1 3 2 0 0 3 2 0 0 -1 3 2 最后结果是：[2*3, 3*3+2*2, 2*3-1*3, -1*2] = [6, 13, 3, 2] 恰好是\(6x^2+13x+3x-2\) 的系数。感觉翻转180度进行卷积与多项式的计算有关联，计算的结果是有意义的，这些系数是\(x^n\)的系数，或者说是某种特征的系数。
另外考虑另外一种实现方式，类似于图13.10.1，也类似于\(y=(3x+2)(2x^2+3x-1)= 6x^2+13x+3x-2\)的化简过程： 将矩阵：i=[3,2]的每个元素与系数矩阵：K=[2, 3, -1]相乘，例如： [3]*[2,3,-1] -&gt; [6, 9, -3] [2]*[2,3,-1] -&gt; [4, 6, -2]
然后将这两个中间结果矩阵按下面的形式相加，最后也得到了同样的系数。
6 9 -3 4 6 -2 6 13 3 -2 思考：这里的中间结果相加对齐了两个元素（考虑\(x^n\)的合并），而图13.10.1 中间结果只是对齐了一个元素，这是为什么？可能与卷积核的大小有关，如果卷积核是4x4 那么中间结果相加是不是要对齐3个元素？
参考： 如何通俗易懂地解释卷积？ - palet的回答 - 知乎 https://blog.csdn.net/qq_27261889/article/details/86304061 &#160;&#x21a9;&#xfe0e;&#160;&#x21a9;&#xfe0e;
A guide to convolution arithmetic for deep learning &#160;&#x21a9;&#xfe0e;&#160;&#x21a9;&#xfe0e;&#160;&#x21a9;&#xfe0e;&#160;&#x21a9;&#xfe0e;&#160;&#x21a9;&#xfe0e;
Transposed Convolutions explained with… MS Excel! &#160;&#x21a9;&#xfe0e;
如何通俗易懂地解释卷积？ - palet的回答 - 知乎 &#160;&#x21a9;&#xfe0e;
理解卷积的数学意义 卷积分 &#160;&#x21a9;&#xfe0e;
]]></content></entry><entry><title>Handwriting Dl Framework</title><url>/handwriting-dl-framework.html</url><categories><category><no value=/></categories><tags><tag>DL</tag><tag>code</tag><tag>algorithm</tag></tags><content type="html"><![CDATA[主要程序 general_neural_network_framework.py github 仓库 计算图的建立 在基类Node中 初始化中 self.inputs 与self.outputs 记录了节点之间的关系，以此将计算图建立好。
class Node: &#34;&#34;&#34; 我们把这个Node类作为这个神经网络的基础模块 &#34;&#34;&#34; def __init__(self,inputs=[],name=None,is_trainable=False): self.inputs = inputs #这个节点的输入，输入的是Node组成的列表 self.outputs = [] #这个节点的输出节点 self.name = name self.is_trainable = is_trainable for n in self.inputs: n.outputs.append(self) #这个节点正好对应了这个输人的输出节点，从而建立了连接关系 self.value = None #每个节点必定对应有一个值 self.gradients = {} #每个节点对上个节点的梯度， def forward(self): &#34;&#34;&#34; 先预留一个方法接口不实现，在其子类中实现,且要求其子类一定要实现，不实现的时话会报错。 &#34;&#34;&#34; raise NotImplemented def backward(self): raise NotImplemented def __repr__(self): return &#34;Node:{}&#34;.format(self.name) 拓扑排序 拓扑排序的目的是，获得一个排好顺序的节点列表. 前向计算一个节点的输出值时，保证这个节点的输入值已经计算好了，换句话说，与这个节点相连的父节点已经算好值了。 同样反向传播时，将拓扑排序好的列表进行倒序计算，在计算一个节点的梯度，保证该节点的子节点已经算好梯度了。
下面是个简单的例子：
# Write a topological sort algorithm def topological_sort(graph): visited = set() stack = [] def dfs(node): if node in visited: return visited.add(node) for neighbor in graph[node]: dfs(neighbor) stack.append(node) for node in graph: dfs(node) # stack.reverse() return stack[::-1] # 拓扑排序的输入是一个有向无环图，输出是一个序列，该序列满足：如果图中存在一条从节点 A 到节点 B 的路径，那么在序列中节点 A 出现在节点 B 的前面。 graph = {&#34;a&#34;: [&#34;b&#34;, &#34;c&#34;], &#34;b&#34;: [&#34;d&#34;], &#34;c&#34;: [&#34;d&#34;], &#34;d&#34;: []} print(topological_sort(graph)) 输入：
输出结果是：
[&#39;a&#39;, &#39;c&#39;, &#39;b&#39;, &#39;d&#39;] 前向计算与梯度反向传播 将计算图进行拓扑排序后，按照排序后的顺序调用每个节点的forward进行前向计算，然后在反向传播的时候调用backward 进行梯度更新。 多维度的前向计算与反向传播 是采用矩阵运算的形式进行运算的。
包的发布 https://blog.csdn.net/qq_43790749/article/details/112134520 参考 https://blog.csdn.net/qq_43790749/article/details/112130630 ]]></content></entry><entry><title>vscode远程调试docker中的python服务</title><url>/post/vscode-remote-debugging-python-service.html</url><categories><category>programming</category></categories><tags><tag>vscode</tag><tag>python</tag></tags><content type="html"><![CDATA[vscode远程调试docker中的python服务
环境：windows Docker Desktop , Vscode
阅读前，默认你对以下内容有基本了解：docker-compose.yml, Dockerfile, Vscode python 调试配置, flask 服务
原本想使用python pdb来调试，但是在容器环境中使用pdb，需要直接在容器终端中启动python程序，不方便 然后找到一个远程调试工具：debugpy，它将在容器中运行，等待vscode的连接（可配置等待模式），然后启动python程序。 配置好后就可以在vscode中调试容器中的python程序了。
远程调试flask服务 在docker 中调试flask服务时不要开启debug模式
例如：
if __name__ == &#39;__main__&#39;: # 本机访问：http://127.0.0.1:5000/ app.run(host=&#34;0.0.0.0&#34;, port=5000, debug=False) 原因是，开启debug后意味着开启了flask的重新加载机制，由于使用debugpy远程调试的某种原因，flask的重载机制触发了，这会导致Python 会创建一个新的进程来运行新的代码。但是,原来的进程还在监听 debug 调试端口,所以当新进程尝试绑定同一个端口时会报 &ldquo;Address already in use&rdquo; 错误。
远程调试flask服务时，Dockerfile的示例 Dockerfile
# Use the Python 3.10 image as the base image FROM python:3.10 # Keeps Python from generating .pyc files in the container ENV PYTHONDONTWRITEBYTECODE=1 # Turns off buffering for easier container logging ENV PYTHONUNBUFFERED=1 # Set the working directory to /app WORKDIR /app # Copy all files in the current directory to /app COPY . /app # Dependencies required by the installation script RUN pip install -r requirements.txt -i https://mirrors.cloud.tencent.com/pypi/simple # Expose the port of the container EXPOSE 5000 EXPOSE 5678 # run script CMD [&#34;python&#34;, &#34;server.py&#34;] 远程调试flask服务时，docker-compose.debug.yml 配置 这里使用的是docker-compose.debug.yml，是为了区别于docker-compose.yml
启动docker-compose.debug.yml的方式是：docker-compose -f docker-compose.debug.yml up
version: &#34;3.9&#34; services: pic_server: build: ./ # tty: true # stdin_open: true # image: web_dl-main_server:latest ports: - &#34;5000:5000&#34; - &#34;5678:5678&#34; restart: always volumes: - &#34;.:/app&#34; command: [&#34;python&#34;, &#34;-m&#34;, &#34;debugpy&#34;, &#34;--listen&#34;, &#34;0.0.0.0:5678&#34;, &#34;--wait-for-client&#34;, &#34;server.py&#34;] 容器启动后，会自动执行command的设置的命令
这个命令会覆盖Dockerfile中的CMD命令，例如会覆盖Dockerfile原来的命令：CMD [&quot;python&quot;, &quot;server.py&quot;]
远程调试flask服务时，vscode 的调试客户端配置 .vscode\launch.json 见后文：vscode 的调试客户端配置
调试我的web-dl服务 web-dl service github address: https://github.com/qyzhizi/web_dl docker-compose.debug.yml 配置 这里使用的是docker-compose.debug.yml，是为了区别于docker-compose.yml
启动docker-compose.debug.yml的方式是：docker-compose -f docker-compose.debug.yml up
docker-compose.debug.yml的内容是：
version: &#34;3.9&#34; services: main_server: depends_on: - redis build: ./ env_file: - .env ports: - &#34;9000:9000&#34; - &#34;5678:5678&#34; restart: always volumes: - &#34;.:/app&#34; command: &gt; sh -c &#34;python web_dl/cmd/celery_work &gt; celery_work.log 2&gt;&amp;1 &amp; python -m debugpy --listen 0.0.0.0:5678 --wait-for-client web_dl/cmd/main&#34; redis: image: &#34;redis/redis-stack-server:latest&#34; 容器启动后，会自动执行command的设置的命令
command: &gt; sh -c &#34;python web_dl/cmd/celery_work &gt; celery_work.log 2&gt;&amp;1 &amp; python -m debugpy --listen 0.0.0.0:5678 --wait-for-client web_dl/cmd/main&#34; 这个命令会覆盖Dockerfile中的CMD命令，例如会覆盖Dockerfile原来的命令：CMD [&quot;bash&quot;, &quot;-c&quot;, &quot;web_dl/cmd/run.sh&quot;]
第一个命令：python web_dl/cmd/celery_work &gt; celery_work.log 2&gt;&amp;1 &amp;，它是在后台执行一个python脚本web_dl/cmd/celery_work,最后的&amp;表示后台执行 这里一定要后台执行，因为这个脚本不会终止。否者第二个命令就无法被终端执行，而是一直等第一个命令执行结束。
第二个命令：python -m debugpy --listen 0.0.0.0:5678 --wait-for-client web_dl/cmd/main&quot;, 它是启动docker远端调试服务的关键，python 启动debugpy， 并且监听0.0.0.0:5678, --wait-for-client表示等待客户端的连接接（docker这边启动的是服务端），客户端本文采用的vscode的python调试模块（后文再介绍相关配置）。
最后启动python 脚本web_dl/cmd/main，这个脚本是python web服务的入口点。
vscode 的调试客户端配置 安装python 扩展插件 打开vscode的调试界面，如果你之前没有创建过launch.json, 那就选择创建launch.json 文件，然后选择调试器Docker: Debug in Container,然后生成一个文件launch.json 接下来配置这个launch.json,如下：
{ // Use IntelliSense to understand related attributes。 // Hover to see descriptions of existing properties。 // For more information, please visit: https://go.microsoft.com/fwlink/?linkid=830387 &#34;version&#34;: &#34;0.2.0&#34;, &#34;configurations&#34;: [ { &#34;name&#34;: &#34;Python: remote attach&#34;, &#34;type&#34;: &#34;python&#34;, &#34;request&#34;: &#34;attach&#34;, &#34;connect&#34;: { &#34;host&#34;: &#34;localhost&#34;, &#34;port&#34;: 5678 }, &#34;pathMappings&#34;: [ { &#34;localRoot&#34;: &#34;${workspaceFolder}&#34;, &#34;remoteRoot&#34;: &#34;/app&#34; } ], &#34;justMyCode&#34;: true } ] } 其中：
&#34;connect&#34;: { &#34;host&#34;: &#34;localhost&#34;, &#34;port&#34;: 5678 }, 这个表示连接到本地的5678端口，因为调试的服务端是本地， 如果你的docker服务在其他地方，比如云端，那么这里需要填写机器的ip地址，可能还会有密码需要配置， 目前笔者还没有试过远程连接docker服务，先就不管了。 &quot;justMyCode&quot;: true 表示只是调试你写的代码，第三方库的代码就不调试了，这里笔者也没有试过，先记录一下。
另外：
&#34;pathMappings&#34;: [ { &#34;localRoot&#34;: &#34;${workspaceFolder}&#34;, &#34;remoteRoot&#34;: &#34;/app&#34; } ], 这个表示本地代码到docker容器的代码映射，因为在Dockerfile中，代码的根目录是/app,所以&quot;remoteRoot&quot;: &quot;/app&quot; ${workspaceFolder}表示vscode的工作目录，这里是把当前工作目录与容器的/app进行映射。 之所以要做映射，是因为在调试时，可以准确找到对应的代码。
参考 https://blog.hipolabs.com/remote-debugging-with-vscode-docker-and-pico-fde11f0e5f1c https://github.com/Microsoft/ptvsd/issues/1131 ]]></content></entry><entry><title>没有H1-6标题头和评论的文章</title><url>/post/no-header-title.html</url><categories><category>示例</category></categories><tags><tag>toc</tag><tag>标题</tag></tags><content type="html">刘慈欣2018克拉克奖获奖感言（部分内容节选）。
用于测试在没有H1-6标题头时，文章的目录导航是否会直接关闭，并关闭评论功能。
先生们、女士们，晚上好，
很荣幸获得Clarke Award for Imagination in Service to Society Award。
这个奖项是对想象力的奖励，而想象力是人类所拥有的一种似乎只应属于神的能力，它存在的意义也远超出我们的想象。有历史学家说过，人类之所以能够超越地球上的其它物种建立文明，主要是因为他们能够在自己的大脑中创造出现实中不存在的东西。在未来，当人工智能拥有超过人类的智力时，想象力也许是我们对于它们所拥有的惟一优势。
科幻小说是基于想象力的文学，而最早给我留下深刻印象的是Arthur . Clarke的作品。除了Jules Verne和George Wells外，Clarke的作品是最早进入中国的西方现代科幻小说。在上世纪八十年代初，中国出版了他的《2001:A Space Odyssey》和《Rendezvous With Rama》。当时文革刚刚结束，旧的生活和信仰已经崩塌，新的还没有建立起来，我和其他年轻人一样，心中一片迷茫。这两本书第一次激活了我想象力，思想豁然开阔许多，有小溪流进大海的感觉。读完《2001:A Space Odyssey》的那天深夜，我走出家门仰望星空，那时的中国的天空还没有太多的污染，能够看到银河，在我的眼中，星空与过去完全不一样了，我第一次对宇宙的宏大与神秘产生了敬畏感，这是一种宗教般的感觉。而后来读到的《Rendezvous With Rama》，也让我惊叹如何可以用想象力构造一个栩栩如生的想象世界。正是Clarke带给我的这些感受，让我后来成为一名科幻作家。
现在，三十多年过去了，我渐渐发现，我们这一代在上世纪六十年代出生于中国的人，很可能是人类历史上最幸运的人，因为之前没有任何一代人，像我们这样目睹周围的世界发生了如此巨大的变化，我们现在生活的世界，与我们童年的世界已经完全是两个不同的世界，而这种变化还在加速发生着。中国是一个充满着未来感的国度，中国的未来可能充满着挑战和危机，但从来没有像现在这样具有吸引力，这就给科幻小说提供了肥沃的土壤，使其在中国受到了空前的关注，作为一个在六十年代出生在中国的科幻小说家，则是幸运中的幸运。
我期待有那么一天，像那些曾经描写过信息时代的科幻小说一样，描写太空航行的科幻小说也变的平淡无奇了，那时的火星和小行星带都是乏味的地方，有无数的人在那里谋生；木星和它众多的卫星已成为旅游胜地，阻止人们去那里的唯一障碍就是昂贵的价格。
但即使在这个时候，宇宙仍是一个大的无法想象的存在，距我们最近的恒星仍然遥不可及。浩瀚的星空永远能够承载我们无穷的想象力。
谢谢大家。
点击阅读全文</content></entry><entry><title>Mermaid支持流程图</title><url>/post/mermaid-charts.html</url><categories><category>示例</category></categories><tags><tag>流程图</tag><tag>时序图</tag></tags><content type="html"><![CDATA[本主题已支持 Mermaid 实现以纯文本的方式绘制流程图、序列图、甘特图、状态图、关系图行等等，随着 Mermaid 也在逐步发展，后续还会有各种各样的图被引入进来，更多的类型及使用方式可关注其官方网站： https://mermaid-js.github.io/ 。
使用说明 通过 hugo new 命令创建一篇新的文章 在文章头部配置 mermaid: true 使用短代码书写各种类型的图，自带2个参数： align（对齐） 和 bc（背景色），可参考如下使用示例 流程图 {{&lt; mermaid align=&#34;left&#34; &gt;}} graph TD; A--&gt;B; A--&gt;C; B--&gt;D; C--&gt;D; {{&lt; /mermaid &gt;}} graph TD; A-->B; A-->C; B-->D; C-->D; 时序图 {{&lt; mermaid bc=&#34;#eee&#34; &gt;}} sequenceDiagram participant Alice participant Bob Alice-&gt;&gt;John: Hello John, how are you? loop Healthcheck John-&gt;&gt;John: Fight against hypochondria end Note right of John: Rational thoughts &lt;br/&gt;prevail! John--&gt;&gt;Alice: Great! John-&gt;&gt;Bob: How about you? Bob--&gt;&gt;John: Jolly good! {{&lt; /mermaid &gt;}} sequenceDiagram participant Alice participant Bob Alice->>John: Hello John, how are you? loop Healthcheck John->>John: Fight against hypochondria end Note right of John: Rational thoughts prevail! John-->>Alice: Great! John->>Bob: How about you? Bob-->>John: Jolly good! 类图 {{&lt; mermaid &gt;}} classDiagram Class01 &lt;|-- AveryLongClass : Cool Class03 *-- Class04 Class05 o-- Class06 Class07 .. Class08 Class09 --&gt; C2 : Where am i? Class09 --* C3 Class09 --|&gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla Class08 &lt;--&gt; C2: Cool label {{&lt; /mermaid &gt;}} classDiagram Class01 <|-- AveryLongClass : Cool Class03 *-- Class04 Class05 o-- Class06 Class07 .. Class08 Class09 --> C2 : Where am i? Class09 --* C3 Class09 --|> Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla Class08 <--> C2: Cool label 甘特图 {{&lt; mermaid &gt;}} gantt dateFormat YYYY-MM-DD title Adding GANTT diagram to mermaid excludes weekdays 2014-01-10 section A section Completed task :done, des1, 2014-01-06,2014-01-08 Active task :active, des2, 2014-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d {{&lt; /mermaid &gt;}} gantt dateFormat YYYY-MM-DD title Adding GANTT diagram to mermaid excludes weekdays 2014-01-10 section A section Completed task :done, des1, 2014-01-06,2014-01-08 Active task :active, des2, 2014-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d 实体关系图 {{&lt; mermaid &gt;}} erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses {{&lt; /mermaid &gt;}} erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses 用户旅程 {{&lt; mermaid &gt;}} journey title My working day section Go to work Make tea: 5: Me Go upstairs: 3: Me Do work: 1: Me, Cat section Go home Go downstairs: 5: Me Sit down: 5: Me {{&lt; /mermaid &gt;}} journey title My working day section Go to work Make tea: 5: Me Go upstairs: 3: Me Do work: 1: Me, Cat section Go home Go downstairs: 5: Me Sit down: 5: Me ]]></content></entry><entry><title>数学公式渲染</title><url>/post/math-formula.html</url><categories><category>示例</category></categories><tags><tag>数学公式</tag><tag>mathjax</tag><tag>katex</tag></tags><content type="html"><![CDATA[本主题支持 mathjax 和 katex 两种不的方案支持数学公式的渲染，可根据自已的需求进行选择。
接下的示例中，将使用 MathJax 方案来展示渲染效果。
使用 hugo new 命令创建一篇新的文章 可以全局启用数据公式渲染，请在项目配置参数 math: katex 或 math: mathjax 或是将该参数配置到需要显示数学公式的页面头部（减少不必要的加载消耗） 注意： 使用 支持的TeX功能 的联机参考资料。
例子 重复的分数 $$ \frac{1}{\Bigl(\sqrt{\phi \sqrt{5}}-\phi\Bigr) e^{\frac25 \pi}} \equiv 1+\frac{e^{-2\pi}} {1+\frac{e^{-4\pi}} {1+\frac{e^{-6\pi}} {1+\frac{e^{-8\pi}} {1+\cdots} } } } $$
总和记号 $$ \left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right) $$
几何级数之和 我把接下来的两个例子分成了几行，这样它在手机上表现得更好。这就是为什么它们包含 \displaystyle。
$$ \displaystyle\sum_{i=1}^{k+1}i $$
$$ \displaystyle= \left(\sum_{i=1}^{k}i\right) +(k+1) $$
$$ \displaystyle= \frac{k(k+1)}{2}+k+1 $$
$$ \displaystyle= \frac{k(k+1)+2(k+1)}{2} $$
$$ \displaystyle= \frac{(k+1)(k+2)}{2} $$
$$ \displaystyle= \frac{(k+1)((k+1)+1)}{2} $$
乘记号 $$ \displaystyle 1 + \frac{q^2}{(1-q)}+\frac{q^6}{(1-q)(1-q^2)}+\cdots = \displaystyle \prod_{j=0}^{\infty}\frac{1}{(1-q^{5j+2})(1-q^{5j+3})}, \displaystyle\text{ for }\lvert q\rvert &lt; 1. $$
随文数式 这是一些线性数学: $$ k_{n+1} = n^2 + k_n^2 - k_{n-1} $$ ， 然后是更多的文本。
希腊字母 $$ \Gamma\ \Delta\ \Theta\ \Lambda\ \Xi\ \Pi\ \Sigma\ \Upsilon\ \Phi\ \Psi\ \Omega \alpha\ \beta\ \gamma\ \delta\ \epsilon\ \zeta\ \eta\ \theta\ \iota\ \kappa\ \lambda\ \mu\ \nu\ \xi \ \omicron\ \pi\ \rho\ \sigma\ \tau\ \upsilon\ \phi\ \chi\ \psi\ \omega\ \varepsilon\ \vartheta\ \varpi\ \varrho\ \varsigma\ \varphi $$
箭头 $$ \gets\ \to\ \leftarrow\ \rightarrow\ \uparrow\ \Uparrow\ \downarrow\ \Downarrow\ \updownarrow\ \Updownarrow $$
$$ \Leftarrow\ \Rightarrow\ \leftrightarrow\ \Leftrightarrow\ \mapsto\ \hookleftarrow \leftharpoonup\ \leftharpoondown\ \rightleftharpoons\ \longleftarrow\ \Longleftarrow\ \longrightarrow $$
$$ \Longrightarrow\ \longleftrightarrow\ \Longleftrightarrow\ \longmapsto\ \hookrightarrow\ \rightharpoonup $$
$$ \rightharpoondown\ \leadsto\ \nearrow\ \searrow\ \swarrow\ \nwarrow $$
符号 $$ \surd\ \barwedge\ \veebar\ \odot\ \oplus\ \otimes\ \oslash\ \circledcirc\ \boxdot\ \bigtriangleup $$
$$ \bigtriangledown\ \dagger\ \diamond\ \star\ \triangleleft\ \triangleright\ \angle\ \infty\ \prime\ \triangle $$
微积分学 $$ \int u \frac{dv}{dx},dx=uv-\int \frac{du}{dx}v,dx $$
$$ f(x) = \int_{-\infty}^\infty \hat f(\xi),e^{2 \pi i \xi x} $$
$$ \oint \vec{F} \cdot d\vec{s}=0 $$
洛伦茨方程 $$ \begin{aligned} \dot{x} &amp; = \sigma(y-x) \\ \dot{y} &amp; = \rho x - y - xz \\ \dot{z} &amp; = -\beta z + xy \end{aligned} $$
交叉乘积 这在KaTeX中是可行的，但在这种环境中馏分的分离不是很好。
$$ \mathbf{V}_1 \times \mathbf{V}_2 = \begin{vmatrix} \mathbf{i} &amp; \mathbf{j} &amp; \mathbf{k} \\ \frac{\partial X}{\partial u} &amp; \frac{\partial Y}{\partial u} &amp; 0 \\ \frac{\partial X}{\partial v} &amp; \frac{\partial Y}{\partial v} &amp; 0 \end{vmatrix} $$
这里有一个解决方案:使用“mfrac”类(在MathJax情况下没有区别)的额外类使分数更小:
$$ \mathbf{V}_1 \times \mathbf{V}_2 = \begin{vmatrix} \mathbf{i} &amp; \mathbf{j} &amp; \mathbf{k} \\ \frac{\partial X}{\partial u} &amp; \frac{\partial Y}{\partial u} &amp; 0 \\ \frac{\partial X}{\partial v} &amp; \frac{\partial Y}{\partial v} &amp; 0 \end{vmatrix} $$
强调 $$ \hat{x}\ \vec{x}\ \ddot{x} $$
有弹性的括号 $$ \left(\frac{x^2}{y^3}\right) $$
评估范围 $$ \left.\frac{x^3}{3}\right|_0^1 $$
诊断标准 $$ f(n) = \begin{cases} \frac{n}{2}, &amp; \text{if } n\text{ is even} \\ 3n+1, &amp; \text{if } n\text{ is odd} \end{cases} $$
麦克斯韦方程组 $$ \begin{aligned} \nabla \times \vec{\mathbf{B}} -, \frac1c, \frac{\partial\vec{\mathbf{E}}}{\partial t} &amp; = \frac{4\pi}{c}\vec{\mathbf{j}} \\ \nabla \cdot \vec{\mathbf{E}} &amp; = 4 \pi \rho \\ \nabla \times \vec{\mathbf{E}}, +, \frac1c, \frac{\partial\vec{\mathbf{B}}}{\partial t} &amp; = \vec{\mathbf{0}} \\ \nabla \cdot \vec{\mathbf{B}} &amp; = 0 \end{aligned} $$
统计学 固定词组：
$$ \frac{n!}{k!(n-k)!} = {^n}C_k {n \choose k} $$
分数在分数 $$ \frac{\frac{1}{x}+\frac{1}{y}}{y-z} $$
ｎ次方根 $$ \sqrt[n]{1+x+x^2+x^3+\ldots} $$
矩阵 $$ \begin{pmatrix} a_{11} &amp; a_{12} &amp; a_{13}\\ a_{21} &amp; a_{22} &amp; a_{23}\\ a_{31} &amp; a_{32} &amp; a_{33} \end{pmatrix} \begin{bmatrix} 0 &amp; \cdots &amp; 0 \\ \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; \cdots &amp; 0 \end{bmatrix} $$
标点符号 $$ f(x) = \sqrt{1+x} \quad (x \ge -1) f(x) \sim x^2 \quad (x\to\infty) $$
现在用标点符号:
$$ f(x) = \sqrt{1+x}, \quad x \ge -1 f(x) \sim x^2, \quad x\to\infty $$
]]></content></entry><entry><title>支持用户自定义设计</title><url>/post/custom-files.html</url><categories><category>示例</category></categories><tags><tag>自定义</tag><tag>个性化</tag><tag>布局</tag></tags><content type="html"><![CDATA[对于熟悉前端开发的用户来说，可以通过自定义文件配置，实现对站点的样式和布局进行个性化的调整。其中布局方面主要是支持左侧边栏的站点概览部分，以及站点底部2个位置，但样式的重置可以是整个站点的任意位置。
打开配置参数 首先要明确在配置文件的 params 区域中有配置如下参数：
customFilePath: sidebar: custom_sidebar.html footer: custom_footer.html style: /css/custom_style.css 注意： sidebar 和 footer 的文件命名不可以与它们的参数名称相同，不然会影响系统默认的布局设计，切记！！！ 😄 然后在站点的根目录下创建 layouts/partials 2个目录，用于存放自定布局设计文件，另外在站点根目录下创建 statics/css 2个目录，用于存放自定义 CSS 样式文件。一切就绪后，就可以参考如下的步骤，完成自己的设计想法。
侧边栏设计 在前面创建 partials 目录中新一个后缀名为 html 的文件，可以在里面书写你所想表达的设计或内容，比如引入一些第三方组件内容。示例如下：
&lt;div class=&#34;mydefined animated&#34; itemprop=&#34;custom&#34;&gt; &lt;span&gt;支持自定义CSS和Sidebar布局啦💄💄💄&lt;/span&gt; &lt;/div&gt; 再把该文件的路径配置到相应的参数中，效果请查看左侧边栏底部的效果。
底部设计 在前面创建 partials 目录中新一个后缀名为 html 的文件，可以在里面书写你所想表达的设计或内容，比如引入一些第三方组件内容。示例如下：
&lt;div class=&#34;custom-footer&#34;&gt; Website source code &lt;a href=&#34;https://github.com/hugo-next/hugo-theme-next/tree/develop/exampleSite/layouts/partials/custom-footer.html&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; &lt;/div&gt; 再把该文件的路径配置到相应的参数中，效果请查看站点底部的效果。
自定义样式 在前面创建 css 目录中新一个后缀名为 css 的文件，然后可以在里面把站点的样式进行重定义，或是增加一些自己定义的样式设计，在写文章时进行引用，示例如下：
.custom-head5 { font-size: 1.2em; color: #ed6c24; font-weight: bold; } 再把该文件的路径配置到相应的参数中，效果参考如下：
我是自定义的标题样式效果!!!
]]></content></entry><entry><title>自定义短语示例</title><url>/post/shortcodes.html</url><categories><category>示例</category></categories><tags><tag>短代码</tag><tag>语法</tag></tags><content type="html"><![CDATA[虽然 Markdown 语法已经非常丰富能够满足我们写文章的绝大部分需求，但是为更好的对文章内容进行更友好的排版，为引设计一套自定义的短语，便于在使用时能够快速引用。
块引用 在引用一些经典名言名句时，可以采用此短语，语法参考如下：
{{&lt; quote &gt;}} ### block quote 写下你想表达的话语！ {{&lt; /quote &gt;}} 实际效果：
希望是无所谓有，无所谓无的，这正如地上的路。
其实地上本没有路，走的人多了，也便成了路。
鲁迅
信息块 支持 default，info，success，warning，danger 等五种不同效果的展示，语法参考如下：
{{&lt; note [class] [no-icon] &gt;}} 书写表达的信息 支持 Markdown 语法 {{&lt; /note &gt;}} 实际效果：
Default Header without icon Welcome to Hugo NexT! Default Header Welcome to Hugo NexT! Info Header Welcome to Hugo NexT! Success Header Welcome to Hugo NexT! Warning Header Welcome to Hugo NexT! Danger Header Welcome to Hugo NexT! ]]></content></entry><entry><title>关于 Hugo NexT 组织</title><url>/about.html</url><categories/><tags/><content type="html">Hugo NexT 组织是由众多喜爱 NexT 主题及风格的世界各地友人共同组建而成，为的就是让这个主题继续在 Hugo 引擎中也能得到发扬光大，在此也欢迎你的加入！
我们的愿景 延续 NexT 经典的黑白调搭配，保持简单的易用性及强大的功能。
使用反馈 加入 GitHub Discussions 或 Gitter 在线讨论 🍻 GitHub Issues 提交错误报告 🐛 GitHub Feature 表新功能的想法 ✨ 同时国内用户也可加入 QQ 群交流： 604710815</content></entry><entry><title>Hugo 内置的 Chroma 语法高亮</title><url>/post/syntax-highlighting.html</url><categories><category>示例</category></categories><tags><tag>语法</tag><tag>高亮</tag><tag>Chroma</tag></tags><content type="html"><![CDATA[Hugo 通过 Chroma 提供非常快速的语法高亮显示，现 Hugo 中使用 Chroma 作为代码块高亮支持，它内置在 Go 语言当中，速度是真的非常、非常快，而且最为重要的是它也兼容之前我们使用的 Pygments 方式。
以下通过 Hugo 内置短代码 highlight 和 Markdown 代码块方式分别验证不同语言的代码块渲染效果并能正确高亮显示，有关优化语法突出显示的更多信息，请参阅 Hugo 文档 。
编程语言 GO 199 200 201 202 203 204 205 206 207 208 func GetTitleFunc(style string) func(s string) string { switch strings.ToLower(style) { case &#34;go&#34;: return strings.Title case &#34;chicago&#34;: return transform.NewTitleConverter(transform.ChicagoStyle) default: return transform.NewTitleConverter(transform.APStyle) } } Java import javax.swing.JFrame; //Importing class JFrame import javax.swing.JLabel; //Importing class JLabel public class HelloWorld { public static void main(String[] args) { JFrame frame = new JFrame(); //Creating frame frame.setTitle(&#34;Hi!&#34;); //Setting title frame frame.add(new JLabel(&#34;Hello, world!&#34;));//Adding text to frame frame.pack(); //Setting size to smallest frame.setLocationRelativeTo(null); //Centering frame frame.setVisible(true); //Showing frame } } Python print &#34;Hello, world!&#34; Git 对比 1*** /path/to/original &#39;&#39;timestamp&#39;&#39; 2--- /path/to/new &#39;&#39;timestamp&#39;&#39; 3*************** 4*** 1 **** 5! This is a line. 6--- 1 --- 7! This is a replacement line. 8It is important to spell 9-removed line 10+new line *** /path/to/original &#39;&#39;timestamp&#39;&#39; --- /path/to/new &#39;&#39;timestamp&#39;&#39; *************** *** 1 **** ! This is a line. --- 1 --- ! This is a replacement line. It is important to spell -removed line +new line 文件 Make 文件 CC=gcc CFLAGS=-I. hellomake: hellomake.o hellofunc.o $(CC) -o hellomake hellomake.o hellofunc.o -I. Markdown 文档 **bold** *italics* [link](www.example.com) 数据内容 JSON 数据 {&#34;employees&#34;:[ {&#34;firstName&#34;:&#34;John&#34;, &#34;lastName&#34;:&#34;Doe&#34;}, ]} XML 内容 &lt;employees&gt; &lt;employee&gt; &lt;firstName&gt;John&lt;/firstName&gt; &lt;lastName&gt;Doe&lt;/lastName&gt; &lt;/employee&gt; &lt;/employees&gt; SQL 查询 SELECT column_name,column_name FROM Table WHERE column_name = &#34;condition&#34; 除以上列举的代码高亮显示外，还支持诸如：C 语言、C++、HTML、CSS、Shell脚本等各主流的代码语言高亮显示，可自行测试效果。
]]></content></entry><entry><title>支持 Emoji 表情</title><url>/post/emoji-support.html</url><categories><category>示例</category></categories><tags><tag>表情</tag><tag>emoji</tag></tags><content type="html">Emoji 可以通过多种方式在 Hugo 项目中启用。
emojify 方法可以直接在模板中调用, 或者使用 行内 Shortcodes .
要全局使用 emoji, 需要在你的 网站配置 中设置 enableEmoji 为 true， 然后你就可以直接在文章中输入 emoji 的代码。
它们以冒号开头和结尾，并且包含 emoji 的 代码：
去露营啦! {:}tent: 很快就回来. 真开心! {:}joy: 呈现的输出效果如下:
去露营啦! ⛺ 很快就回来。
真开心! 😂
以下符号清单是 emoji 代码的非常有用的参考。
表情与情感 笑脸表情 图标 代码 图标 代码 😀 grinning 😃 smiley 😄 smile 😁 grin 😆 laughing satisfied 😅 sweat_smile 🤣 rofl 😂 joy 🙂 slightly_smiling_face 🙃 upside_down_face 😉 wink 😊 blush 😇 innocent 爱意表情 图标 代码 图标 代码 😍 heart_eyes 😘 kissing_heart 😗 kissing ☺️ relaxed 😚 kissing_closed_eyes 😙 kissing_smiling_eyes 吐舌头表情 图标 代码 图标 代码 😋 yum 😛 stuck_out_tongue 😜 stuck_out_tongue_winking_eye 😝 stuck_out_tongue_closed_eyes 🤑 money_mouth_face 国家和地区旗帜 图标 代码 图标 代码 🇦🇩 andorra 🇦🇪 united_arab_emirates 🇦🇫 afghanistan 🇦🇬 antigua_barbuda 🇦🇮 anguilla 🇦🇱 albania 🇦🇲 armenia 🇦🇴 angola 🇦🇶 antarctica 🇦🇷 argentina 🇦🇸 american_samoa 🇦🇹 austria 🇦🇺 australia 🇦🇼 aruba 🇦🇽 aland_islands 🇦🇿 azerbaijan 🇧🇦 bosnia_herzegovina 🇧🇧 barbados 🇧🇩 bangladesh 🇧🇪 belgium 🇧🇫 burkina_faso 🇧🇬 bulgaria 🇧🇭 bahrain 🇧🇮 burundi 🇧🇯 benin 🇧🇱 st_barthelemy 🇧🇲 bermuda 🇧🇳 brunei 🇧🇴 bolivia 🇧🇶 caribbean_netherlands 🇧🇷 brazil 🇧🇸 bahamas 🇧🇹 bhutan 🇧🇼 botswana 🇧🇾 belarus 🇧🇿 belize 🇨🇦 canada 🇨🇨 cocos_islands 🇨🇩 congo_kinshasa 🇨🇫 central_african_republic 🇨🇬 congo_brazzaville 🇨🇭 switzerland 🇨🇮 cote_divoire 🇨🇰 cook_islands 🇨🇱 chile 🇨🇲 cameroon 🇨🇳 cn 🇨🇴 colombia 🇨🇷 costa_rica 🇨🇺 cuba 🇨🇻 cape_verde 🇨🇼 curacao 🇨🇽 christmas_island 🇨🇾 cyprus 🇨🇿 czech_republic 🇩🇪 de 🇩🇯 djibouti 🇩🇰 denmark 🇩🇲 dominica 🇩🇴 dominican_republic 🇩🇿 algeria 🇪🇨 ecuador 🇪🇪 estonia 🇪🇬 egypt 🇪🇭 western_sahara 🇪🇷 eritrea 🇪🇸 es 🇪🇹 ethiopia 🇪🇺 eu european_union 🇫🇮 finland 🇫🇯 fiji 🇫🇰 falkland_islands 🇫🇲 micronesia 🇫🇴 faroe_islands 🇫🇷 fr 🇬🇦 gabon 🇬🇧 gb uk 🇬🇩 grenada 🇬🇪 georgia 🇬🇫 french_guiana 🇬🇬 guernsey 🇬🇭 ghana 🇬🇮 gibraltar 🇬🇱 greenland 🇬🇲 gambia 🇬🇳 guinea 🇬🇵 guadeloupe 🇬🇶 equatorial_guinea 🇬🇷 greece 🇬🇸 south_georgia_south_sandwich_islands 🇬🇹 guatemala 🇬🇺 guam 🇬🇼 guinea_bissau 🇬🇾 guyana 🇭🇰 hong_kong 🇭🇳 honduras 🇭🇷 croatia 🇭🇹 haiti 🇭🇺 hungary 🇮🇨 canary_islands 🇮🇩 indonesia 🇮🇪 ireland 🇮🇱 israel 🇮🇲 isle_of_man 🇮🇳 india 🇮🇴 british_indian_ocean_territory 🇮🇶 iraq 🇮🇷 iran 🇮🇸 iceland 🇮🇹 it 🇯🇪 jersey 🇯🇲 jamaica 🇯🇴 jordan 🇯🇵 jp 🇰🇪 kenya 🇰🇬 kyrgyzstan 🇰🇭 cambodia 🇰🇮 kiribati 🇰🇲 comoros 🇰🇳 st_kitts_nevis 🇰🇵 north_korea 🇰🇷 kr 🇰🇼 kuwait 🇰🇾 cayman_islands 🇰🇿 kazakhstan 🇱🇦 laos 🇱🇧 lebanon 🇱🇨 st_lucia 🇱🇮 liechtenstein 🇱🇰 sri_lanka 🇱🇷 liberia 🇱🇸 lesotho 🇱🇹 lithuania 🇱🇺 luxembourg 🇱🇻 latvia 🇱🇾 libya 🇲🇦 morocco 🇲🇨 monaco 🇲🇩 moldova 🇲🇪 montenegro 🇲🇬 madagascar 🇲🇭 marshall_islands 🇲🇰 macedonia 🇲🇱 mali 🇲🇲 myanmar 🇲🇳 mongolia 🇲🇴 macau 🇲🇵 northern_mariana_islands 🇲🇶 martinique 🇲🇷 mauritania 🇲🇸 montserrat 🇲🇹 malta 🇲🇺 mauritius 🇲🇻 maldives 🇲🇼 malawi 🇲🇽 mexico 🇲🇾 malaysia 🇲🇿 mozambique 🇳🇦 namibia 🇳🇨 new_caledonia 🇳🇪 niger 🇳🇫 norfolk_island 🇳🇬 nigeria 🇳🇮 nicaragua 🇳🇱 netherlands 🇳🇴 norway 🇳🇵 nepal 🇳🇷 nauru 🇳🇺 niue 🇳🇿 new_zealand 🇴🇲 oman 🇵🇦 panama 🇵🇪 peru 🇵🇫 french_polynesia 🇵🇬 papua_new_guinea 🇵🇭 philippines 🇵🇰 pakistan 🇵🇱 poland 🇵🇲 st_pierre_miquelon 🇵🇳 pitcairn_islands 🇵🇷 puerto_rico 🇵🇸 palestinian_territories 🇵🇹 portugal 🇵🇼 palau 🇵🇾 paraguay 🇶🇦 qatar 🇷🇪 reunion 🇷🇴 romania 🇷🇸 serbia 🇷🇺 ru 🇷🇼 rwanda 🇸🇦 saudi_arabia 🇸🇧 solomon_islands 🇸🇨 seychelles 🇸🇩 sudan 🇸🇪 sweden 🇸🇬 singapore 🇸🇭 st_helena 🇸🇮 slovenia 🇸🇰 slovakia 🇸🇱 sierra_leone 🇸🇲 san_marino 🇸🇳 senegal 🇸🇴 somalia 🇸🇷 suriname 🇸🇸 south_sudan 🇸🇹 sao_tome_principe 🇸🇻 el_salvador 🇸🇽 sint_maarten 🇸🇾 syria 🇸🇿 swaziland 🇹🇨 turks_caicos_islands 🇹🇩 chad 🇹🇫 french_southern_territories 🇹🇬 togo 🇹🇭 thailand 🇹🇯 tajikistan 🇹🇰 tokelau 🇹🇱 timor_leste 🇹🇲 turkmenistan 🇹🇳 tunisia 🇹🇴 tonga 🇹🇷 tr 🇹🇹 trinidad_tobago 🇹🇻 tuvalu 🇹🇼 taiwan 🇹🇿 tanzania 🇺🇦 ukraine 🇺🇬 uganda 🇺🇸 us 🇺🇾 uruguay 🇺🇿 uzbekistan 🇻🇦 vatican_city 🇻🇨 st_vincent_grenadines 🇻🇪 venezuela 🇻🇬 british_virgin_islands 🇻🇮 us_virgin_islands 🇻🇳 vietnam 🇻🇺 vanuatu 🇼🇫 wallis_futuna 🇼🇸 samoa 🇽🇰 kosovo 🇾🇪 yemen 🇾🇹 mayotte 🇿🇦 south_africa 🇿🇲 zambia 🇿🇼 zimbabwe</content></entry><entry><title>Markdown 语法支持</title><url>/post/markdown-syntax.html</url><categories><category>示例</category></categories><tags><tag>Markdown</tag><tag>语法</tag></tags><content type="html"><![CDATA[仅以此篇文章来测试下在 NexT 主题中在通过 Hugo 引擎来建站时，是否支持 Markdown 文件内容中所写的各种语法，并展示下实际的效果。
标题样式 让我们从所有可能的标题开始，在 HTML 中 &lt;h1&gt;-&lt;h6&gt;元素分别表示六个不同级别的标题样式，其中 &lt;h1&gt; 为最大标题，&lt;h6&gt;为最小标题，效果如下：
标题 1 标题 2 标题 3 标题 4 标题 5 标题 6 段落格式 根据 W3C 定义的 HTML5 规范 ，HTML 文档由元素和文本组成。每个元素的组成都由一个 开始标记 表示，例如： &lt;body&gt; ，和 结束标记 表示，例如： &lt;/body&gt; 。（某些开始标记和结束标记在某些情况下可以省略，并由其他标记暗示。） 元素可以具有属性，这些属性控制元素的工作方式。例如：超链接是使用 a 元素及其 href 属性形成的。
Markdown 语法 ![图像说明](图像地址) HTML IMG 标签 &lt;img src=&#34;图像地址&#34; width=&#34;宽度&#34; height=&#34;高度&#34; /&gt; SVG 格式 &lt;svg&gt;xxxxxx&lt;/svg&gt; 列表类型 有序列表 第一个元素 第二个元素 第三个元素 无序列表 列表元素 另一个元素 和其它元素 嵌套列表 借助 HTML 的 ul 元素来实现。
第一项 第二项 第二项第一个子项目 第二项第二个子项目 第二项第二分项第一分项 第二项第二分项第二分项 第二项第二分项第三分项 第二项第三个子项目 第二项第三分项第一分项 第二项第三分项第二分项 第二项第三分项第三分项 第三项 自定义列表 通过 HTML 的 dl 元素还支持自定义列表（表格列表）。
Hugo 目录结构 assets config.toml content data theme static Hugo 模板 基础模板 列表模板 单页模板 块引用 blockquote 元素表示从另一个源引用的内容，可以选择引用必须在 footer 或 cite 元素中，也可以选择使用注释和缩写等行内更改。
引用文本 这一行也是同样的引用 同样你也在 blockquote 中使用 Markdown 语法书写
带有引文的 Blockquote 元素效果。
我的目标不是赚大钱,是为了制造好的电脑。当我意识到我可以永远当工程师时，我才创办了这家公司。
— 史蒂夫·沃兹尼亚克 根据 Mozilla 的网站记录，Firefox 1.0 于 2004 年发布，并取得了巨大成功。
表格 表格并不算是 Markdown 的核心要素，但 Hugo 同样支持它。
ID 创建者 模型 年份 1 Honda Accord 2009 2 Toyota Camry 2012 3 Hyundai Elantra 2010 可以使用 : （英文格式冒号）来对表格内容进行对齐。
表格 可以是 很酷 左对齐 居中 右对齐 左对齐 居中 右对齐 左对齐 居中 右对齐 同样也可以在表格中使用 Markdown 语法。
表格 中 使用 Markdown 语法 斜体 粗体 中划线 代码块 Code &lt;!DOCTYPE html&gt; &lt;html lang=&#34;en&#34;&gt; &lt;head&gt; &lt;meta charset=&#34;UTF-8&#34;&gt; &lt;title&gt;Example HTML5 Document&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;Test&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; &lt;!DOCTYPE html&gt; &lt;html lang=&#34;en&#34;&gt; &lt;head&gt; &lt;meta charset=&#34;UTF-8&#34;&gt; &lt;title&gt;Example HTML5 Document&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;Test&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; 其它元素： abbr、sub、sup、kbd等等 GIF 是位图图像格式。
H2O
C6H12O6
Xn + Yn = Zn
按X获胜。或按CTRL+ALT+F显示 FPS 计数器。
比特作为信息论中的信息单位，也被称为 shannon ，以信息论领域的创始人 Claude shannon 的名字命名。
参考：
来自 Mainroad 主题的 Basic Elements 内容 ]]></content></entry><entry><title>站点示例</title><url>/flinks.html</url><categories/><tags/><content type="html">如想交换本站友情链接，请在评论区留下你的站点信息，格式参考如下：
- name: Hugo-NexT desc: Hugo NexT 官方预览网站。 avatar: https://hugo-next.eu.org/imgs/hugo_next_avatar.png link: https://hugo-next.eu.org</content></entry></search>